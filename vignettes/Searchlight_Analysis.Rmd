---
title: "Searchlight Analysis"
author: "Bradley Buchsbaum"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Searchlight Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


## Searchlight Analysis
```{r, echo=FALSE, message=FALSE}
suppressPackageStartupMessages(library(neuroim2))
##suppressPackageStartupMessages(library(devtools))
library(rMVPA)

# Safe histogram helper: prefer ggplot2; otherwise print a compact summary
safe_plot_hist <- function(x, title = "Histogram", bins = 30) {
  x <- as.numeric(x)
  x <- x[is.finite(x)]
  if (!length(x)) {
    message("No finite AUC values to plot.")
    return(invisible(NULL))
  }
  if (requireNamespace("ggplot2", quietly = TRUE)) {
    df <- data.frame(x = x)
    p <- ggplot2::ggplot(df, ggplot2::aes(x = x)) +
      ggplot2::geom_histogram(bins = bins, fill = "grey80", color = "white") +
      ggplot2::labs(title = title, x = "AUC", y = "Count") +
      ggplot2::theme_minimal()
    print(p)
  } else {
    smry <- sprintf("AUC summary: n=%d, mean=%.3f, sd=%.3f, min=%.3f, max=%.3f", 
                    length(x), mean(x), stats::sd(x), min(x), max(x))
    message(smry)
  }
}
```

### Generate a volumetric dataset with 100 observations and two classes

To generate a dataset we use the `gen_sample_dataset` function. We are creating a 4-dimensional neuroimaging dataset, with 6-by-6-by-6 spatial dimensions and 80 observations in the 4th dimension. These 80 observations are divided into 4 blocks, each consisting of 20 trials. The generated `y` variable is a `factor` with 2 levels ('a' and 'b'). the `gen_sample_dataset` function creates a list with two elements: an `mvpa_dataset` object (`dataset`) and an `mvpa_design` object (`design`). The first contains information about the data itself and the second contains information about the experimental design.


```{r}

dataset <- gen_sample_dataset(D=c(6,6,6), nobs = 80, blocks=4, nlevels=2)
print(dataset)
```

### Create a cross-validation object using a pre-defined blocking variable.

Most MVPA analyses involve the collection of fMRI data over a series of scanning runs, or "blocks". Due to intra-block serial correlations, it makes sense to take advantage of this block structure for cross-validation. In other words, we want to train the classifier on `k-1` blocks and test on the set of trials for all `k` held out blocks. This is a form of leave-one-group-out cross-validation, which is encapsulated in the `blocked_cross_validation` function.

```{r}
block <- dataset$design$block_var
crossval <- blocked_cross_validation(block)
crossval
```

### Construct an `mvpa_model` object with a Shrinkage Discriminant Analysis classifier (`sda_notune`)

The "sda_notune" model is an `sda` model where the `lambda` parameter is estimated from the training data. See documentation in the [sda package](https://cran.r-project.org/web/packages/sda/index.html)
 package.

```{r}
sda_model <- load_model("sda_notune") 
model <- mvpa_model(model=sda_model, dataset=dataset$dataset, design=dataset$design, crossval=crossval)
model
```

### Run a standard searchlight analysis

The output of `run_searchlight` is a list of image volumes containing performance measures for each spherical searchlight. For a two-class classification problem, there are three output measures: `Accuracy` and `AUC` (`AUC` has .5 subtracted from it, so that it is centered at 0 rather than .5). `Accuracy` is the raw cross-validated accuracy measure for each centroid and `AUC` is the area under the curve statistic. The `radius` argument indicates the radius in `mm` of the spherical searchlight. Finally, `method` indicates the searchlight scheme, which can be `standard` or `randomized`. See below for more information about the randomized searchlight.

```{r}
result <- run_searchlight(model, radius=4, method="standard")
result
```

```{r, echo=FALSE}
if (!is.null(result$results$AUC)) {
  auc_vals <- as.numeric(neuroim2::values(result$results$AUC))
  auc_vals <- auc_vals[is.finite(auc_vals)]
  if (length(auc_vals) > 0) safe_plot_hist(auc_vals, title = "Searchlight AUC (centered)")
}
```

## Run a randomized searchlight analysis

A randomized searchlight analysis is an iterative procedure in which searchlight regions are sampled *without replacement* from the voxel set. A classification analysis is run for each region, and the result is recorded for the center voxel and *all other voxels in the region*. This is done for each of `niter` times, where each iteration involves an exhaustive sampling of the voxel set. The performance at each voxel is the average performance for the set of analyses in which the given voxel was included as a feature. The result will be similar to the standard searchlight procedure, but emphasizes the contribution of a given voxel across different local contexts to classification performance. This should in principle offer slightly better spatial localization than the standard searchlight. The randomized searchlight procedure can also be faster, because the total number of estimated models is a function of `nvoxels/radius * niter`, which will be smaller than `nvoxels` for many choices of `radius` and `niter`.

```{r}
result <- run_searchlight(model, radius=4, method="randomized", niter=8)
result
```

```{r, echo=FALSE}
if (!is.null(result$results$AUC)) {
  auc_vals <- as.numeric(neuroim2::values(result$results$AUC))
  auc_vals <- auc_vals[is.finite(auc_vals)]
  if (length(auc_vals) > 0) safe_plot_hist(auc_vals, title = "Randomized Searchlight AUC (centered)")
}
```

## Using different classifiers

All of the classifiers in the MVPAModels registry can be used for a searchlight analysis. Additional models can be registered using `register_mvpa_model()`. For example, to run an analysis using a built-in model:

```{r, eval=FALSE}
svm_model <- load_model("svmLinear") 
model <- mvpa_model(model=svm_model, dataset=dataset$dataset, design=dataset$design, crossval=crossval)
result_svm <- run_searchlight(model, radius=4, method="randomized", niter=2)
```


Here we specify a range of values for the `mtry` tuning parameter. In this case, by supplying the `tune_reps` argument to `mvpa_model` we control the number of resamples used to tune the model parameters. The default is 10, but here we speed up execution time by reducing it to 2. In general, more resamples are required to reliably estimate optimal tuning parameters. This means for a whole-brain searchlight, parameter tuning is **generally** impractical. This is why the classifier `sda_notune` is a good choice for searchlight analyses, since it "works well" with default tuning parameters.

```{r}
if (requireNamespace("randomForest", quietly = TRUE)) {
  rf_model <- load_model("rf")
  model <- mvpa_model(model = rf_model, dataset = dataset$dataset, design = dataset$design,
                      crossval = crossval, tune_grid = data.frame(mtry = 2))
  result_rf <- run_searchlight(model, radius = 4, method = "randomized", niter = 2)
  result_rf
} else {
  message("Package 'randomForest' not installed; skipping RF example.")
}
```

```{r, message=FALSE, warning=FALSE}
if (requireNamespace("randomForest", quietly = TRUE)) {
  grid <- data.frame(mtry = c(2, 4, 6, 8))
  model2 <- mvpa_model(model = rf_model, dataset = dataset$dataset, design = dataset$design,
                       crossval = crossval, tune_grid = grid, tune_reps = 2)
  result_rf_tuned <- run_searchlight(model2, radius = 6, method = "randomized", niter = 1)
  result_rf_tuned
} else {
  message("Package 'randomForest' not installed; skipping tuned RF example.")
}
```

<!-- ## External Cross-Validation Example -->

<!-- Instead of using internal cross-validation, as we used in the above examples, sometimes one might have a held-out test data that can be used as a validation set. Here we show how to  -->

<!-- ```{r} -->
<!-- # Create training data -->
<!-- train_design <- data.frame(y = rep(letters[1:4], 5), x1 = rnorm(20), x2 = rnorm(20), block = rep(1:4, each = 5)) -->

<!-- # Create test data -->
<!-- test_design <- data.frame(y = sample(letters[1:4], 10, replace=TRUE)) -->

<!-- # Create an MVPA design object with external cross-validation -->
<!-- design <- mvpa_design(train_design, ~ y, block_var = ~ block, test_design = test_design, y_test = ~ y) -->

<!-- # Display the MVPA design object -->
<!-- print(design) -->

<!-- # Create a new dataset for external cross-validation -->
<!-- dataset_ext <- list(dataset = dataset$dataset, design = design) -->

<!-- # Construct an `mvpa_model` object with a Shrinkage Discriminant Analysis classifier (`sda_notune`) -->
<!-- sda_model_ext <- load_model("sda_notune") -->
<!-- model_ext <- mvpa_model(model = sda_model_ext, dataset = dataset_ext$dataset, design = dataset_ext$design) -->

<!-- # Run a randomized searchlight analysis using external cross-validation -->
<!-- result_ext <- run_searchlight(model_ext, radius = 4, method = "randomized", niter = 8) -->

<!-- # Display the results -->
<!-- print(result_ext) -->

<!-- # Plot a histogram of AUC values -->
<!-- hist(result_ext$AUC) -->
<!-- ``` -->
