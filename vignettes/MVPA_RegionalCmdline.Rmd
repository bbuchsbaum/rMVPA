---
title: MVPA Regional Analysis Tutorial
author: Your Name
date: '`r Sys.Date()`'
output: rmarkdown::html_vignette
vignette: '%\VignetteIndexEntry{MVPA Regional Analysis Tutorial} %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}'
params:
  family: red
css: albers.css
resource_files:
- albers.css
- albers.js
includes:
  in_header: |-
    <script src="albers.js"></script>
    <script>document.addEventListener('DOMContentLoaded',()=>document.body.classList.add('palette-red'));</script>

---

# Introduction

This tutorial explains how to run **regional multivariate pattern analysis (MVPA)** using **MVPA_Regional.R**. 
The script performs MVPA on specified brain regions, enabling both classification and regression analyses on fMRI data. 
Regional analysis can be conducted on volumetric (NIfTI) or surface-based neuroimaging data, and allows for separate training and testing subsets.

## Key features

The script supports volumetric NIfTI and surface data, separate training/testing subsets, and full configuration via YAML or R files. Outputs include region‑level performance maps, prediction tables, and a configuration record. Cross‑validation options include blocked, k‑fold, and two‑fold. Built‑in MVPA models are available from the registry, and preprocessing includes optional centering/scaling and feature selection.

---

# Running the Script

## 1. Basic Usage

If you have:

- A **4D fMRI file** for training (e.g., `train_data.nii`)
- A **trial-by-trial design matrix** (e.g., `train_design.txt`)
- A **brain mask file** (e.g., `mask.nii`)

You can run the regional analysis from the command line:

```bash
Rscript MVPA_Regional.R --train_design=train_design.txt \
                         --train_data=train_data.nii \
                         --mask=mask.nii \
                         --model=sda_notune \
                         --label_column=condition \
                         --ncores=4 \
                         --output=my_regional_output
```

## 2. Data modes

The script supports two primary data modes:

### Image mode (volumetric)
Default (`--data_mode=image`). For regional analysis, the `--mask` argument should be a label map (aka ROI parcellation) in NIfTI format:

- The mask is a 3D image in the same space as your data.
- Voxels with value `0` are ignored (background).
- Each non‑zero integer value defines a distinct ROI ID (e.g., 1, 2, 3, ...).
- The script treats every unique non‑zero value as a separate region and runs one MVPA per region.

Typical sources for region masks:
- Atlas/parcellation volumes (e.g., cortical/functional parcellations) where integers index regions.
- Custom ROI sets you create by combining binary masks into a single labeled volume.

Create a simple labeled ROI mask in R (example):
```r
library(neuroim2)

# Start from two binary ROI masks in the same space
roi1 <- read_vol("roi_left.nii.gz")
roi2 <- read_vol("roi_right.nii.gz")

# Build a labeled mask: left=1, right=2; background stays 0
lab <- array(0L, dim = dim(roi1))
v1 <- as.logical(values(roi1))
v2 <- as.logical(values(roi2))
lab[v1] <- 1L
lab[v2] <- 2L

roi_mask <- NeuroVol(lab, space(roi1))
write_vol(roi_mask, "my_roi_mask.nii.gz")
```

Use this file with the regional script:
```bash
Rscript MVPA_Regional.R \
  --train_design=train_design.txt \
  --train_data=train_data.nii.gz \
  --mask=my_roi_mask.nii.gz \
  --model=sda_notune \
  --label_column=condition \
  --output=regional_out
```

Notes
- To analyze only a subset of atlas regions, make a copy of the atlas and set all unwanted labels to 0.
- The script logs the number of detected regions; this should match the count of unique non‑zero labels.

### Surface mode
Use `--data_mode=surface` for cortical meshes; multiple surface sections are supported.

For surface analyses, `--mask` can be a labeled surface (one file per section/hemisphere) matching the mesh. The loader will use the non‑zero labels as ROI IDs, similar to volumetric masks.

## 3. Models

The script supports various classification and regression models:

### Built‑in MVPA models
- `corclass`: Correlation-based classifier with template matching
- `sda_notune`: Shrinkage Discriminant Analysis without tuning
- `sda_boot`: SDA with bootstrap resampling
- `glmnet_opt`: Elastic net with EPSGO parameter optimization
- `sparse_sda`: SDA with sparsity constraints
- `sda_ranking`: SDA with automatic feature ranking
- `mgsda`: Multi-Group Sparse Discriminant Analysis
- `lda_thomaz`: Modified LDA for high-dimensional data
- `hdrda`: High-Dimensional Regularized Discriminant Analysis

You can also register custom models via `register_mvpa_model()`.

## 4. Cross‑validation options

Multiple cross-validation strategies are available:

### Blocked Cross-Validation
```bash
--block_column=session
```
Uses a blocking variable (e.g., session) for splitting the data.

### K-Fold Cross-Validation
Default when no block column is specified; uses random splits.

### Two-Fold Cross-Validation
Specify in the configuration file:
```yaml
cross_validation:
  name: "twofold"
  nreps: 10
```

### Advanced cross‑validation methods

Beyond blocked and k‑fold splits, you can use two‑fold resampling (repeated), or provide custom train/test indices. Specify the method in the config file under `cross_validation.name`. For example:
```yaml
cross_validation:
  name: "twofold"   # Options: "twofold", "blocked", "custom" (kfold is the default when unspecified)
  nreps: 10
```
Choose the method that best matches your data structure and experimental design.

## 5. Feature Selection

Enable feature selection with:
```yaml
feature_selector:
  method: "anova"  # Options: "correlation", "t-test", etc.
  cutoff_type: "percentile"
  cutoff_value: 0.1
```

## 6. Understanding `label_column`

The **label column** specifies the target variable:

- For **classification**, it should contain categorical labels (e.g., "Face", "House").
- For **regression**, it should contain continuous values (e.g., reaction times).

**Example Design File (`train_design.txt`):**

```
trial  condition  subject  session
1      Face       S01      1
2      House      S01      1
3      Face       S01      1
4      House      S01      1
5      Face       S01      2
```

## 7. Using a Configuration File

Instead of specifying all options on the command line, you can use a configuration file.

**Example YAML Config File (`regional_config.yaml`):**

```yaml
# Data Sources
train_design: "train_design.txt"
test_design: "test_design.txt"
train_data: "train_data.nii"
test_data: "test_data.nii"
mask: "mask.nii"

# Analysis Parameters
model: "rf"  # Random Forest classifier
data_mode: "image"  # or "surface"
ncores: 4
label_column: "condition"
block_column: "session"

# Output Options
output: "regional_results"
normalize_samples: TRUE
class_metrics: TRUE

# Advanced Options
feature_selector:
  method: "anova"
  cutoff_type: "percentile"
  cutoff_value: 0.1

cross_validation:
  name: "twofold"
  nreps: 10

# Optional Subsetting: Define different subsets for training and testing
train_subset: "subject == 'S01'"
test_subset: "subject == 'S02'"
```

**Running with a Config File:**

```bash
Rscript MVPA_Regional.R --config=regional_config.yaml
```

## 8. Expected Outputs

After running the script, the output directory (e.g., `regional_results/`) contains:

- **Performance Maps**: NIfTI files with region-level performance metrics (e.g., accuracy, AUC).
- **Prediction Tables**: Text files summarizing predictions for each region.
- **Configuration File**: `config.yaml` with complete analysis parameters for reproducibility.

Example directory structure:

```
regional_results/
├── performance_table.txt   # Regional performance metrics
├── prediction_table.txt    # Prediction details per region
├── regional_metric1.nii    # Regional performance map (e.g., accuracy or AUC)
├── regional_metric2.nii    # Additional metric maps (if applicable)
└── config.yaml             # Analysis configuration
```

For regression analyses, different metrics (e.g., `r2.nii`, `rmse.nii`, `spearcor.nii`) will be output.

## 9. Performance Considerations

- Use `--normalize` on the CLI (or `normalize_samples: TRUE` in YAML) for improved model performance.
- Increase `--ncores` to leverage multi-core systems.
- Adjust parameters based on spatial resolution and hypotheses.
- Select appropriate cross-validation strategies to prevent overfitting.

## 10. Domain‑adaptive cross‑decoding from the CLI (REMAP‑RRR)

To run REMAP‑RRR from MVPA_Regional.R, set `--model=remap_rrr` and provide both train and test datasets/designs (source→target). Optionally supply a pairing key shared by train/test designs:

```bash
Rscript MVPA_Regional.R \
  --train_design=perception_design.txt \
  --test_design=memory_design.txt \
  --train_data=perception_data.nii \
  --test_data=memory_data.nii \
  --mask=mask.nii \
  --model=remap_rrr \
  --label_column=condition \
  --output=remap_roi
```

Optional config fields for REMAP (YAML):
```yaml
link_by: image_id              # item ID present in both designs
remap_rank: auto               # or small integer (e.g., 4)
remap_lambda_grid: [0, 0.25, 0.5, 0.75, 1]
remap_leave_one_key_out: true
remap_min_pairs: 5
```
Outputs include standard metrics plus REMAP diagnostics per ROI: `remap_improv`, `delta_frob_mean`, `lambda_mean`.

# Summary

MVPA_Regional.R provides comprehensive regional MVPA analysis capabilities. It handles both volumetric and surface-based data formats with flexible configuration through command line or config files. The tool generates detailed performance maps and prediction tables, while incorporating robust cross-validation and feature selection to ensure reliable results.

**Next Steps:**
- Experiment with various models (`--model=rf`, `--model=sda_notune`).
- Test different feature selection methods.
- Evaluate both classification and regression scenarios.
- Optimize processing using parallel computation.

Happy regional analysis! 
