% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/allgeneric.R, R/importance.R
\name{model_importance}
\alias{model_importance}
\alias{model_importance.sda}
\alias{model_importance.glmnet}
\alias{model_importance.spacenet_fit}
\alias{model_importance.randomForest}
\alias{model_importance.default}
\title{Per-Feature Model Importance}
\usage{
model_importance(object, X_train, ...)

\method{model_importance}{sda}(object, X_train, summary_fun = NULL, ...)

\method{model_importance}{glmnet}(object, X_train, summary_fun = NULL, ...)

\method{model_importance}{spacenet_fit}(object, X_train, summary_fun = NULL, ...)

\method{model_importance}{randomForest}(object, X_train, ...)

\method{model_importance}{default}(object, X_train, ...)
}
\arguments{
\item{object}{A fitted model object (e.g., from \code{sda}, \code{glmnet},
\code{randomForest}).}

\item{X_train}{The training data matrix (T x P) used to fit \code{object}.
Required for Haufe-based methods; ignored by tree-based methods.}

\item{...}{Additional arguments passed to methods.}

\item{summary_fun}{Optional function to summarize the activation pattern matrix rows. Default NULL uses L2 norm.}
}
\value{
A numeric vector of length P with per-feature importance scores,
  or \code{NULL} if importance is not available for this model class.
}
\description{
Generic function that extracts a per-feature importance vector from a fitted
model object.
}
\details{
The importance measure returned depends on the model class:

\describe{
  \item{\strong{SDA / glmnet (linear models)}}{Computes Haufe et al. (2014)
    \emph{forward-model} activation patterns: A = Sigma_x * W * inv(W' Sigma_x W).
    The returned vector is the L2 norm (or custom \code{summary_fun}) of the
    rows of A.
    This is the recommended importance measure for neuroscience interpretation
    because it reflects where the neural signal originates, not merely which
    features carry discriminative weight.}
  \item{\strong{randomForest}}{Returns MeanDecreaseGini (or MeanDecreaseAccuracy
    when available).
    This is a \strong{backward} (decoding) measure and is \strong{not}
    Haufe-safe: suppressor variables that reduce node impurity without
    carrying neural signal will receive high importance.
    Use \code{\link{region_importance}} for a slower but more robust
    backward measure that is bounded by out-of-sample performance, or
    restrict neuroscience interpretation to linear models with Haufe-based
    importance.}
  \item{\strong{default}}{Returns \code{NULL}, signaling that no importance
    is available for the model class.}
}

\code{model_importance.randomForest} returns Gini-based importance
(MeanDecreaseGini) by default, or permutation-based importance
(MeanDecreaseAccuracy) when the forest was trained with
\code{importance = TRUE}.
Both are \strong{backward} (decoding) measures and may assign high
importance to suppressor variables that do not carry neural signal.
For neuroscience interpretation, prefer \code{\link{haufe_importance}}
with a linear model or use \code{\link{region_importance}} for a
model-agnostic alternative bounded by out-of-sample performance.
}
\examples{
\donttest{
  ds <- gen_sample_dataset(c(5,5,5), 40, nlevels=2)
  mdl <- load_model("sda_notune")
  mspec <- mvpa_model(mdl, ds$dataset, ds$design, "classification")
  vox <- which(ds$dataset$mask > 0)
  X <- neuroim2::series(ds$dataset$train_data, vox)
  fit <- train_model(mspec, X, ds$design$y_train, indices=vox)
  imp <- model_importance(fit, X)
}
}
