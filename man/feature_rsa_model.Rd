% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/feature_rsa_model.R
\name{feature_rsa_model}
\alias{feature_rsa_model}
\title{Create a Feature-Based RSA Model}
\usage{
feature_rsa_model(
  dataset,
  design,
  method = c("pls", "pca", "glmnet"),
  crossval = NULL,
  ncomp_selection = c("loo", "max", "pve"),
  pve_threshold = 0.9,
  alpha = 0.5,
  cv_glmnet = FALSE,
  lambda = NULL,
  nperm = 0,
  permute_by = c("features", "observations"),
  save_distributions = FALSE,
  ...
)
}
\arguments{
\item{dataset}{An \code{mvpa_dataset} object containing the neural data (\code{X}).}

\item{design}{A \code{feature_rsa_design} object specifying the feature space (\code{F})
and including the component limit (`max_comps`).}

\item{method}{Character string specifying the analysis method. One of:
\describe{
  \item{pls}{Partial Least Squares regression predicting X from F (via \code{pls::plsr}).}
  \item{pca}{Principal Component Regression predicting X from PCs of F (via \code{pls::pcr}).}
  \item{glmnet}{Elastic net regression predicting X from F using glmnet with multivariate Gaussian response.}
}}

\item{crossval}{Optional cross-validation specification.}

\item{ncomp_selection}{Character string controlling how the number of components
is chosen for \code{pls} and \code{pca} methods. One of:
\describe{
\item{loo}{(Default) Fit with leave-one-out validation and select the
fewest components within one standard error of the minimum RMSEP
(\code{pls::selectNcomp}, method \code{"onesigma"}).}
\item{pve}{Keep the fewest components whose cumulative explained
variance reaches \code{pve_threshold} of the total explained by all
fitted components.}
\item{max}{Use all \code{max_comps} components (legacy behaviour).}
}
Ignored when \code{method = "glmnet"}.}

\item{pve_threshold}{Numeric in (0, 1]. When \code{ncomp_selection = "pve"},
the proportion of total explained X-variance at which to stop adding
components. Default 0.9.}

\item{alpha}{Numeric value between 0 and 1, only used when method="glmnet". Controls the elastic net
mixing parameter: 1 for lasso (default), 0 for ridge, values in between for a mixture.
Defaults to 0.5 (equal mix of ridge and lasso).}

\item{cv_glmnet}{Logical, if TRUE and method="glmnet", use cv.glmnet to automatically select the
optimal lambda value via cross-validation. Defaults to FALSE.}

\item{lambda}{Optional numeric value or sequence of values, only used when method="glmnet" and
cv_glmnet=FALSE. Specifies the regularization parameter. If NULL (default), a sequence will be 
automatically determined by glmnet.}

\item{nperm}{Integer, number of permutations to run for statistical testing of model performance
metrics after merging cross-validation folds. Default 0 (no permutation testing).}

\item{permute_by}{DEPRECATED. Permutation is always done by shuffling rows of the predicted matrix.}

\item{save_distributions}{Logical, if TRUE and nperm > 0, save the full null distributions
from the permutation test. Defaults to FALSE.}

\item{...}{Additional arguments (currently unused). Passing deprecated
arguments such as \code{cache_pca} now results in an error.}
}
\value{
A \code{feature_rsa_model} object (S3 class).
}
\description{
Creates a model for feature-based Representational Similarity Analysis (RSA) that relates neural patterns
(X) to a predefined feature space (F).
}
\details{
Feature RSA models analyze how well a feature matrix \code{F} (defined in the `design`)
relates to neural data \code{X}. The `max_comps` parameter, inherited from the `design` object,
sets an upper limit on the number of components fitted:
  - \strong{pls}: PLS regression via \code{pls::plsr}. Fits up to `max_comps` components;
    the actual number used for prediction is chosen by \code{ncomp_selection}.
  - \strong{pca}: Principal Component Regression via \code{pls::pcr}. Fits up to
    `max_comps` components; selection controlled by \code{ncomp_selection}.
  - \strong{glmnet}: Elastic net regression via \code{glmnet} with multivariate Gaussian
    response. Regularisation (lambda) can be auto-selected via \code{cv_glmnet=TRUE}.

For \code{pls} and \code{pca}, the \code{ncomp_selection} argument determines how many
of the fitted components are actually used for prediction. The default
(\code{"loo"}) fits the model with leave-one-out cross-validation and picks
the fewest components within one SE of the minimum RMSEP.

\strong{Performance Metrics} (computed by \code{evaluate_model} after cross-validation):

Condition-pattern metrics (trial x trial correlation matrix):
  - \code{pattern_correlation}: Average correlation between the predicted and observed
    spatial patterns for corresponding trials (diagonal of the trial x trial
    correlation matrix computed across voxels).
  - \code{pattern_discrimination}: \code{pattern_correlation} minus the mean off-diagonal
    correlation. Measures how much better the model predicts the correct trial's
    pattern compared to incorrect trials.
  - \code{pattern_rank_percentile}: For each trial, percentile rank of the correct
    pattern match among all candidates. 0.5 = chance, 1 = perfect.

Global reconstruction metrics:
  - \code{voxel_correlation}: Correlation of the flattened predicted and observed
    matrices (all trials x all voxels).
  - \code{mse}: Mean Squared Error.
  - \code{r_squared}: 1 - RSS/TSS.

Voxel encoding fidelity:
  - \code{mean_voxelwise_temporal_cor}: Average per-voxel temporal correlation
    between predicted and observed time courses.

  - \code{p_*}, \code{z_*}: If \code{nperm > 0}, permutation-based p-values and z-scores for
    the above metrics.

The number of components actually used (\code{ncomp}) for the region/searchlight is
also included in the performance output.
}
