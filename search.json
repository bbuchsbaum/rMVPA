[{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"project-overview","dir":"","previous_headings":"","what":"Project Overview","title":"CLAUDE.md","text":"rMVPA R package Multivoxel Pattern Analysis (MVPA) neuroimaging data. provides infrastructure machine learning analyses neuroimaging datasets, supporting programmatic R usage command-line interfaces.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"building-and-testing","dir":"","previous_headings":"Common Development Tasks","what":"Building and Testing","title":"CLAUDE.md","text":"","code":"# Install package locally R CMD INSTALL .  # Run R CMD check R CMD check .  # Run specific tests Rscript -e \"testthat::test_file('tests/testthat/test_mvpa_searchlight.R')\"  # Run all tests Rscript -e \"testthat::test_local()\"  # Build documentation Rscript -e \"devtools::document()\"  # Build vignettes Rscript -e \"devtools::build_vignettes()\"  # Install with dependencies Rscript -e \"devtools::install(dependencies = TRUE)\""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"linting-and-code-quality","dir":"","previous_headings":"Common Development Tasks","what":"Linting and Code Quality","title":"CLAUDE.md","text":"","code":"# Run lintr (if available) Rscript -e \"lintr::lint_package()\"  # Check code coverage Rscript -e \"covr::package_coverage()\""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"core-design-patterns","dir":"","previous_headings":"High-Level Architecture","what":"Core Design Patterns","title":"CLAUDE.md","text":"S3 Object System: package uses S3 classes extensively model types (mvpa_model, rsa_model, contrast_rsa_model, etc.) generic functions (train_model, predict_model, performance). Model Registry: machine learning models stored MVPAModels environment (R/classifiers.R). Models follow standard interface: type: “Classification” “Regression” library: Required packages parameters: Tunable hyperparameters grid: Function generate parameter grids fit: Model training function predict: Prediction function prob: Probability estimation (classification) Analysis Workflows: Two main analysis approaches: Regional: Analyzes specific brain regions (ROIs) Searchlight: Sliding sphere analysis across brain Cross-validation Infrastructure: Custom cross-validation system R/crossval.R supports various schemes (k-fold, blocked, bootstrap).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"key-components","dir":"","previous_headings":"High-Level Architecture","what":"Key Components","title":"CLAUDE.md","text":"Data Structures: mvpa_dataset: Core data container neuroimaging data, labels, metadata mvpa_design: Experimental design specification Model-specific designs: rsa_design, manova_design, feature_rsa_design Model Types: Standard MVPA: Classification/regression models RSA (Representational Similarity Analysis): Multiple variants MANOVA: Multivariate ANOVA MS-ReVE: Multi-Scale Representational Variance Explained (contrast_rsa_model.R) Feature Selection: Modular system supporting F-test, categorical scores, custom methods Performance Metrics: Extensible performance evaluation supporting accuracy, AUC, RMSE, R², custom metrics","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"important-ongoing-work","dir":"","previous_headings":"High-Level Architecture","what":"Important Ongoing Work","title":"CLAUDE.md","text":"Caret Removal: package undergoing major refactoring remove caret dependency (see caret_removal_plan.md). Key changes: - Replacing caret::train custom tuning loops using rsample yardstick - Model loading now exclusively uses internal MVPAModels registry - Performance metrics transitioning caret yardstick functions Current branch remaining-codex-integration contains work--progress changes.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"command-line-scripts","dir":"","previous_headings":"High-Level Architecture","what":"Command Line Scripts","title":"CLAUDE.md","text":"scripts/ directory contains CLI tools: - MVPA_Searchlight.R: Searchlight analysis - MVPA_Regional.R: Regional/ROI analysis - MVPA_Cluster.R: Cluster-based analysis - MVPA_Predict.R: Prediction new data","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"testing-infrastructure","dir":"","previous_headings":"High-Level Architecture","what":"Testing Infrastructure","title":"CLAUDE.md","text":"Comprehensive test suite tests/testthat/ Tests organized functionality (searchlight, regional, RSA, etc.) Mock CV specifications helper helper-mock_cv_spec.R GitHub Actions CI runs R CMD check multiple platforms","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"key-dependencies","dir":"","previous_headings":"High-Level Architecture","what":"Key Dependencies","title":"CLAUDE.md","text":"Neuroimaging: neuroim2, neurosurf (custom packages author) Machine Learning: rsample (resampling), yardstick (metrics) tidymodels ecosystem Data Manipulation: dplyr, purrr, tibble Parallel Processing: future, future.apply, furrr Statistical Models: glmnet, sda, randomForest, e1071","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"model-registry-mvpamodels","dir":"","previous_headings":"High-Level Architecture","what":"Model Registry (MVPAModels)","title":"CLAUDE.md","text":"package uses centralized model registry called MVPAModels (environment R/classifiers.R). built-models registered consistent structure: type: “Classification” “Regression” library: Required R packages model label: Display name parameters: data.frame tunable parameters grid: Function generate parameter tuning grid fit: Function train model predict: Function predictions prob: Function class probabilities (classification ) Loading models: Use load_model(name) retrieve model specification Custom models: Use register_mvpa_model(name, spec) add new models","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/CLAUDE.html","id":"development-notes","dir":"","previous_headings":"High-Level Architecture","what":"Development Notes","title":"CLAUDE.md","text":"package heavily uses functional programming patterns purrr Parallel processing handled future framework Logging via futile.logger debugging MS-ReVE functionality R/contrast_rsa_model.R (contrast_rsa.R) package longer depends caret - model management handled internally Commonly used caret models (rf, spls, etc.) extracted adapted R/caret_models.R Model aliases exist backward compatibility: sda → sda_notune, glmnet → glmnet_opt","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"standard Representational Similarity Analysis (RSA) compares neural patterns model-based similarity structures, cases specialized approaches needed. rMVPA package provides two advanced RSA methods: Feature-Based RSA: Projects neural patterns predefined feature space Vector-Based RSA: Directly compares vectorized distance matrices vignette explains use specialized approaches instead standard RSA.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"overview","dir":"Articles","previous_headings":"Feature-Based RSA","what":"Overview","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Feature-Based RSA designed cases : rich feature space describing stimuli want directly map neural patterns features ’re interested reconstructing stimulus features neural patterns Unlike standard RSA compares similarity matrices, Feature-Based RSA attempts find mapping neural patterns feature space.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"key-differences-from-standard-rsa","dir":"Articles","previous_headings":"Feature-Based RSA","what":"Key Differences from Standard RSA","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Standard RSA: Compares similarity structures Feature RSA: Maps neural patterns feature dimensions Standard RSA: Correlation/regression coefficients RDMs Feature RSA: Predicted feature values stimulus Standard RSA: Testing theoretical models representation Feature RSA: Reconstructing stimulus features brain activity","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"implementation-example","dir":"Articles","previous_headings":"Feature-Based RSA","what":"Implementation Example","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Let’s walk complete example:","code":"# Generate a synthetic dataset with dimensions 6x6x6, 50 observations, divided into 4 blocks # This ensures that the number of trials matches the number of stimuli used below data_out <- rMVPA::gen_sample_dataset(D = c(6,6,6), nobs = 50, blocks = 4, nlevels = 2) print(data_out) ## $dataset ##  ##  █▀▀ MVPA Dataset ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Dimensions:  6 × 6 × 6 × 50 observations  ## │  └─ Type:  DenseNeuroVec  ## ├─ Test Data  ## │  └─  None  ## └─ Mask Information  ##    ├─ Areas:  1 : 120  ##    └─ Active voxels/vertices:  120  ##  ##  ## $design ##  ##  █▀▀ MVPA Design ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Observations:  50  ## │  ├─ Response Type:  Factor ## │  ├─ Levels:  a, b  ## │  └─ Class Distribution:  a: 25, b: 25  ## ├─ Test Data  ## │  └─  None  ## └─ Structure  ##    ├─ Blocking:  Present ##    ├─ Number of Blocks:  4  ##    ├─ Mean Block Size:  12  (SD:  0.58 )  ##    └─ Split Groups:  None # Generate synthetic feature space (e.g., visual features of stimuli) set.seed(123) n_stimuli <- 50 n_features <- 5  # Create feature matrix (stimuli × features) feature_matrix <- matrix(rnorm(n_stimuli * n_features), n_stimuli, n_features) colnames(feature_matrix) <- paste0(\"feature_\", 1:n_features)  # Create stimulus labels stim_labels <- paste0(\"stim_\", 1:n_stimuli)  # Create feature RSA design feature_design <- feature_rsa_design(   F = feature_matrix,  # Direct feature matrix   labels = stim_labels )  # Create MVPA dataset from the generated data dset <- mvpa_dataset(data_out$dataset$train_data, mask = data_out$dataset$mask)  # Create cross-validation structure using the block information crossval <- blocked_cross_validation(data_out$design$block_var)  # Create feature RSA model feature_model <- feature_rsa_model(   dataset = dset,   design = feature_design,   method = \"pls\",  # Partial Least Squares   crossval = crossval  # Add cross-validation )  # Create proper region mask from the dataset's mask mask_vol <- data_out$dataset$mask nvox <- sum(mask_vol) region_mask <- neuroim2::NeuroVol(   sample(1:3, size = nvox, replace = TRUE),  # 3 regions   space(mask_vol),   indices = which(mask_vol > 0) )  # Run regional analysis results <- run_regional(feature_model, region_mask) ## INFO [2025-09-27 21:50:59]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 # Examine results print(results$performance_table) ## # A tibble: 3 × 10 ##   roinum mean_correlation cor_difference mean_rank_percentile voxel_correlation ##    <int>            <dbl>          <dbl>                <dbl>             <dbl> ## 1      1          -0.0652        -0.0656                0.399          -0.00515 ## 2      2          -0.109         -0.112                 0.314          -0.0593  ## 3      3          -0.0693        -0.0687                0.383          -0.00189 ## # ℹ 5 more variables: mse <dbl>, r_squared <dbl>, cor_temporal_means <dbl>, ## #   mean_voxelwise_temporal_cor <dbl>, ncomp <dbl>"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"available-methods","dir":"Articles","previous_headings":"Feature-Based RSA","what":"Available Methods","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Feature-Based RSA supports multiple analysis methods: Finds latent components maximize covariance neural patterns features Good prediction features highly correlated Uses PCA features followed regression Good dimensionality reduction clear interpretability Elastic net regression L1 L2 regularization Useful feature selection handling correlated features","code":"# Compare different methods methods <- c(\"pls\", \"pca\", \"glmnet\") results_list <- lapply(methods, function(method) {   model <- feature_rsa_model(     dataset = dset,     design = feature_design,     method = method,     crossval = crossval  # Add cross-validation   )   run_regional(model, region_mask) }) ## INFO [2025-09-27 21:51:03]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:51:06]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## WARN [2025-09-27 21:51:07] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:07] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:07] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:07] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:07] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:07] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:07] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:07] Correlation difference is NA/NaN. ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## WARN [2025-09-27 21:51:08] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:08] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:09] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:09] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:09] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:09] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:09] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:09] Correlation difference is NA/NaN. ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## WARN [2025-09-27 21:51:10] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:10] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:10] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:10] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:10] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:10] Correlation difference is NA/NaN. ## WARN [2025-09-27 21:51:11] Mean correlation is NA/NaN. ## WARN [2025-09-27 21:51:11] Correlation difference is NA/NaN. ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in evaluate_model.feature_rsa_model(object = obj, predicted = Xpred, : ## evaluate_model: Predictions or observed data have zero variance in some ## columns. Correlation metrics may be NA. ## Warning in cor(predicted, observed): the standard deviation is zero ## Warning in cor(mean_obs_across_space, mean_pred_across_space): the standard ## deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## Warning in cor(observed[, i], predicted[, i]): the standard deviation is zero ## INFO [2025-09-27 21:51:11]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 # Compare performance for (i in seq_along(methods)) {   cat(\"\\nMethod:\", methods[i], \"\\n\")   print(results_list[[i]]$performance_table) } ##  ## Method: pls  ## # A tibble: 3 × 10 ##   roinum mean_correlation cor_difference mean_rank_percentile voxel_correlation ##    <int>            <dbl>          <dbl>                <dbl>             <dbl> ## 1      1          -0.0652        -0.0656                0.399          -0.00515 ## 2      2          -0.109         -0.112                 0.314          -0.0593  ## 3      3          -0.0693        -0.0687                0.383          -0.00189 ## # ℹ 5 more variables: mse <dbl>, r_squared <dbl>, cor_temporal_means <dbl>, ## #   mean_voxelwise_temporal_cor <dbl>, ncomp <dbl> ##  ## Method: pca  ## # A tibble: 3 × 10 ##   roinum mean_correlation cor_difference mean_rank_percentile voxel_correlation ##    <int>            <dbl>          <dbl>                <dbl>             <dbl> ## 1      1          -0.0652        -0.0656                0.399          -0.00515 ## 2      2          -0.109         -0.112                 0.314          -0.0593  ## 3      3          -0.0693        -0.0687                0.383          -0.00189 ## # ℹ 5 more variables: mse <dbl>, r_squared <dbl>, cor_temporal_means <dbl>, ## #   mean_voxelwise_temporal_cor <dbl>, ncomp <dbl> ##  ## Method: glmnet  ## # A tibble: 3 × 10 ##   roinum mean_correlation cor_difference mean_rank_percentile voxel_correlation ##    <int>            <dbl>          <dbl>                <dbl>             <dbl> ## 1      1           -0.236         -0.237               0.0850           -0.0580 ## 2      2           -0.215         -0.211               0.107            -0.0245 ## 3      3           -0.208         -0.200               0.106            -0.0117 ## # ℹ 5 more variables: mse <dbl>, r_squared <dbl>, cor_temporal_means <dbl>, ## #   mean_voxelwise_temporal_cor <dbl>, ncomp <dbl>"},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"overview-1","dir":"Articles","previous_headings":"Vector-Based RSA","what":"Overview","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Vector-Based RSA designed cases : pre-computed distance matrices want compare across-block distances need efficient computation large datasets Unlike standard RSA works full similarity matrices, Vector-Based RSA operates vectorized distance matrices can efficiently handle block structure.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"key-differences-from-standard-rsa-1","dir":"Articles","previous_headings":"Vector-Based RSA","what":"Key Differences from Standard RSA","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Standard RSA: Works full similarity matrices Vector RSA: Works vectorized distances Standard RSA: Manual block exclusion Vector RSA: Built-efficient block handling Standard RSA: Stores full matrices Vector RSA: Stores necessary comparisons","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"implementation-example-1","dir":"Articles","previous_headings":"Vector-Based RSA","what":"Implementation Example","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"","code":"# Create distance matrix for stimuli stim_distances <- as.matrix(dist(feature_matrix)) rownames(stim_distances) <- stim_labels  # Create block structure (e.g., runs) blocks <- rep(1:5, length.out = n_stimuli)  # Create vector RSA design vector_design <- vector_rsa_design(     D = stim_distances,     labels = stim_labels,     block_var = blocks )  # Create vector RSA model vector_model <- vector_rsa_model(   dataset = dset,   design = vector_design,   distfun = cordist(),  # Correlation distance   rsa_simfun = \"pearson\" )  # Run analysis results_vector <- run_regional(vector_model, region_mask) ## INFO [2025-09-27 21:51:15]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 # Examine results print(results_vector$performance_table) ## # A tibble: 3 × 2 ##   roinum rsa_score ##    <int>     <dbl> ## 1      1  0.00948  ## 2      2 -0.0467   ## 3      3  0.000723"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"efficient-block-handling","dir":"Articles","previous_headings":"Vector-Based RSA","what":"Efficient Block Handling","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Vector-Based RSA automatically handles block structure:","code":"# Compare with different block structures block_sizes <- c(5, 10) results_blocks <- lapply(block_sizes, function(size) {   blocks <- rep(1:(n_stimuli/size), each = size)   design <- vector_rsa_design(     D = stim_distances,     labels = stim_labels,     block_var = blocks   )   model <- vector_rsa_model(     dataset = dset,     design = design,     distfun = cordist()   )   run_regional(model, region_mask) }) ## INFO [2025-09-27 21:51:18]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:51:21]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 # Compare results for (i in seq_along(block_sizes)) {   cat(\"\\nBlock size:\", block_sizes[i], \"\\n\")   print(results_blocks[[i]]$performance_table) } ##  ## Block size: 5  ## # A tibble: 3 × 2 ##   roinum rsa_score ##    <int>     <dbl> ## 1      1  -0.0185  ## 2      2  -0.0450  ## 3      3   0.00323 ##  ## Block size: 10  ## # A tibble: 3 × 2 ##   roinum rsa_score ##    <int>     <dbl> ## 1      1  -0.0192  ## 2      2  -0.0377  ## 3      3   0.00519"},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"feature-based-rsa-1","dir":"Articles","previous_headings":"When to Use Each Method","what":"Feature-Based RSA","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Feature-Based RSA appropriate working well-defined feature space dimensions meaningful interpretations. approach excels reconstructing predicting specific stimulus features neural activity patterns. Common applications include predicting visual features visual cortex responses, reconstructing semantic dimensions language area activity, mapping motion parameters MT/V5 activation patterns.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"vector-based-rsa-1","dir":"Articles","previous_headings":"When to Use Each Method","what":"Vector-Based RSA","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Vector-Based RSA ideal analyzing large datasets pre-computed distance matrices. handles memory efficiently provides sophisticated block handling capabilities. makes particularly valuable comparing across multiple experimental runs, working high-resolution fMRI data, analyzing large-scale similarity structures.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"standard-rsa","dir":"Articles","previous_headings":"When to Use Each Method","what":"Standard RSA","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"Stick standard RSA : - ’re testing theoretical models - want compare similarity structures - Block structure isn’t critical - Memory usage isn’t concern","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Advanced_RSA.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Advanced RSA Methods: Feature-Based and Vector-Based Approaches","text":"rMVPA package provides three complementary RSA approaches: Standard RSA: General-purpose similarity analysis Feature-Based RSA: Direct feature mapping reconstruction Vector-Based RSA: Efficient similarity comparison block handling choice RSA method align research goals, match data’s structure, fit within computational constraints, reflect whether ’re analyzing feature spaces similarity patterns. implementation details, refer : - feature_rsa_model.R - vector_rsa_model.R - rsa_model.R","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"MVPA Searchlight Tutorial","text":"tutorial explains run searchlight-based Multivariate Pattern Analysis (MVPA) using MVPA_Searchlight.R. script performs local classification regression analysis fMRI data iterating voxel (node surface data) extracting information surrounding neighborhood.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"key-features","dir":"Articles","previous_headings":"Introduction","what":"Key Features:","title":"MVPA Searchlight Tutorial","text":"script handles volumetric (NIfTI) surface-based neuroimaging data. leverages parallel processing across multiple cores faster computation. can choose various classifiers regressors like rf, sda_notune, corsim. analysis generates reproducible outputs including config files metric maps. Cross-validation options include blocked stratified approaches. Data can optionally normalized centering scaling. script supports different feature selection methods works seamlessly volumetric surface-based analyses.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"basic-usage","dir":"Articles","previous_headings":"Running the Script","what":"1. Basic Usage","title":"MVPA Searchlight Tutorial","text":": 4D fMRI file training: train_data.nii trial--trial design matrix: train_design.txt brain mask file: mask.nii can run script command line:","code":"MVPA_Searchlight.R --radius=6 \\                            --train_design=train_design.txt \\                            --train_data=train_data.nii \\                            --mask=mask.nii \\                            --model=sda_notune \\                            --label_column=condition \\                            --ncores=4 \\                            --output=my_searchlight_output"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"understanding-data-modes","dir":"Articles","previous_headings":"Running the Script","what":"2. Understanding Data Modes","title":"MVPA Searchlight Tutorial","text":"script supports two primary data modes:","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"image-mode-volumetric-data","dir":"Articles","previous_headings":"Running the Script > 2. Understanding Data Modes","what":"Image Mode (Volumetric Data)","title":"MVPA Searchlight Tutorial","text":"Default mode (--data_mode=image) Works NIfTI format files Requires binary mask file Processes voxel-wise data 3D space","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"surface-mode","dir":"Articles","previous_headings":"Running the Script > 2. Understanding Data Modes","what":"Surface Mode","title":"MVPA Searchlight Tutorial","text":"Activated --data_mode=surface Works surface-based neuroimaging data Can handle multiple surface sections Processes data cortical surface meshes","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"available-models","dir":"Articles","previous_headings":"Running the Script","what":"3. Available Models","title":"MVPA Searchlight Tutorial","text":"script supports various classification regression models:","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"built-in-mvpa-models","dir":"Articles","previous_headings":"Running the Script > 3. Available Models","what":"Built-in MVPA Models:","title":"MVPA Searchlight Tutorial","text":"corclass: Correlation-based classifier template matching sda_notune: Simple Shrinkage Discriminant Analysis without tuning sda_boot: SDA bootstrap resampling glmnet_opt: Elastic net EPSGO parameter optimization sparse_sda: SDA sparsity constraints sda_ranking: SDA automatic feature ranking mgsda: Multi-Group Sparse Discriminant Analysis lda_thomaz: Modified LDA high-dimensional data hdrda: High-Dimensional Regularized Discriminant Analysis","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"additional-models","dir":"Articles","previous_headings":"Running the Script > 3. Available Models","what":"Additional Models:","title":"MVPA Searchlight Tutorial","text":"Custom models can registered using register_mvpa_model()","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"cross-validation-options","dir":"Articles","previous_headings":"Running the Script","what":"4. Cross-Validation Options","title":"MVPA Searchlight Tutorial","text":"script supports multiple cross-validation strategies:","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"blocked-cross-validation","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"Blocked Cross-Validation","title":"MVPA Searchlight Tutorial","text":"Uses blocking variable (e.g., session) cross-validation splits.","code":"--block_column=session"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"k-fold-cross-validation","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"K-Fold Cross-Validation","title":"MVPA Searchlight Tutorial","text":"Default block column specified. Uses random splits.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"two-fold-cross-validation","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"Two-Fold Cross-Validation","title":"MVPA Searchlight Tutorial","text":"Specify configuration file:","code":"cross_validation:   name: \"twofold\"   nreps: 10"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"advanced-cross-validation-methods","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"Advanced Cross-Validation Methods","title":"MVPA Searchlight Tutorial","text":"addition standard options , several advanced cross-validation strategies available: Blocked Cross-Validation: Divides dataset based blocking variable (e.g., session) samples block remain together. K-Fold Cross-Validation: Randomly partitions data k folds, providing robust estimate model performance. Bootstrap Blocked Cross-Validation: Generates bootstrap resamples within blocks assess model stability heterogeneous datasets. Sequential Blocked Cross-Validation: Assigns sequential folds within block, preserving temporal ordered structures. Custom Cross-Validation: Allows define custom training testing splits standard methods fit experimental design. Specify desired method configuration file setting name field cross_validation. example, use bootstrap blocked cross-validation: Choose method best aligns data structure experimental design.","code":"cross_validation:   name: \"bootstrap\"   # Options: \"twofold\", \"bootstrap\", \"sequential\", \"custom\", \"kfold\"   nreps: 10"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"feature-selection","dir":"Articles","previous_headings":"Running the Script","what":"5. Feature Selection","title":"MVPA Searchlight Tutorial","text":"Enable feature selection --feature_selector parameter:","code":"feature_selector:   method: \"anova\"  # or \"correlation\", \"t-test\", etc.   cutoff_type: \"percentile\"   cutoff_value: 0.1"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"understanding-label_column","dir":"Articles","previous_headings":"Running the Script","what":"6. Understanding label_column","title":"MVPA Searchlight Tutorial","text":"label column critical specifies target variable classification regression. performing classification, column contain categorical labels (e.g., \"Face\" vs. \"House\"). performing regression, column contain continuous values (e.g., reaction times, confidence ratings). Example Design File (train_design.txt):","code":"trial  condition  subject  session 1      Face       S01      1 2      House      S01      1 3      Face       S01      1 4      House      S01      1 5      Face       S01      2"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"using-a-configuration-file","dir":"Articles","previous_headings":"Running the Script","what":"7. Using a Configuration File","title":"MVPA Searchlight Tutorial","text":"Instead specifying options command line, can use YAML R script configuration file. Example YAML Config File (config.yaml): Running Config File:","code":"# Data Sources train_design: \"train_design.txt\" test_design: \"test_design.txt\" train_data: \"train_data.nii\" test_data: \"test_data.nii\" mask: \"mask.nii\"  # Analysis Parameters model: \"rf\"  # Random Forest classifier data_mode: \"image\"  # or \"surface\" ncores: 4 radius: 6 label_column: \"condition\" block_column: \"session\"  # Output Options output: \"searchlight_results\" normalize_samples: TRUE class_metrics: TRUE  # Advanced Options feature_selector:   method: \"anova\"   cutoff_type: \"percentile\"   cutoff_value: 0.1  cross_validation:   name: \"twofold\"   nreps: 10  # Optional Subsetting train_subset: \"subject == 'S01'\" test_subset: \"subject == 'S02'\" Rscript MVPA_Searchlight.R --config=config.yaml"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"expected-outputs","dir":"Articles","previous_headings":"Running the Script","what":"8. Expected Outputs","title":"MVPA Searchlight Tutorial","text":"running script, output directory (searchlight_results/) contains: accuracy.nii: Overall classification accuracy map auc.nii: Area Curve (AUC) performance map auc_class1.nii, auc_class2.nii, etc.: Per-class AUC maps prob_observed.nii: Probabilities observed classes prob_predicted.nii: Probabilities predicted classes config.yaml: Complete record analysis parameters reproducibility Example directory structure: exact files depend : - Whether ’s binary multiclass classification - class_metrics: TRUE set - type analysis (classification vs regression) - model type used regression analyses, ’ll see different metrics: - r2.nii: R-squared values - rmse.nii: Root Mean Square Error - spearcor.nii: Spearman correlation","code":"searchlight_results/ ├── accuracy.nii          # Overall classification accuracy ├── auc.nii              # Mean AUC across classes ├── auc_class1.nii       # AUC for class 1 (if class_metrics: TRUE) ├── auc_class2.nii       # AUC for class 2 (if class_metrics: TRUE) ├── prob_observed.nii    # Probabilities for observed classes ├── prob_predicted.nii   # Probabilities for predicted classes └── config.yaml          # Analysis configuration"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"performance-considerations","dir":"Articles","previous_headings":"Running the Script","what":"9. Performance Considerations","title":"MVPA Searchlight Tutorial","text":"Use --normalize_samples=TRUE better model performance Increase --ncores faster processing multi-core systems Adjust --radius based spatial resolution hypothesis Consider using --type=randomized faster approximate searchlights Set appropriate memory limits options(future.globals.maxSize)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CommandLineScripts.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"MVPA Searchlight Tutorial","text":"MVPA_Searchlight.R provides flexible searchlight-based MVPA tool works volumetric surface-based data. includes cross-validation, feature selection, extensive configuration command line config files. tool generates comprehensive metrics reproducible outputs help analyze neuroimaging data. Next Steps: - Try different models (--model=rf, --model=sda_notune) - Experiment feature selection methods - Explore surface-based MVPA --data_mode=surface - Use cross-validation strategies appropriate design - Optimize performance parallel processing Happy searchlighting!","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Constructing_Datasets.html","id":"creating-a-real-volumetric-image-based-dataset","dir":"Articles","previous_headings":"","what":"Creating a Real Volumetric (Image-Based) Dataset","title":"Constructing Datasets for MVPA Analysis","text":"example assumes 4D fMRI file (“bold.nii.gz”) corresponding 3D brain mask file (“mask.nii.gz”).","code":"library(neuroim2)  # Read the fMRI data as a NeuroVec object using neuroim2::read_vec train_neurovec <- neuroim2::read_vec(\"path/to/bold.nii.gz\", mode = \"normal\")  # Read the brain mask and create a NeuroVol object mask_vec <- neuroim2::read_vec(\"path/to/mask.nii.gz\", mode = \"normal\") mask_vol <- NeuroVol(as.array(mask_vec), NeuroSpace(dim(mask_vec), spacing = c(2, 2, 2)))  # Create the MVPA image dataset real_dataset <- mvpa_dataset(train_data = train_neurovec, mask = mask_vol)  # Display dataset details print(real_dataset)"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Constructing_Datasets.html","id":"creating-a-real-surface-based-dataset","dir":"Articles","previous_headings":"","what":"Creating a Real Surface-Based Dataset","title":"Constructing Datasets for MVPA Analysis","text":"example assumes cortical geometry stored file (e.g., “subject.lh.smoothwm.asc”) signal matrix CSV format (“surface_data.csv”). signal matrix dimensions corresponding number vertices number observations.","code":"## remotes::install_github(\"bbuchsbaum/neurosurf\") library(neurosurf)  # Load the cortical geometry geom <- read_surf_geometry(\"path/to/subject.lh.smoothwm.asc\")  # Read the surface data from a CSV file # The CSV should not have a header and have dimensions: number of vertices x number of observations data_matrix <- as.matrix(read.csv(\"path/to/surface_data.csv\", header = FALSE))  # Verify that the number of rows in the data matches the geometry nvert <- nrow(neurosurf::vertices(geom)) if(nrow(data_matrix) != nvert) {   stop(\"The number of vertices in the data does not match the geometry.\") }  # Create a NeuroSurfaceVector using the geometry and the data matrix real_neurosurf <- NeuroSurfaceVector(geom, 1:nvert, data_matrix)  # Create the MVPA surface dataset; if no mask is provided, one is generated automatically real_surface_dataset <- mvpa_surface_dataset(train_data = real_neurosurf, name = \"lh\")  # Display dataset details print(real_surface_dataset)"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Constructing_Datasets.html","id":"notes","dir":"Articles","previous_headings":"","what":"Notes","title":"Constructing Datasets for MVPA Analysis","text":"volumetric datasets, NeuroSpace object used define dimensions voxel spacing. surface datasets, ensure signal matrix cortical geometry compatible. Replace file paths actual paths real data files running code.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Contrast RSA with contrast_rsa_model","text":"contrast_rsa_model() implements Multi-Dimensional Signed Representational Voxel Encoding (MS-ReVE) approach. relates voxel patterns set predefined contrasts produces maps summarize contrast contributes local representational geometry. vignette walks minimal example explains available output metrics.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"example-setup","dir":"Articles","previous_headings":"","what":"Example setup","title":"Contrast RSA with contrast_rsa_model","text":"start generating small example dataset defining two contrasts. contrasts column centered positive values indicate conditions pull voxels one direction negative values pull opposite direction. Next create model specification run tiny searchlight volume. request default \"beta_delta\" metric.","code":"# Generate dummy dataset (small 6x6x6 volume, 32 samples) set.seed(42) data_info <- gen_sample_dataset(D = c(6,6,6), nobs = 32, blocks = 4)  # mvpa_dataset object mvpa_dat <- data_info$dataset  # Design with two simple contrasts across four conditions K <- nresponses(data_info$design) C_mat <- matrix(0, nrow = K, ncol = 2) rownames(C_mat) <- levels(data_info$design$y_train) C_mat[1:2,1] <- 1; C_mat[3:4,1] <- -1 C_mat[1,2] <- 1; C_mat[2,2] <- -1 C_mat <- base::scale(C_mat, center = TRUE, scale = FALSE) colnames(C_mat) <- c(\"AB_vs_CD\", \"A_vs_B\")  ms_des <- msreve_design(data_info$design, contrast_matrix = C_mat) cv_spec <- blocked_cross_validation(data_info$design$block_var)  model_spec <- contrast_rsa_model(   dataset = mvpa_dat,   design = ms_des,   output_metric = \"beta_delta\",   check_collinearity = FALSE,   cv_spec = cv_spec )  # Run a very small searchlight iterator slight <- get_searchlight(model_spec$dataset, type = \"standard\", radius = 2) center_indices <- which(model_spec$dataset$mask > 0) iter_res <- mvpa_iterate(model_spec, slight, center_indices, analysis_type = \"searchlight\") ## INFO [2025-09-27 21:51:29] ⚡ Processing batch 1/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:30] ⚡ Processing batch 2/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:31] ⚡ Processing batch 3/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:32] ⚡ Processing batch 4/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:33] ⚡ Processing batch 5/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:34] ⚡ Processing batch 6/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:36] ⚡ Processing batch 7/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:37] ⚡ Processing batch 8/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:38] ⚡ Processing batch 9/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:39] ⚡ Processing batch 10/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:51:40]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 120 ## ├─ Processed: 120 ## └─ Skipped: 0 # Inspect the beta_delta metric for the first few centers preview_ids <- seq_len(min(5, nrow(iter_res))) preview_tbl <- do.call(rbind, lapply(preview_ids, function(idx) {   vals <- iter_res$performance[[idx]]$beta_delta   data.frame(     center_id = iter_res$id[idx],     contrast = names(vals),     beta_delta = as.numeric(vals),     row.names = NULL   ) })) preview_tbl ##    center_id contrast   beta_delta ## 1         22 AB_vs_CD -0.732517139 ## 2         22   A_vs_B -0.057170966 ## 3         45 AB_vs_CD -0.097480423 ## 4         45   A_vs_B -0.086342936 ## 5         46 AB_vs_CD -0.261304552 ## 6         46   A_vs_B  0.033916449 ## 7         47 AB_vs_CD -0.064381988 ## 8         47   A_vs_B  0.346159334 ## 9         50 AB_vs_CD  0.027530531 ## 10        50   A_vs_B -0.009356533"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"understanding-the-output-metrics","dir":"Articles","previous_headings":"","what":"Understanding the output metrics","title":"Contrast RSA with contrast_rsa_model","text":"contrast_rsa_model can return several metrics. Multiple metrics can requested returned named list searchlight location. main options :","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"beta_delta","dir":"Articles","previous_headings":"Understanding the output metrics","what":"beta_delta","title":"Contrast RSA with contrast_rsa_model","text":"product RSA regression coefficient (βq\\beta_q) voxel’s projection onto contrast (Δq,v\\Delta_{q,v}). signed quantity indicates strongly voxel supports representational difference captured contrast. Positive values mean voxel pattern aligns predicted direction; negative values indicate opposite.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"beta_only","dir":"Articles","previous_headings":"Understanding the output metrics","what":"beta_only","title":"Contrast RSA with contrast_rsa_model","text":"regression coefficients βq\\beta_q. Useful want map much contrast explains local RDM independent voxel projections.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"delta_only","dir":"Articles","previous_headings":"Understanding the output metrics","what":"delta_only","title":"Contrast RSA with contrast_rsa_model","text":"projection values Δq,v\\Delta_{q,v} . show raw contribution voxel contrast space weighting βq\\beta_q.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"recon_score","dir":"Articles","previous_headings":"Understanding the output metrics","what":"recon_score","title":"Contrast RSA with contrast_rsa_model","text":"single value (per voxel) measuring well voxel’s beta-weighted pattern reconstructs empirical RDM searchlight. Higher values indicate voxel individually informative multi-contrast representational structure.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"beta_delta_norm","dir":"Articles","previous_headings":"Understanding the output metrics","what":"beta_delta_norm","title":"Contrast RSA with contrast_rsa_model","text":"Like beta_delta using L2-normalized contribution vector. emphasizes direction contribution rather magnitude requires normalize_delta = TRUE constructing model.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"beta_delta_reliable","dir":"Articles","previous_headings":"Understanding the output metrics","what":"beta_delta_reliable","title":"Contrast RSA with contrast_rsa_model","text":"Reliability-weighted contributions ρq,vβqΔq,v\\rho_{q,v} \\beta_q \\Delta_{q,v}. weights ρq,v\\rho_{q,v} reflect stable voxel’s contributions across cross-validation folds, highlighting consistent effects.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"composite","dir":"Articles","previous_headings":"Understanding the output metrics","what":"composite","title":"Contrast RSA with contrast_rsa_model","text":"sum beta-weighted, normalized contributions across contrasts (∑qβqΔ̃q,v\\sum_q \\beta_q \\tilde{\\Delta}_{q,v}). “net pull” summarizes whether voxel overall favors positive negative side contrast space. Interpretation easiest contrast matrix orthonormal. metrics allow flexible interrogation voxel region participates specified representational contrasts.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Contrast_RSA.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Contrast RSA with contrast_rsa_model","text":"contrast_rsa_model extends standard RSA decomposing voxel contributions along user-defined contrasts. selecting appropriate output metrics can visualize beta weights, raw contributions, reliability-weighted effects, overall reconstruction quality. combination metrics provides rich picture representational landscape revealed analysis.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Cross-Validation Strategies in rMVPA","text":"Cross-validation critical component evaluating performance generalizability MVPA models. rMVPA package provides several cross-validation strategies specifically designed neuroimaging data, temporal structure run/block organization must carefully considered. vignette covers: - importance cross-validation MVPA - Available cross-validation schemes - implement scheme - Best practices considerations - Working examples","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"why-cross-validation-matters-in-mvpa","dir":"Articles","previous_headings":"Cross-Validation Fundamentals","what":"Why Cross-Validation Matters in MVPA","title":"Cross-Validation Strategies in rMVPA","text":"Cross-validation essential neuroimaging analyses. gives us unbiased estimates well models perform shows whether brain activity patterns truly generalize new data. separating training test sets, cross-validation prevents us overfitting noise data. also maintains temporal independence sets, crucial time-series neuroimaging data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"available-cross-validation-schemes","dir":"Articles","previous_headings":"Cross-Validation Fundamentals","what":"Available Cross-Validation Schemes","title":"Cross-Validation Strategies in rMVPA","text":"rMVPA package implements several cross-validation strategies: Blocked Cross-Validation: Uses scanning runs natural validation blocks K-Fold Cross-Validation: Randomly partitions data k folds Bootstrap Blocked Cross-Validation: Resamples within blocks replacement Sequential Blocked Cross-Validation: Creates sequential folds within blocks Two-Fold Blocked Cross-Validation: Splits blocks two groups Custom Cross-Validation: Allows user-defined validation schemes","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"overview","dir":"Articles","previous_headings":"Blocked Cross-Validation","what":"Overview","title":"Cross-Validation Strategies in rMVPA","text":"Blocked cross-validation common approach fMRI data. respects temporal structure data using scanning runs natural validation blocks.","code":"# Create a simple blocked structure: 5 runs with 20 trials each block_var <- rep(1:5, each = 20) cval <- blocked_cross_validation(block_var) print(cval) ##  ##  █▀▀ Blocked Cross-Validation ▀▀█  ##  ## ├─ Dataset Information  ## │  ├─ Observations:  100  ## │  └─ Number of Folds:  5  ## └─ Block Information  ##    ├─ Total Blocks:  5  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Block Sizes:  1: 20, 2: 20, 3: 20, 4: 20, 5: 20"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"implementation-example","dir":"Articles","previous_headings":"Blocked Cross-Validation","what":"Implementation Example","title":"Cross-Validation Strategies in rMVPA","text":"","code":"# Generate example data set.seed(123) dat <- data.frame(   x1 = rnorm(100),  # 100 trials total   x2 = rnorm(100),   x3 = rnorm(100) ) y <- factor(rep(letters[1:5], length.out = 100))  # 5 conditions  # Generate cross-validation samples samples <- crossval_samples(cval, dat, y) print(samples) ## # A tibble: 5 × 5 ##   ytrain       ytest        train               test                .id   ##   <named list> <named list> <named list>        <named list>        <chr> ## 1 <fct [80]>   <fct [20]>   <resample [80 x 3]> <resample [20 x 3]> 01    ## 2 <fct [80]>   <fct [20]>   <resample [80 x 3]> <resample [20 x 3]> 02    ## 3 <fct [80]>   <fct [20]>   <resample [80 x 3]> <resample [20 x 3]> 03    ## 4 <fct [80]>   <fct [20]>   <resample [80 x 3]> <resample [20 x 3]> 04    ## 5 <fct [80]>   <fct [20]>   <resample [80 x 3]> <resample [20 x 3]> 05"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"understanding-the-output","dir":"Articles","previous_headings":"Blocked Cross-Validation","what":"Understanding the Output","title":"Cross-Validation Strategies in rMVPA","text":"row samples tibble contains: - ytrain: Training labels - ytest: Test labels - train: Training data subset - test: Test data subset - .id: Fold identifier","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"overview-1","dir":"Articles","previous_headings":"Bootstrap Blocked Cross-Validation","what":"Overview","title":"Cross-Validation Strategies in rMVPA","text":"method combines blocking bootstrap resampling, providing stable performance estimates respecting run structure.","code":"# Create bootstrap blocked CV with 20 repetitions boot_cval <- bootstrap_blocked_cross_validation(block_var, nreps = 20) print(boot_cval) ##  ##  █▀▀ Bootstrap Blocked Cross-Validation ▀▀█  ##  ## ├─ Configuration  ## │  ├─ Observations:  100  ## │  └─ Bootstrap Repetitions:  20  ## ├─ Block Information  ## │  ├─ Total Blocks:  5  ## │  ├─ Mean Block Size:  20  (SD:  0 )  ## │  └─ Block Sizes:  1: 20, 2: 20, 3: 20, 4: 20, 5: 20  ## └─ Sampling Weights  ##    └─ Status:  None  (uniform sampling) # Generate samples boot_samples <- crossval_samples(boot_cval, dat, y) print(boot_samples) ## # A tibble: 100 × 5 ##    ytrain     ytest      train               test                .id   ##    <list>     <list>     <list>              <list>              <chr> ##  1 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 001   ##  2 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 002   ##  3 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 003   ##  4 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 004   ##  5 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 005   ##  6 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 006   ##  7 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 007   ##  8 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 008   ##  9 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 009   ## 10 <fct [80]> <fct [20]> <resample [80 x 3]> <resample [20 x 3]> 010   ## # ℹ 90 more rows"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"optional-weighted-sampling","dir":"Articles","previous_headings":"Bootstrap Blocked Cross-Validation","what":"Optional Weighted Sampling","title":"Cross-Validation Strategies in rMVPA","text":"can provide weights influence sampling probability:","code":"# Create weights (e.g., based on motion parameters) weights <- runif(length(block_var)) weighted_boot_cval <- bootstrap_blocked_cross_validation(   block_var,    nreps = 20,   weights = weights ) print(weighted_boot_cval) ##  ##  █▀▀ Bootstrap Blocked Cross-Validation ▀▀█  ##  ## ├─ Configuration  ## │  ├─ Observations:  100  ## │  └─ Bootstrap Repetitions:  20  ## ├─ Block Information  ## │  ├─ Total Blocks:  5  ## │  ├─ Mean Block Size:  20  (SD:  0 )  ## │  └─ Block Sizes:  1: 20, 2: 20, 3: 20, 4: 20, 5: 20  ## └─ Sampling Weights  ##    ├─ Status:  Present  ##    ├─ Range:  [0.001, 0.020]  ##    └─ Non-zero Weights:  100  ( 100.0% )"},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"overview-2","dir":"Articles","previous_headings":"Sequential Blocked Cross-Validation","what":"Overview","title":"Cross-Validation Strategies in rMVPA","text":"method creates sequential folds within block, useful temporal order matters.","code":"# Create sequential blocked CV with 2 folds and 4 repetitions seq_cval <- sequential_blocked_cross_validation(   block_var,   nfolds = 2,   nreps = 4 ) print(seq_cval) ## $block_var ##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ##  [38] 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 ##  [75] 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ##  ## $nfolds ## [1] 2 ##  ## $nreps ## [1] 4 ##  ## $block_ind ## [1] 1 2 3 4 5 ##  ## attr(,\"class\") ## [1] \"sequential_blocked_cross_validation\" \"cross_validation\"                    ## [3] \"list\""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"overview-3","dir":"Articles","previous_headings":"Two-Fold Blocked Cross-Validation","what":"Overview","title":"Cross-Validation Strategies in rMVPA","text":"approach randomly splits blocks two groups, useful rapid performance estimation.","code":"# Create two-fold blocked CV with 10 repetitions twofold_cval <- twofold_blocked_cross_validation(block_var, nreps = 10) print(twofold_cval) ##  ##  █▀▀ Two-Fold Blocked Cross-Validation ▀▀█  ##  ## ├─ Configuration  ## │  ├─ Observations:  100  ## │  ├─ Number of Folds:  2  ## │  └─ Repetitions:  10  ## └─ Block Information  ##    ├─ Total Blocks:  5  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Block Sizes:  1: 20, 2: 20, 3: 20, 4: 20, 5: 20"},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"overview-4","dir":"Articles","previous_headings":"Custom Cross-Validation","what":"Overview","title":"Cross-Validation Strategies in rMVPA","text":"specialized validation schemes, can define custom training/testing splits:","code":"# Define custom splits custom_splits <- list(   list(train = 1:60, test = 61:100),   list(train = 1:40, test = 41:100),   list(train = 1:80, test = 81:100) )  # Create custom CV custom_cval <- custom_cross_validation(custom_splits) print(custom_cval) ## $sample_set ## $sample_set[[1]] ## $sample_set[[1]]$train ##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ## [51] 51 52 53 54 55 56 57 58 59 60 ##  ## $sample_set[[1]]$test ##  [1]  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79 ## [20]  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98 ## [39]  99 100 ##  ##  ## $sample_set[[2]] ## $sample_set[[2]]$train ##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 ##  ## $sample_set[[2]]$test ##  [1]  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59 ## [20]  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78 ## [39]  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97 ## [58]  98  99 100 ##  ##  ## $sample_set[[3]] ## $sample_set[[3]]$train ##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ## [51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## [76] 76 77 78 79 80 ##  ## $sample_set[[3]]$test ##  [1]  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 ## [20] 100 ##  ##  ##  ## $nfolds ## [1] 3 ##  ## attr(,\"class\") ## [1] \"custom_cross_validation\" \"cross_validation\"        ## [3] \"list\""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"practical-example-model-training","dir":"Articles","previous_headings":"","what":"Practical Example: Model Training","title":"Cross-Validation Strategies in rMVPA","text":"’s complete example using blocked cross-validation SDA classifier:","code":"# Setup cross-validation block_var <- rep(1:5, each = 20) cval <- blocked_cross_validation(block_var)  # Generate data set.seed(123) dat <- data.frame(matrix(rnorm(100 * 10), 100, 10)) y <- factor(rep(letters[1:5], 20))  # Generate CV samples samples <- crossval_samples(cval, dat, y)  # Train models for each fold model_fits <- samples %>%    rowwise() %>%    do({     train_dat <- as.data.frame(.$train)     y_train <- .$ytrain     fit <- sda::sda(as.matrix(train_dat), y_train, verbose = FALSE)     tibble::tibble(fit = list(fit))   })  print(model_fits) ## # A tibble: 5 × 1 ## # Rowwise:  ##   fit    ##   <list> ## 1 <sda>  ## 2 <sda>  ## 3 <sda>  ## 4 <sda>  ## 5 <sda>"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"Cross-Validation Strategies in rMVPA","text":"choosing cross-validation strategy, consider: Use blocked CV data clear run/session boundaries Consider sequential CV temporal order matters Use bootstrap blocked CV stable estimates small datasets, bootstrap blocked CV can help large datasets, simple blocked CV may suffice Always respect temporal structure fMRI data Avoid mixing training/testing data run Consider temporal autocorrelation Bootstrap sequential methods require computation Two-fold CV offers quick preliminary results Balance estimation stability computational cost","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Cross-Validation Strategies in rMVPA","text":"Choose right cross-validation strategy neuroimaging data. Match CV approach data structure, account temporal dependencies fMRI, use bootstrap methods need stable estimates. rMVPA package supports approaches, including custom schemes specialized needs. implementation details, refer source code crossval.R.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"integration-with-regional-and-searchlight-analyses","dir":"Articles","previous_headings":"","what":"Integration with Regional and Searchlight Analyses","title":"Cross-Validation Strategies in rMVPA","text":"Cross-validation strategies rMVPA designed work seamlessly regional searchlight analyses. ’ll demonstrate incorporate different cross-validation schemes analyses.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"regional-analysis-example","dir":"Articles","previous_headings":"Integration with Regional and Searchlight Analyses","what":"Regional Analysis Example","title":"Cross-Validation Strategies in rMVPA","text":"Let’s perform regional MVPA analysis using different cross-validation strategies:","code":"# Generate a sample dataset data_out <- gen_sample_dataset(D = c(6,6,6), nobs = 80, blocks = 4, nlevels = 2)  # Create a region mask mask <- data_out$dataset$mask nvox <- sum(mask) region_mask <- neuroim2::NeuroVol(   sample(1:3, size = nvox, replace = TRUE),    space(mask),    indices = which(mask > 0) )  # Create MVPA dataset dset <- mvpa_dataset(data_out$dataset$train_data, mask = data_out$dataset$mask)  # Load the classification model mod <- load_model(\"sda_notune\") tune_grid <- data.frame(lambda = 0.01, diagonal = FALSE)  # Example 1: Using Blocked Cross-Validation blocked_cv <- blocked_cross_validation(data_out$design$block_var) mvpa_mod_blocked <- mvpa_model(   mod,    dataset = dset,    design = data_out$design,   crossval = blocked_cv,   tune_grid = tune_grid )  # Run regional analysis with blocked CV results_blocked <- run_regional(mvpa_mod_blocked, region_mask) ## INFO [2025-09-27 21:51:48]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 # Example 2: Using Bootstrap Blocked Cross-Validation bootstrap_cv <- bootstrap_blocked_cross_validation(   data_out$design$block_var,   nreps = 10 ) mvpa_mod_boot <- mvpa_model(   mod,   dataset = dset,   design = data_out$design,   crossval = bootstrap_cv,   tune_grid = tune_grid )  # Run regional analysis with bootstrap CV results_boot <- run_regional(mvpa_mod_boot, region_mask) ## INFO [2025-09-27 21:51:57]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 # Compare performance between CV strategies cat(\"Blocked CV Performance:\\n\") ## Blocked CV Performance: print(results_blocked$performance_table) ## # A tibble: 3 × 3 ##   roinum Accuracy    AUC ##    <int>    <dbl>  <dbl> ## 1      1    0.6   0.0975 ## 2      2    0.55  0.0931 ## 3      3    0.575 0.114 cat(\"\\nBootstrap CV Performance:\\n\") ##  ## Bootstrap CV Performance: print(results_boot$performance_table) ## # A tibble: 3 × 3 ##   roinum Accuracy    AUC ##    <int>    <dbl>  <dbl> ## 1      1    0.575 0.0569 ## 2      2    0.512 0.0750 ## 3      3    0.588 0.09"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"searchlight-analysis-example","dir":"Articles","previous_headings":"Integration with Regional and Searchlight Analyses","what":"Searchlight Analysis Example","title":"Cross-Validation Strategies in rMVPA","text":"can also use different cross-validation strategies searchlight analysis:","code":"# Example 3: Searchlight with Sequential Blocked Cross-Validation seq_cv <- sequential_blocked_cross_validation(   data_out$design$block_var,   nfolds = 2,   nreps = 4 )  mvpa_mod_seq <- mvpa_model(   mod,   dataset = dset,   design = data_out$design,   crossval = seq_cv,   tune_grid = tune_grid )  # Run searchlight analysis results_searchlight <- run_searchlight(   mvpa_mod_seq,   radius = 2,   method = \"standard\" )"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"key-considerations","dir":"Articles","previous_headings":"Integration with Regional and Searchlight Analyses","what":"Key Considerations","title":"Cross-Validation Strategies in rMVPA","text":"integrating cross-validation regional searchlight analyses: Bootstrap sequential methods generate folds Consider reducing nreps large searchlight analyses Monitor memory usage large datasets Searchlight analysis multiplies computation across voxels Two-fold CV might preferable initial searchlight exploration Use parallel processing available Bootstrap methods provide confidence intervals require computation Consider trade-estimation stability computational cost searchlight analyses, simpler CV schemes might sufficient Different CV schemes might produce slightly different performance estimates Bootstrap methods generally provide conservative estimates Consider averaging results across repetitions bootstrap sequential CV","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CrossValidation.html","id":"example-comparing-cv-strategies-in-regional-analysis","dir":"Articles","previous_headings":"Integration with Regional and Searchlight Analyses","what":"Example: Comparing CV Strategies in Regional Analysis","title":"Cross-Validation Strategies in rMVPA","text":"’s detailed comparison different CV strategies: integration demonstrates different cross-validation strategies can easily incorporated broader MVPA analysis framework, allowing researchers choose appropriate validation approach specific analysis needs. details regional searchlight analyses, refer respective vignettes implementation regional.R searchlight.R.","code":"# Create different CV schemes cv_schemes <- list(   blocked = blocked_cross_validation(data_out$design$block_var),   bootstrap = bootstrap_blocked_cross_validation(data_out$design$block_var, nreps = 10),   twofold = twofold_blocked_cross_validation(data_out$design$block_var, nreps = 5) )  # Run regional analysis with each CV scheme results <- lapply(cv_schemes, function(cv) {   mvpa_mod <- mvpa_model(     mod,     dataset = dset,     design = data_out$design,     crossval = cv,     tune_grid = tune_grid   )   run_regional(mvpa_mod, region_mask) }) ## INFO [2025-09-27 21:52:01]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:52:09]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:52:13]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 # Compare performance across CV schemes performance_comparison <- lapply(names(results), function(name) {   perf <- results[[name]]$performance_table   perf$cv_scheme <- name   perf })  # Combine results all_performance <- do.call(rbind, performance_comparison) print(all_performance) ## # A tibble: 9 × 4 ##   roinum Accuracy    AUC cv_scheme ##    <int>    <dbl>  <dbl> <chr>     ## 1      1    0.6   0.0975 blocked   ## 2      2    0.55  0.0931 blocked   ## 3      3    0.575 0.114  blocked   ## 4      1    0.6   0.0675 bootstrap ## 5      2    0.55  0.0663 bootstrap ## 6      3    0.6   0.0700 bootstrap ## 7      1    0.588 0.103  twofold   ## 8      2    0.538 0.0694 twofold   ## 9      3    0.6   0.0819 twofold"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Running Custom Analyses with rMVPA","text":"rMVPA package provides powerful tools standard MVPA RSA analyses. However, researchers often need perform custom calculations within specific brain regions (ROIs) searchlight spheres go beyond built-models. example, might want : Calculate specific univariate statistics within ROI. Compute custom connectivity metric within searchlight sphere. Integrate novel analysis method currently implemented standard rMVPA model. Perform simpler analysis without overhead defining full mvpa_model rsa_model object. facilitate flexibility, rMVPA offers two functions: run_custom_regional run_custom_searchlight. functions allow apply R function define data extracted ROIs searchlight spheres, leveraging rMVPA’s data handling, iteration, parallel processing, error management capabilities. vignette explains rationale behind functions provides practical examples use.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"rationale-why-use-custom-analysis-functions","dir":"Articles","previous_headings":"","what":"Rationale: Why Use Custom Analysis Functions?","title":"Running Custom Analyses with rMVPA","text":"Using run_custom_regional run_custom_searchlight offers several advantages: Flexibility: Apply R function ROI searchlight data, enabling bespoke analyses tailored specific research questions. Simplicity: analyses don’t fit standard mvpa_model structure (e.g., simple descriptive statistics), functions provide direct interface creating custom S3 model class. Integration: Seamlessly integrate custom metrics methods R packages rMVPA workflow. Efficiency: Benefit rMVPA’s optimized iteration (mvpa_iterate) parallel processing capabilities (future framework) custom analyses. Robustness: Leverage built-error handling catches errors within custom function specific ROIs/spheres without halting entire analysis.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"run_custom_regional","dir":"Articles","previous_headings":"Core Functions","what":"run_custom_regional","title":"Running Custom Analyses with rMVPA","text":"function applies custom analysis function data within predefined regions interest (ROIs). Usage: custom_func Regional Analysis: custom function must accept two arguments: roi_data: matrix tibble containing data (samples x features) current ROI. roi_info: list containing information ROI, including id (ROI number mask) indices (feature indices within dataset corresponding ROI). function must return either: * named list scalar values (e.g., list(mean = m, sd = s)). * single-row data frame tibble column scalar value. names list elements columns become columns final output table.","code":"run_custom_regional(   dataset,      # mvpa_dataset or mvpa_surface_dataset   region_mask,  # NeuroVol or NeuroSurface mask defining ROIs   custom_func,  # Your R function   ...,          # Optional args passed to mvpa_iterate   .cores = 1,   # Number of cores for parallel processing   .verbose = FALSE # Print progress messages? )"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"run_custom_searchlight","dir":"Articles","previous_headings":"Core Functions","what":"run_custom_searchlight","title":"Running Custom Analyses with rMVPA","text":"function applies custom analysis function data within moving searchlight spheres across brain. Usage: custom_func Searchlight Analysis: custom function must accept two arguments: sl_data: matrix tibble containing data (samples x features_in_sphere) current searchlight sphere. sl_info: list containing information sphere, including center_index (index center voxel/vertex) indices (indices features within sphere). Similar regional version, function must return either: * named list scalar values. * single-row data frame tibble scalar columns. successfully processed spheres must return set named metrics. results aggregated brain maps (NeuroVol NeuroSurface).","code":"run_custom_searchlight(   dataset,      # mvpa_dataset or mvpa_surface_dataset   custom_func,  # Your R function   radius,       # Searchlight radius (mm for volume, connections for surface)   method = \"standard\", # \"standard\" or \"randomized\"   niter = 100,  # Iterations for \"randomized\" method   ...,          # Optional args passed to mvpa_iterate   .cores = 1,   # Number of cores for parallel processing   .verbose = FALSE # Print progress messages? )"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"end-to-end-example","dir":"Articles","previous_headings":"","what":"End-to-End Example","title":"Running Custom Analyses with rMVPA","text":"Let’s demonstrate functions simple custom analysis: calculating mean standard deviation signal within ROI searchlight sphere.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"setup-data-and-custom-function","dir":"Articles","previous_headings":"End-to-End Example","what":"1. Setup: Data and Custom Function","title":"Running Custom Analyses with rMVPA","text":"First, generate sample volumetric dataset define custom function.","code":"# Generate sample dataset (e.g., 10x10x10 volume, 50 observations, 2 blocks) dset_info <- gen_sample_dataset(D = c(10, 10, 10), nobs = 50, blocks = 2, nlevels=2) dataset_obj <- dset_info$dataset  # Define our custom analysis function # It calculates mean, sd, and number of features (voxels) calculate_roi_stats <- function(data, info) {   # Inputs:   # data: matrix (samples x features) for the current ROI/sphere   # info: list with id/center_index and feature indices      # Perform calculations   mean_signal <- mean(data, na.rm = TRUE)   sd_signal <- sd(data, na.rm = TRUE)   num_features <- ncol(data)      # Return results as a named list of scalars   list(     mean_signal = mean_signal,     sd_signal = sd_signal,     n_features = num_features   ) }  # Define a version that might fail for small ROIs/spheres calculate_roi_stats_robust <- function(data, info) {     if (ncol(data) < 5) {         stop(\"Too few features (< 5) in this region!\")     }     # If enough features, proceed as normal     mean_signal <- mean(data, na.rm = TRUE)     sd_signal <- sd(data, na.rm = TRUE)     num_features <- ncol(data)     list(         mean_signal = mean_signal,         sd_signal = sd_signal,         n_features = num_features     ) }"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"custom-regional-analysis","dir":"Articles","previous_headings":"End-to-End Example","what":"2. Custom Regional Analysis","title":"Running Custom Analyses with rMVPA","text":"Now, create region mask run run_custom_regional. Explanation: output run_custom_regional tibble. row corresponds ROI defined region_mask_vol. columns : * id: ROI identifier (integer value mask). * Columns based named list returned custom_func (mean_signal, sd_signal, n_features). * error: logical flag indicating error occurred within custom_func ROI. * error_message: error message error TRUE. second example, calculate_roi_stats_robust encountered ROI fewer 5 voxels (potentially ROI 4), corresponding row show error = TRUE, specific error message, NA values metrics.","code":"# Create a region mask with 4 ROIs covering parts of the dataset mask mask_vol <- dataset_obj$mask mask_arr <- array(0, dim(mask_vol)) active_indices <- which(mask_vol > 0) n_active <- length(active_indices)  # Assign active voxels roughly to 4 regions set.seed(456) # for reproducibility roi_assignments <- sample(1:4, size = n_active, replace = TRUE)  # Make ROI 4 potentially small to test error handling roi_assignments[sample(which(roi_assignments==4), size=round(sum(roi_assignments==4)*0.9))] <- sample(1:3, size=round(sum(roi_assignments==4)*0.9), replace=TRUE)   mask_arr[active_indices] <- roi_assignments region_mask_vol <- NeuroVol(mask_arr, space(mask_vol))  # Run the custom regional analysis (sequentially first) custom_regional_results <- run_custom_regional(   dataset = dataset_obj,   region_mask = region_mask_vol,   custom_func = calculate_roi_stats,   .cores = 1,    .verbose = FALSE ) ## INFO [2025-09-27 21:52:18] Starting custom regional analysis... ## INFO [2025-09-27 21:52:23]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 4 ## ├─ Processed: 4 ## └─ Skipped: 0 ## INFO [2025-09-27 21:52:23] Custom regional analysis iteration complete. ## INFO [2025-09-27 21:52:23] Finished formatting custom regional results. # Print the results table print(custom_regional_results) ## # A tibble: 4 × 6 ##      id mean_signal sd_signal n_features error error_message ##   <int>       <dbl>     <dbl>      <int> <lgl> <chr>         ## 1     1    -0.0169      0.988        188 FALSE ~             ## 2     2    -0.00801     1.00         158 FALSE ~             ## 3     3    -0.0121      0.997        153 FALSE ~             ## 4     4    -0.0151      0.948         13 FALSE ~ # Example with error handling (using the robust function and potential small ROI 4) # Suppress expected warnings from the logger about the error suppressWarnings({     custom_regional_error_results <- run_custom_regional(       dataset = dataset_obj,       region_mask = region_mask_vol,       custom_func = calculate_roi_stats_robust, # Function that might error       .cores = 1,        .verbose = FALSE     ) }) ## INFO [2025-09-27 21:52:23] Starting custom regional analysis... ## INFO [2025-09-27 21:52:27]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 4 ## ├─ Processed: 4 ## └─ Skipped: 0 ## INFO [2025-09-27 21:52:27] Custom regional analysis iteration complete. ## INFO [2025-09-27 21:52:27] Finished formatting custom regional results. cat(\"\\nResults with potential errors:\\n\") ##  ## Results with potential errors: print(custom_regional_error_results) ## # A tibble: 4 × 6 ##      id mean_signal sd_signal n_features error error_message ##   <int>       <dbl>     <dbl>      <int> <lgl> <chr>         ## 1     1    -0.0169      0.988        188 FALSE ~             ## 2     2    -0.00801     1.00         158 FALSE ~             ## 3     3    -0.0121      0.997        153 FALSE ~             ## 4     4    -0.0151      0.948         13 FALSE ~"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"custom-searchlight-analysis","dir":"Articles","previous_headings":"End-to-End Example","what":"3. Custom Searchlight Analysis","title":"Running Custom Analyses with rMVPA","text":"Next, run searchlight analysis using custom function. Explanation: output run_custom_searchlight searchlight_result object (list). Key components include: * results: named list element corresponds metric returned custom_func (e.g., results$mean_signal, results$sd_signal). * metric element (e.g., results$mean_signal) searchlight_performance object containing: * $data: NeuroVol (NeuroSurface) object holding metric values mapped back brain space. * $summary_stats: Basic statistics (mean, sd, min, max) calculated across map values. * metadata like $metric_name, $n_nonzero. * metrics: Names metrics computed. * n_voxels: total voxels/vertices defined mask. * active_voxels: number voxels/vertices results. values output maps ($data) represent result custom_func applied searchlight sphere centered voxel. “randomized” method used, map values represent average metric across spheres included voxel.","code":"# Run the custom searchlight analysis (standard method) # Use a moderate radius; set cores > 1 for parallel execution if available # Note: Running in parallel might print messages about the future plan setting. custom_searchlight_results <- run_custom_searchlight(   dataset = dataset_obj,   custom_func = calculate_roi_stats,   radius = 4, # e.g., 4mm radius   method = \"standard\",   .cores = 2, # Use 2 cores if available   .verbose = FALSE ) ## INFO [2025-09-27 21:52:28] Starting custom searchlight analysis (method: standard, radius: 4 mm)... ## INFO [2025-09-27 21:52:28] Preparing 512 standard searchlight spheres... ## INFO [2025-09-27 21:53:17]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 512 ## ├─ Processed: 512 ## └─ Skipped: 0 ## INFO [2025-09-27 21:53:18] Combining results from standard searchlight... ## INFO [2025-09-27 21:53:18] Finished custom searchlight analysis. # Print the results object summary print(custom_searchlight_results) ##  ##  █▀▀ Searchlight Analysis Results ▀▀█  ##  ## ├─ Coverage  ## │  ├─ Voxels/Vertices in Mask:  1,000  ## │  └─ Voxels/Vertices with Results:  512  ## └─ Output Maps (Metrics)  ##    ├─  mean_signal  (Type:  searchlight_performance )  ##    ├─  sd_signal  (Type:  searchlight_performance )  ##    ├─  n_features  (Type:  searchlight_performance ) # Access the results for a specific metric (e.g., mean_signal) mean_signal_map_obj <- custom_searchlight_results$results$mean_signal  # The map itself is stored in the 'data' slot mean_signal_map_vol <- mean_signal_map_obj$data cat(\"\\nClass of the mean_signal map:\", class(mean_signal_map_vol), \"\\n\") ##  ## Class of the mean_signal map: DenseNeuroVol cat(\"Dimensions of the map:\", dim(mean_signal_map_vol), \"\\n\") ## Dimensions of the map: 10 10 10 # Print summary stats for the map print(mean_signal_map_obj$summary_stats) ## $mean ## [1] -0.00275647 ##  ## $sd ## [1] 0.008462561 ##  ## $min ## [1] -0.03412619 ##  ## $max ## [1] 0.03016657 # You can plot the map using neuroim2's plotting functions (example commented out) # plot(mean_signal_map_vol)"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"key-considerations","dir":"Articles","previous_headings":"","what":"Key Considerations","title":"Running Custom Analyses with rMVPA","text":"custom_func Requirements: Ensure function strictly adheres input argument requirements (roi_data/sl_data, roi_info/sl_info) returns named list single-row tibble scalar values. Inconsistent return types names across ROIs/spheres cause errors result aggregation. Parallel Processing: Set .cores > 1 speed analysis. future package backend used. control, set future::plan() calling run_custom_* function (e.g., future::plan(future::multisession, workers = 4)). Error Handling: Errors occurring within custom_func specific ROI sphere caught automatically. analysis continue, affected ROI/voxel marked error flag contain NA output. Use futile.logger::flog.warn flog.error inside custom_func tryCatch blocks rMVPA detailed debugging messages. Memory: Searchlight analyses, especially large radii many randomized iterations, can memory-intensive. Monitor usage accordingly. Randomized Searchlight: using method = \"randomized\", ensure metric returned custom_func meaningful averaged across overlapping spheres.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/CustomAnalyses.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Running Custom Analyses with rMVPA","text":"run_custom_regional run_custom_searchlight functions provide powerful mechanism extend rMVPA’s capabilities. allow researchers apply bespoke analyses within ROIs searchlight spheres benefiting package’s iteration, parallelization, error-handling infrastructure. defining custom function meets specified input output requirements, can easily integrate diverse analytical approaches neuroimaging workflow. implementation details, refer source code R/custom.R.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/FeatureSelection.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Feature Selection in rMVPA","text":"modern neuroimaging machine learning analyses, datasets often contain large number features (e.g., voxels). Many features can noisy irrelevant prediction task hand. Feature selection critical step reduce dimensionality, improve model interpretability, potentially enhance predictive performance. essential integrate feature selection within cross-validation framework avoid introducing selection bias. rMVPA package, feature selection can applied automatically part analysis pipeline. rMVPA, feature selector object used specify method criteria feature selection. Two primary methods available: FTest: Performs one-way ANOVA F-test feature uses resulting p-values selection. catscore: Computes correlation-adjusted t-scores (using sda.ranking function sda package) rank features. Additionally, two types cutoff criteria supported: Top_k (“topk”): Selects top k features based ranking. Top_p (“topp”): Selects proportion p features (e.g., setting p 0.1 selects top 10% features).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/FeatureSelection.html","id":"creating-a-feature-selector-object","dir":"Articles","previous_headings":"","what":"Creating a Feature Selector Object","title":"Feature Selection in rMVPA","text":"create feature selector rMVPA, use feature_selector() function. example, construct feature selector using FTest method top_k cutoff (selecting top 10 features): Similarly, can create feature selector selects proportion features using top_p option. example , select top 10% features based FTest ranking:","code":"suppressPackageStartupMessages(library(rMVPA)) # Create a feature selector using FTest with top_k cutoff (select top 10 features) fsel <- feature_selector(method = \"FTest\", cutoff_type = \"top_k\", cutoff_value = 10) fsel ## Feature Selector Object\\n-----------------------\\nMethod:         FTest \\nCutoff Type:    top_k \\nCutoff Value:   10 \\n # Create a feature selector using FTest with top_p cutoff (select top 10% of features) fsel <- feature_selector(method = \"FTest\", cutoff_type = \"top_p\", cutoff_value = 0.1) fsel ## Feature Selector Object\\n-----------------------\\nMethod:         FTest \\nCutoff Type:    top_p \\nCutoff Value:   0.1 \\n"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/FeatureSelection.html","id":"applying-feature-selection-to-data","dir":"Articles","previous_headings":"","what":"Applying Feature Selection to Data","title":"Feature Selection in rMVPA","text":"select_features() function applies feature selection process given feature matrix X response variable Y. function returns logical vector TRUE selected features FALSE otherwise. example using simulated data: Now, let’s use top_p option. select proportion features. example, cutoff value 0.1, top 10% features selected:","code":"# Simulate a response variable (categorical) Y <- factor(rep(letters[1:4], each = 25))  # Simulate a feature matrix with 100 samples and 100 features X <- matrix(rnorm(100 * 100), nrow = 100, ncol = 100)  # Apply feature selection using the FTest method with top_k cutoff fsel <- feature_selector(method = \"FTest\", cutoff_type = \"top_k\", cutoff_value = 10) selected_features <- select_features(fsel, X, Y)  # The number of selected features should be equal to the cutoff value (10) cat(\"Number of selected features (top_k):\", sum(selected_features), \"\\n\") ## Number of selected features (top_k): 10 # Apply feature selection using the FTest method with top_p cutoff (select top 10% of features) fsel <- feature_selector(method = \"FTest\", cutoff_type = \"top_p\", cutoff_value = 0.1) selected_features <- select_features(fsel, X, Y)  # Calculate the proportion of features selected the_proportion <- sum(selected_features) / ncol(X) cat(\"Proportion of features selected (top_p):\", the_proportion, \"\\n\") ## Proportion of features selected (top_p): 0.1"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/FeatureSelection.html","id":"using-the-catscore-method","dir":"Articles","previous_headings":"","what":"Using the catscore Method","title":"Feature Selection in rMVPA","text":"Alternatively, can use catscore method perform feature selection. catscore method computes correlation-adjusted t-score feature. ’s example:","code":"# Create a feature selector using catscore with top_k cutoff (select top 10 features) fsel <- feature_selector(method = \"catscore\", cutoff_type = \"top_k\", cutoff_value = 10)  # Simulate a response variable and feature matrix Y <- factor(rep(letters[1:3], length.out = 90)) X <- matrix(rnorm(90 * 50), nrow = 90, ncol = 50)  # Apply feature selection using catscore selected_features <- select_features(fsel, X, Y, ranking.score = \"entropy\")  cat(\"Number of features selected using catscore (top_k):\", sum(selected_features), \"\\n\") ## Number of features selected using catscore (top_k): 10"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/FeatureSelection.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Feature Selection in rMVPA","text":"Feature selection powerful tool reduce dimensionality high-dimensional datasets, especially neuroimaging applications. rMVPA, integration feature selection cross-validation workflows helps ensure models built unbiased, relevant subsets data. can choose different methods (FTest catscore) cutoff strategies (top_k vs top_p) based specific analysis needs.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"MVPA Regional Analysis Tutorial","text":"tutorial explains run regional multivariate pattern analysis (MVPA) using MVPA_Regional.R. script performs MVPA specified brain regions, enabling classification regression analyses fMRI data. Regional analysis can conducted volumetric (NIfTI) surface-based neuroimaging data, allows separate training testing subsets.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"key-features","dir":"Articles","previous_headings":"Introduction","what":"Key Features","title":"MVPA Regional Analysis Tutorial","text":"script handles volumetric NIfTI surface-based data formats. can evaluate specific regions using separate training testing subsets. parameters configurable YAML R files. analysis produces comprehensive outputs including performance maps, prediction tables, configuration records. Cross-validation options include blocked, k-fold, two-fold approaches. script works built-MVPA models MVPAModels registry. Data preprocessing includes optional centering/scaling flexible feature selection methods.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"basic-usage","dir":"Articles","previous_headings":"Running the Script","what":"1. Basic Usage","title":"MVPA Regional Analysis Tutorial","text":": 4D fMRI file training (e.g., train_data.nii) trial--trial design matrix (e.g., train_design.txt) brain mask file (e.g., mask.nii) can run regional analysis command line:","code":"Rscript MVPA_Regional.R --train_design=train_design.txt \\                          --train_data=train_data.nii \\                          --mask=mask.nii \\                          --model=sda_notune \\                          --label_column=condition \\                          --ncores=4 \\                          --output=my_regional_output"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"understanding-data-modes","dir":"Articles","previous_headings":"Running the Script","what":"2. Understanding Data Modes","title":"MVPA Regional Analysis Tutorial","text":"script supports two primary data modes:","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"image-mode-volumetric-data","dir":"Articles","previous_headings":"Running the Script > 2. Understanding Data Modes","what":"Image Mode (Volumetric Data)","title":"MVPA Regional Analysis Tutorial","text":"Default mode (--data_mode=image) Works NIfTI files binary mask Analyzes region-level data based voxel masks","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"surface-mode","dir":"Articles","previous_headings":"Running the Script > 2. Understanding Data Modes","what":"Surface Mode","title":"MVPA Regional Analysis Tutorial","text":"Activated --data_mode=surface Processes surface-based neuroimaging data Can handle multiple surface sections","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"available-models","dir":"Articles","previous_headings":"Running the Script","what":"3. Available Models","title":"MVPA Regional Analysis Tutorial","text":"script supports various classification regression models:","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"built-in-mvpa-models","dir":"Articles","previous_headings":"Running the Script > 3. Available Models","what":"Built-in MVPA Models:","title":"MVPA Regional Analysis Tutorial","text":"corclass: Correlation-based classifier template matching sda_notune: Shrinkage Discriminant Analysis without tuning sda_boot: SDA bootstrap resampling glmnet_opt: Elastic net EPSGO parameter optimization sparse_sda: SDA sparsity constraints sda_ranking: SDA automatic feature ranking mgsda: Multi-Group Sparse Discriminant Analysis lda_thomaz: Modified LDA high-dimensional data hdrda: High-Dimensional Regularized Discriminant Analysis","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"caret-models","dir":"Articles","previous_headings":"Running the Script > 3. Available Models","what":"Caret Models:","title":"MVPA Regional Analysis Tutorial","text":"Custom models can registered using register_mvpa_model()","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"cross-validation-options","dir":"Articles","previous_headings":"Running the Script","what":"4. Cross-Validation Options","title":"MVPA Regional Analysis Tutorial","text":"Multiple cross-validation strategies available:","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"blocked-cross-validation","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"Blocked Cross-Validation","title":"MVPA Regional Analysis Tutorial","text":"Uses blocking variable (e.g., session) splitting data.","code":"--block_column=session"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"k-fold-cross-validation","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"K-Fold Cross-Validation","title":"MVPA Regional Analysis Tutorial","text":"Default block column specified; uses random splits.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"two-fold-cross-validation","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"Two-Fold Cross-Validation","title":"MVPA Regional Analysis Tutorial","text":"Specify configuration file:","code":"cross_validation:   name: \"twofold\"   nreps: 10"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"advanced-cross-validation-methods","dir":"Articles","previous_headings":"Running the Script > 4. Cross-Validation Options","what":"Advanced Cross-Validation Methods","title":"MVPA Regional Analysis Tutorial","text":"addition standard options , several advanced cross-validation strategies available: Blocked Cross-Validation: Divides dataset based blocking variable (e.g., session) samples block remain together. K-Fold Cross-Validation: Randomly partitions data k folds, providing robust estimate model performance. Bootstrap Blocked Cross-Validation: Generates bootstrap resamples within blocks assess model stability heterogeneous datasets. Sequential Blocked Cross-Validation: Assigns sequential folds within block, preserving temporal ordered structures. Custom Cross-Validation: Allows define custom training testing splits standard methods fit experimental design. Specify desired method configuration file setting name field cross_validation. example, use bootstrap blocked cross-validation: Choose method best aligns data structure experimental design.","code":"cross_validation:   name: \"bootstrap\"   # Options: \"twofold\", \"bootstrap\", \"sequential\", \"custom\", \"kfold\"   nreps: 10"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"feature-selection","dir":"Articles","previous_headings":"Running the Script","what":"5. Feature Selection","title":"MVPA Regional Analysis Tutorial","text":"Enable feature selection :","code":"feature_selector:   method: \"anova\"  # Options: \"correlation\", \"t-test\", etc.   cutoff_type: \"percentile\"   cutoff_value: 0.1"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"understanding-label_column","dir":"Articles","previous_headings":"Running the Script","what":"6. Understanding label_column","title":"MVPA Regional Analysis Tutorial","text":"label column specifies target variable: classification, contain categorical labels (e.g., “Face”, “House”). regression, contain continuous values (e.g., reaction times). Example Design File (train_design.txt):","code":"trial  condition  subject  session 1      Face       S01      1 2      House      S01      1 3      Face       S01      1 4      House      S01      1 5      Face       S01      2"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"using-a-configuration-file","dir":"Articles","previous_headings":"Running the Script","what":"7. Using a Configuration File","title":"MVPA Regional Analysis Tutorial","text":"Instead specifying options command line, can use configuration file. Example YAML Config File (regional_config.yaml): Running Config File:","code":"# Data Sources train_design: \"train_design.txt\" test_design: \"test_design.txt\" train_data: \"train_data.nii\" test_data: \"test_data.nii\" mask: \"mask.nii\"  # Analysis Parameters model: \"rf\"  # Random Forest classifier data_mode: \"image\"  # or \"surface\" ncores: 4 label_column: \"condition\" block_column: \"session\"  # Output Options output: \"regional_results\" normalize_samples: TRUE class_metrics: TRUE  # Advanced Options feature_selector:   method: \"anova\"   cutoff_type: \"percentile\"   cutoff_value: 0.1  cross_validation:   name: \"twofold\"   nreps: 10  # Optional Subsetting: Define different subsets for training and testing train_subset: \"subject == 'S01'\" test_subset: \"subject == 'S02'\" Rscript MVPA_Regional.R --config=regional_config.yaml"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"expected-outputs","dir":"Articles","previous_headings":"Running the Script","what":"8. Expected Outputs","title":"MVPA Regional Analysis Tutorial","text":"running script, output directory (e.g., regional_results/) contains: Performance Maps: NIfTI files region-level performance metrics (e.g., accuracy, AUC). Prediction Tables: Text files summarizing predictions region. Configuration File: config.yaml complete analysis parameters reproducibility. Example directory structure: regression analyses, different metrics (e.g., r2.nii, rmse.nii, spearcor.nii) output.","code":"regional_results/ ├── performance_table.txt   # Regional performance metrics ├── prediction_table.txt    # Prediction details per region ├── regional_metric1.nii    # Regional performance map (e.g., accuracy or AUC) ├── regional_metric2.nii    # Additional metric maps (if applicable) └── config.yaml             # Analysis configuration"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"performance-considerations","dir":"Articles","previous_headings":"Running the Script","what":"9. Performance Considerations","title":"MVPA Regional Analysis Tutorial","text":"Use --normalize_samples=TRUE improved model performance. Increase --ncores leverage multi-core systems. Adjust parameters based spatial resolution hypotheses. Select appropriate cross-validation strategies prevent overfitting.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/MVPA_RegionalCmdline.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"MVPA Regional Analysis Tutorial","text":"MVPA_Regional.R provides comprehensive regional MVPA analysis capabilities. handles volumetric surface-based data formats flexible configuration command line config files. tool generates detailed performance maps prediction tables, incorporating robust cross-validation feature selection ensure reliable results. Next Steps: - Experiment various models (--model=rf, --model=sda_notune). - Test different feature selection methods. - Evaluate classification regression scenarios. - Optimize processing using parallel computation. Happy regional analysis!","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"introduction-to-representational-similarity-analysis","dir":"Articles","previous_headings":"","what":"Introduction to Representational Similarity Analysis","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"Representational Similarity Analysis (RSA) compares neural activity patterns computational models measuring pattern similarities, matching model predictions, quantifying well models explain neural data. rMVPA package implements technique neuroimaging analysis.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"dissimilarity-matrices","dir":"Articles","previous_headings":"Basic Concepts","what":"Dissimilarity Matrices","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"dissimilarity matrix represents pairwise differences conditions stimuli. RSA: - cell (,j) represents different conditions j - Can derived neural data theoretical models - Common measures: correlation distance (1 - correlation), Euclidean distance","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"rsa-workflow-in-rmvpa","dir":"Articles","previous_headings":"Basic Concepts","what":"RSA Workflow in rMVPA","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"Create MVPA dataset Define model dissimilarity matrices Create RSA design Build run RSA model","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"creating-sample-data","dir":"Articles","previous_headings":"Step-by-Step Example","what":"1. Creating Sample Data","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"Let’s create simple example dataset known structure:","code":"# Generate a sample dataset (20x20x8 volume, 80 observations, 4 blocks) dataset <- rMVPA::gen_sample_dataset(D=c(20,20,8), nobs = 80, blocks=4)"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"creating-model-dissimilarity-matrices","dir":"Articles","previous_headings":"Step-by-Step Example","what":"2. Creating Model Dissimilarity Matrices","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"can use different types dissimilarity matrices:","code":"# Method 1: Using dist() on feature vectors model_features <- matrix(rnorm(80*10), 80, 10)  # 80 trials, 10 features model_rdm <- dist(model_features)  # Default is Euclidean distance  # Method 2: Direct correlation distance matrix model_matrix <- 1 - cor(t(model_features))  # Correlation distance"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"creating-an-rsa-design","dir":"Articles","previous_headings":"Step-by-Step Example","what":"3. Creating an RSA Design","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"RSA design specifies compare neural model dissimilarity patterns:","code":"# Basic design with one model RDM basic_design <- rsa_design(   formula = ~ model_rdm,   data = list(model_rdm = model_rdm),   block_var = factor(dataset$design$block_var) )  # Design with multiple model RDMs model_rdm2 <- dist(matrix(rnorm(80*10), 80, 10)) complex_design <- rsa_design(   formula = ~ model_rdm + model_rdm2,   data = list(     model_rdm = model_rdm,     model_rdm2 = model_rdm2   ),   block_var = factor(dataset$design$block_var),   keep_intra_run = FALSE  # Exclude within-run comparisons )"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"creating-and-running-an-rsa-model","dir":"Articles","previous_headings":"Step-by-Step Example","what":"4. Creating and Running an RSA Model","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"rsa_model() function supports different methods computing neural dissimilarities analyzing relationships:","code":"# Create MVPA dataset dset <- mvpa_dataset(dataset$dataset$train_data, mask=dataset$dataset$mask)  # Create RSA model with different options rsa_spearman <- rsa_model(   dataset = dset,   design = basic_design,   distmethod = \"spearman\",  # Method for computing neural dissimilarities   regtype = \"spearman\"      # Method for comparing neural and model RDMs )  # Run searchlight analysis results <- run_searchlight(   rsa_spearman,   radius = 4,   method = \"standard\" ) ## INFO [2025-09-27 21:53:37] Running standard searchlight with radius = 4 ## INFO [2025-09-27 21:53:37] creating standard searchlight ## INFO [2025-09-27 21:53:37] running standard searchlight iterator ## INFO [2025-09-27 21:53:37] ⚡ Processing batch 1/11 (24 ROIs in this batch) ## INFO [2025-09-27 21:53:38] ⚡ Processing batch 2/11 (24 ROIs in this batch) ## INFO [2025-09-27 21:53:40] ⚡ Processing batch 3/11 (24 ROIs in this batch) ## INFO [2025-09-27 21:53:41] ⚡ Processing batch 4/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:43] ⚡ Processing batch 5/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:44] ⚡ Processing batch 6/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:46] ⚡ Processing batch 7/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:47] ⚡ Processing batch 8/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:48] ⚡ Processing batch 9/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:50] ⚡ Processing batch 10/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:51] ⚡ Processing batch 11/11 (23 ROIs in this batch) ## INFO [2025-09-27 21:53:52]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 256 ## ├─ Processed: 256 ## └─ Skipped: 0"},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"multiple-comparison-methods","dir":"Articles","previous_headings":"Advanced Features","what":"Multiple Comparison Methods","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"rMVPA supports several methods comparing neural model RDMs:","code":"# Pearson correlation rsa_pearson <- rsa_model(dset, basic_design,                          distmethod = \"pearson\",                          regtype = \"pearson\")  # Linear regression rsa_lm <- rsa_model(dset, basic_design,                      distmethod = \"spearman\",                      regtype = \"lm\")  # Rank-based regression rsa_rfit <- rsa_model(dset, basic_design,                        distmethod = \"spearman\",                        regtype = \"rfit\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"handling-run-structure","dir":"Articles","previous_headings":"Advanced Features","what":"Handling Run Structure","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"RSA can account run/block structure fMRI data. critical consideration fMRI analysis whether include comparisons patterns run.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"understanding-keep_intra_run","dir":"Articles","previous_headings":"Advanced Features > Handling Run Structure","what":"Understanding keep_intra_run","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"keep_intra_run = FALSE parameter tells RSA exclude comparisons patterns within run/block. important : Temporal Autocorrelation: BOLD responses within run temporally autocorrelated Scanner Drift: Within-run patterns may share scanner drift effects Physiological Noise: Within-run patterns may share structured noise breathing, heart rate, etc. ’s visualization keep_intra_run = FALSE : create RSA design keep_intra_run = FALSE: creates RSA design : - Comparisons patterns different runs included - Comparisons patterns within run excluded - analysis focuses reliable -run pattern similarities","code":"# Create a small example with 2 runs, 4 trials each mini_data <- matrix(1:8, ncol=1)  # Trial numbers 1-8 run_labels <- c(1,1,1,1, 2,2,2,2)  # Two runs with 4 trials each  # Create distance matrix d <- dist(mini_data) d_mat <- as.matrix(d)  # Show which comparisons are kept (TRUE) or excluded (FALSE) comparison_matrix <- outer(run_labels, run_labels, \"!=\") # Only show lower triangle to match distance matrix structure comparison_matrix[upper.tri(comparison_matrix)] <- NA  # Display the matrices cat(\"Trial numbers:\\n\") ## Trial numbers: print(matrix(1:8, nrow=8, ncol=8)[lower.tri(matrix(1:8, 8, 8))]) ##  [1] 2 3 4 5 6 7 8 3 4 5 6 7 8 4 5 6 7 8 5 6 7 8 6 7 8 7 8 8 cat(\"\\nRun comparisons (TRUE = across-run, FALSE = within-run):\\n\") ##  ## Run comparisons (TRUE = across-run, FALSE = within-run): print(comparison_matrix[lower.tri(comparison_matrix)]) ##  [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE ## [13]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE # Create design excluding within-run comparisons blocked_design <- rsa_design(   formula = ~ model_rdm,   data = list(model_rdm = model_rdm),   block_var = factor(dataset$design$block_var),   keep_intra_run = FALSE  # Exclude within-run comparisons )"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"when-to-use-keep_intra_run-false","dir":"Articles","previous_headings":"Advanced Features > Handling Run Structure","what":"When to Use keep_intra_run = FALSE","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"consider setting keep_intra_run = FALSE : - experiment multiple runs/blocks - want control temporal autocorrelation - want minimize impact run-specific noise - ’re following conservative analysis practices Setting keep_intra_run = TRUE (default) might appropriate : - runs need samples - runs short - ’ve carefully controlled temporal confounds - ’re exploratory analyses","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"visualizing-results","dir":"Articles","previous_headings":"Advanced Features","what":"Visualizing Results","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"can examine visualize RSA results:","code":"# Extract the searchlight map rsa_map <- results$results$model_rdm  # Compute range of correlation values rsa_values <- neuroim2::values(rsa_map) range(rsa_values, na.rm = TRUE) ## [1] -0.03370494  0.03541486 # Basic summary of the searchlight result print(results) ##  ##  █▀▀ Searchlight Analysis Results ▀▀█  ##  ## ├─ Coverage  ## │  ├─ Voxels/Vertices in Mask:  3,200  ## │  └─ Voxels/Vertices with Results:  256  ## └─ Output Maps (Metrics)  ##    ├─  model_rdm  (Type:  DenseNeuroVol ) # Save results (commented out) # neuroim2::write_vol(rsa_map, \"RSA_results.nii.gz\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"rMVPA package provides comprehensive RSA implementation flexible model specification, multiple dissimilarity computation methods, support complex experimental designs run/block structures. integrates seamlessly searchlight analysis offers various statistical approaches including correlation, regression, rank-based methods. using RSA rMVPA, carefully consider experimental design setting block variables intra-run parameters, choose distance methods match theoretical framework, select statistical approaches appropriate analysis goals.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/RSA.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Representational Similarity Analysis (RSA) in rMVPA","text":"information RSA: - Kriegeskorte et al. (2008). Representational similarity analysis - connecting branches systems neuroscience. Front Syst Neurosci. - Nili et al. (2014). toolbox representational similarity analysis. PLoS Comput Biol.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Advanced Regional MVPA Analysis in rMVPA","text":"Regional MVPA evaluates prediction performance within predefined brain regions. vignette walks complete workflow using rMVPA: ’ll generate synthetic data, define ROIs region mask, build MVPA model cross-validation, run analysis, examine results. implementation follows approach regional.R, mvpa_model.R, dataset.R.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"data-generation-and-preparation","dir":"Articles","previous_headings":"","what":"Data Generation and Preparation","title":"Advanced Regional MVPA Analysis in rMVPA","text":"begin generating synthetic volumetric dataset using gen_sample_dataset() function. function creates 4D array (spatial dimensions multiple observations), along binary mask associated design cross-validation. returned list contains: dataset: MVPA dataset object training data binary mask. design: MVPA design object specifying response variable block structure.","code":"library(rMVPA) library(neuroim2) # Generate a synthetic dataset with dimensions 6x6x6, 80 observations, divided into 4 blocks data_out <- rMVPA::gen_sample_dataset(D = c(6,6,6), nobs = 80, blocks = 4, nlevels = 2) print(data_out) ## $dataset ##  ##  █▀▀ MVPA Dataset ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Dimensions:  6 × 6 × 6 × 80 observations  ## │  └─ Type:  DenseNeuroVec  ## ├─ Test Data  ## │  └─  None  ## └─ Mask Information  ##    ├─ Areas:  1 : 120  ##    └─ Active voxels/vertices:  120  ##  ##  ## $design ##  ##  █▀▀ MVPA Design ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Observations:  80  ## │  ├─ Response Type:  Factor ## │  ├─ Levels:  a, b  ## │  └─ Class Distribution:  a: 40, b: 40  ## ├─ Test Data  ## │  └─  None  ## └─ Structure  ##    ├─ Blocking:  Present ##    ├─ Number of Blocks:  4  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Split Groups:  None"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"creating-a-region-mask","dir":"Articles","previous_headings":"Data Generation and Preparation","what":"Creating a Region Mask","title":"Advanced Regional MVPA Analysis in rMVPA","text":"regional analysis, need define ROIs. , create region mask randomly assigning active voxel binary mask region label (1 3). simulates scenario brain partitioned three regions interest.","code":"# Extract the binary mask from the dataset mask <- data_out$dataset$mask nvox <- sum(mask)  # Create a regional mask: assign each voxel a random region number (1 to 3) set.seed(123)  # for reproducibility region_mask <- neuroim2::NeuroVol(sample(1:3, size = nvox, replace = TRUE), neuroim2::space(mask), indices = which(mask > 0)) table(region_mask) ## region_mask ##  0  1  2  3  ## 96 36 44 40"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"setting-up-the-mvpa-model","dir":"Articles","previous_headings":"","what":"Setting Up the MVPA Model","title":"Advanced Regional MVPA Analysis in rMVPA","text":"Next, create MVPA model evaluate classification task. involves: Constructing MVPA dataset using mvpa_dataset(). Specifying design (including block variable response) via mvpa_design(). Defining model mvpa_model() using chosen classifier cross-validation strategy. mvpa_model() function, defined mvpa_model.R, packages necessary parameters including cross-validation performance computation.","code":"# Create MVPA dataset object from the generated training data and mask  dset <- mvpa_dataset(data_out$dataset$train_data, mask = data_out$dataset$mask)  # Build cross-validation structure using block information from the design cval <- blocked_cross_validation(data_out$design$block_var)  # Load a classification model; here we use \"sda\" (Shrinkage Discriminant Analysis) mod <- load_model(\"sda\") tune_grid <- data.frame(lambda = 0.01, diagonal = FALSE)  # Create the MVPA model object mvpa_mod <- mvpa_model(mod, dataset = dset, design = data_out$design, crossval = cval, tune_grid = tune_grid) print(mvpa_mod) ## mvpa_model object.  ## model:  sda  ## model type:  classification  ## tune_reps:  15  ## tune_grid:   ##   lambda diagonal ## 1   0.01    FALSE ##  ##  █▀▀ Blocked Cross-Validation ▀▀█  ##  ## ├─ Dataset Information  ## │  ├─ Observations:  80  ## │  └─ Number of Folds:  4  ## └─ Block Information  ##    ├─ Total Blocks:  4  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Block Sizes:  1: 20, 2: 20, 3: 20, 4: 20  ##  ##  ##  █▀▀ MVPA Dataset ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Dimensions:  6 × 6 × 6 × 80 observations  ## │  └─ Type:  DenseNeuroVec  ## ├─ Test Data  ## │  └─  None  ## └─ Mask Information  ##    ├─ Areas:  1 : 120  ##    └─ Active voxels/vertices:  120  ##  ##  ##  █▀▀ MVPA Design ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Observations:  80  ## │  ├─ Response Type:  Factor ## │  ├─ Levels:  a, b  ## │  └─ Class Distribution:  a: 40, b: 40  ## ├─ Test Data  ## │  └─  None  ## └─ Structure  ##    ├─ Blocking:  Present ##    ├─ Number of Blocks:  4  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Split Groups:  None"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"running-the-regional-analysis","dir":"Articles","previous_headings":"","what":"Running the Regional Analysis","title":"Advanced Regional MVPA Analysis in rMVPA","text":"regional analysis executed run_regional() function, : Prepares ROIs extracting voxel indices region mask. Iterates regions, applying MVPA model ROI. Compiles performance metrics prediction tables. output regional_mvpa_result object containing: performance_table: Cross-validated performance metrics per region. prediction_table: Detailed predictions ROI trial. vol_results: Volumetric maps representing performance distributed across brain.","code":"# Run the regional analysis on the defined region mask regional_results <- run_regional(mvpa_mod, region_mask)"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"examining-the-results","dir":"Articles","previous_headings":"","what":"Examining the Results","title":"Advanced Regional MVPA Analysis in rMVPA","text":"can inspect performance table evaluate model accuracy region. detailed view, prediction table shows trial--trial predictions: Volumetric results (vol_results) can visualized neuroimaging tools determine spatial patterns performance.","code":"# Display performance metrics for each region print(regional_results$performance_table) ## # A tibble: 3 × 3 ##   roinum Accuracy     AUC ##    <int>    <dbl>   <dbl> ## 1      1    0.45  -0.0288 ## 2      2    0.388 -0.106  ## 3      3    0.55   0.0500 # Display the prediction table print(regional_results$prediction_table) ## # A tibble: 240 × 8 ## # Rowwise:  ##    .rownum roinum observed pobserved predicted correct prob_a prob_b ##      <int>  <int> <fct>        <dbl> <chr>     <lgl>    <dbl>  <dbl> ##  1       1      1 b            0.594 b         TRUE     0.406 0.594  ##  2       2      1 a            0.494 b         FALSE    0.494 0.506  ##  3       3      1 a            0.681 a         TRUE     0.681 0.319  ##  4       4      1 b            0.383 a         FALSE    0.617 0.383  ##  5       5      1 b            0.125 a         FALSE    0.875 0.125  ##  6       6      1 a            0.122 b         FALSE    0.122 0.878  ##  7       7      1 b            0.411 a         FALSE    0.589 0.411  ##  8       8      1 a            0.454 b         FALSE    0.454 0.546  ##  9       9      1 a            0.971 a         TRUE     0.971 0.0293 ## 10      10      1 a            0.944 a         TRUE     0.944 0.0557 ## # ℹ 230 more rows"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"under-the-hood-how-it-works","dir":"Articles","previous_headings":"","what":"Under the Hood: How It Works","title":"Advanced Regional MVPA Analysis in rMVPA","text":"run_regional() function internally calls prep_regional() (regional.R) process region mask, uses mvpa_iterate() apply MVPA model across ROI. Functions combine_regional_results() combine_prediction_tables() merge individual regional outputs comprehensive result. modular design, laid mvpa_model.R dataset.R, ensures : Data integrity maintained. Cross-validation properly applied. Results aggregated clear interpretation regional level.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Regional_Analysis.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Advanced Regional MVPA Analysis in rMVPA","text":"vignette showed generate synthetic neuroimaging data, define ROIs region masks, set MVPA models cross-validation, run analyses across ROIs, interpret performance metrics. now tools conduct regional MVPA analyses neuroimaging data. details, please refer source files: regional.R regional analysis methods. mvpa_model.R MVPA model creation result formatting. dataset.R dataset generation routines. Happy analyzing!","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Searchlight_Analysis.html","id":"searchlight-analysis","dir":"Articles","previous_headings":"","what":"Searchlight Analysis","title":"Searchlight Analysis","text":"","code":"## Warning in rgl.init(initValue, onlyNULL): RGL: unable to open X11 display ## Warning: 'rgl.init' failed, will use the null device. ## See '?rgl.useNULL' for ways to avoid this warning."},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Searchlight_Analysis.html","id":"generate-a-volumetric-dataset-with-100-observations-and-two-classes","dir":"Articles","previous_headings":"Searchlight Analysis","what":"Generate a volumetric dataset with 100 observations and two classes","title":"Searchlight Analysis","text":"generate dataset use gen_sample_dataset function. creating 4-dimensional neuroimaging dataset, 6--6--6 spatial dimensions 80 observations 4th dimension. 80 observations divided 4 blocks, consisting 20 trials. generated y variable factor 2 levels (‘’ ‘b’). gen_sample_dataset function creates list two elements: mvpa_dataset object (dataset) mvpa_design object (design). first contains information data second contains information experimental design.","code":"dataset <- gen_sample_dataset(D=c(6,6,6), nobs = 80, blocks=4, nlevels=2) print(dataset) ## $dataset ##  ##  █▀▀ MVPA Dataset ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Dimensions:  6 × 6 × 6 × 80 observations  ## │  └─ Type:  DenseNeuroVec  ## ├─ Test Data  ## │  └─  None  ## └─ Mask Information  ##    ├─ Areas:  1 : 120  ##    └─ Active voxels/vertices:  120  ##  ##  ## $design ##  ##  █▀▀ MVPA Design ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Observations:  80  ## │  ├─ Response Type:  Factor ## │  ├─ Levels:  a, b  ## │  └─ Class Distribution:  a: 40, b: 40  ## ├─ Test Data  ## │  └─  None  ## └─ Structure  ##    ├─ Blocking:  Present ##    ├─ Number of Blocks:  4  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Split Groups:  None"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Searchlight_Analysis.html","id":"create-a-cross-validation-object-using-a-pre-defined-blocking-variable-","dir":"Articles","previous_headings":"Searchlight Analysis","what":"Create a cross-validation object using a pre-defined blocking variable.","title":"Searchlight Analysis","text":"MVPA analyses involve collection fMRI data series scanning runs, “blocks”. Due intra-block serial correlations, makes sense take advantage block structure cross-validation. words, want train classifier k-1 blocks test set trials k held blocks. form leave-one-group-cross-validation, encapsulated blocked_cross_validation function.","code":"block <- dataset$design$block_var crossval <- blocked_cross_validation(block) crossval ##  ##  █▀▀ Blocked Cross-Validation ▀▀█  ##  ## ├─ Dataset Information  ## │  ├─ Observations:  80  ## │  └─ Number of Folds:  4  ## └─ Block Information  ##    ├─ Total Blocks:  4  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Block Sizes:  1: 20, 2: 20, 3: 20, 4: 20"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Searchlight_Analysis.html","id":"construct-an-mvpa_model-object-with-a-shrinkage-discriminant-analysis-classifier-sda_notune","dir":"Articles","previous_headings":"Searchlight Analysis","what":"Construct an mvpa_model object with a Shrinkage Discriminant Analysis classifier (sda_notune)","title":"Searchlight Analysis","text":"“sda_notune” model sda model lambda parameter estimated training data. See documentation sda package package.","code":"sda_model <- load_model(\"sda_notune\")  model <- mvpa_model(model=sda_model, dataset=dataset$dataset, design=dataset$design, crossval=crossval) model ## mvpa_model object.  ## model:  sda_notune  ## model type:  classification  ##  ##  █▀▀ Blocked Cross-Validation ▀▀█  ##  ## ├─ Dataset Information  ## │  ├─ Observations:  80  ## │  └─ Number of Folds:  4  ## └─ Block Information  ##    ├─ Total Blocks:  4  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Block Sizes:  1: 20, 2: 20, 3: 20, 4: 20  ##  ##  ##  █▀▀ MVPA Dataset ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Dimensions:  6 × 6 × 6 × 80 observations  ## │  └─ Type:  DenseNeuroVec  ## ├─ Test Data  ## │  └─  None  ## └─ Mask Information  ##    ├─ Areas:  1 : 120  ##    └─ Active voxels/vertices:  120  ##  ##  ##  █▀▀ MVPA Design ▀▀█  ##  ## ├─ Training Data  ## │  ├─ Observations:  80  ## │  ├─ Response Type:  Factor ## │  ├─ Levels:  a, b  ## │  └─ Class Distribution:  a: 40, b: 40  ## ├─ Test Data  ## │  └─  None  ## └─ Structure  ##    ├─ Blocking:  Present ##    ├─ Number of Blocks:  4  ##    ├─ Mean Block Size:  20  (SD:  0 )  ##    └─ Split Groups:  None"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Searchlight_Analysis.html","id":"run-a-standard-searchlight-analysis","dir":"Articles","previous_headings":"Searchlight Analysis","what":"Run a standard searchlight analysis","title":"Searchlight Analysis","text":"output run_searchlight list image volumes containing performance measures spherical searchlight. two-class classification problem, three output measures: Accuracy AUC (AUC .5 subtracted , centered 0 rather .5). Accuracy raw cross-validated accuracy measure centroid AUC area curve statistic. radius argument indicates radius mm spherical searchlight. Finally, method indicates searchlight scheme, can standard randomized. See information randomized searchlight.","code":"result <- run_searchlight(model, radius=4, method=\"standard\") ## INFO [2025-09-27 21:53:57] Running standard searchlight with radius = 4 ## INFO [2025-09-27 21:53:57] creating standard searchlight ## INFO [2025-09-27 21:53:57] running standard searchlight iterator ## INFO [2025-09-27 21:53:57] ⚡ Processing batch 1/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:02] ⚡ Processing batch 2/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:07] ⚡ Processing batch 3/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:11] ⚡ Processing batch 4/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:15] ⚡ Processing batch 5/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:20] ⚡ Processing batch 6/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:24] ⚡ Processing batch 7/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:29] ⚡ Processing batch 8/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:33] ⚡ Processing batch 9/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:36] ⚡ Processing batch 10/10 (12 ROIs in this batch) ## INFO [2025-09-27 21:54:40]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 120 ## ├─ Processed: 120 ## └─ Skipped: 0 ## New names: ## • `` -> `...1` ## • `` -> `...2` ## • `` -> `...3` ## • `` -> `...4` ## • `` -> `...5` ## • `` -> `...6` ## • `` -> `...7` ## • `` -> `...8` ## • `` -> `...9` ## • `` -> `...10` ## • `` -> `...11` ## • `` -> `...12` ## • `` -> `...13` ## • `` -> `...14` ## • `` -> `...15` ## • `` -> `...16` ## • `` -> `...17` ## • `` -> `...18` ## • `` -> `...19` ## • `` -> `...20` ## • `` -> `...21` ## • `` -> `...22` ## • `` -> `...23` ## • `` -> `...24` ## • `` -> `...25` ## • `` -> `...26` ## • `` -> `...27` ## • `` -> `...28` ## • `` -> `...29` ## • `` -> `...30` ## • `` -> `...31` ## • `` -> `...32` ## • `` -> `...33` ## • `` -> `...34` ## • `` -> `...35` ## • `` -> `...36` ## • `` -> `...37` ## • `` -> `...38` ## • `` -> `...39` ## • `` -> `...40` ## • `` -> `...41` ## • `` -> `...42` ## • `` -> `...43` ## • `` -> `...44` ## • `` -> `...45` ## • `` -> `...46` ## • `` -> `...47` ## • `` -> `...48` ## • `` -> `...49` ## • `` -> `...50` ## • `` -> `...51` ## • `` -> `...52` ## • `` -> `...53` ## • `` -> `...54` ## • `` -> `...55` ## • `` -> `...56` ## • `` -> `...57` ## • `` -> `...58` ## • `` -> `...59` ## • `` -> `...60` ## • `` -> `...61` ## • `` -> `...62` ## • `` -> `...63` ## • `` -> `...64` ## • `` -> `...65` ## • `` -> `...66` ## • `` -> `...67` ## • `` -> `...68` ## • `` -> `...69` ## • `` -> `...70` ## • `` -> `...71` ## • `` -> `...72` ## • `` -> `...73` ## • `` -> `...74` ## • `` -> `...75` ## • `` -> `...76` ## • `` -> `...77` ## • `` -> `...78` ## • `` -> `...79` ## • `` -> `...80` ## • `` -> `...81` ## • `` -> `...82` ## • `` -> `...83` ## • `` -> `...84` ## • `` -> `...85` ## • `` -> `...86` ## • `` -> `...87` ## • `` -> `...88` ## • `` -> `...89` ## • `` -> `...90` ## • `` -> `...91` ## • `` -> `...92` ## • `` -> `...93` ## • `` -> `...94` ## • `` -> `...95` ## • `` -> `...96` ## • `` -> `...97` ## • `` -> `...98` ## • `` -> `...99` ## • `` -> `...100` ## • `` -> `...101` ## • `` -> `...102` ## • `` -> `...103` ## • `` -> `...104` ## • `` -> `...105` ## • `` -> `...106` ## • `` -> `...107` ## • `` -> `...108` ## • `` -> `...109` ## • `` -> `...110` ## • `` -> `...111` ## • `` -> `...112` ## • `` -> `...113` ## • `` -> `...114` ## • `` -> `...115` ## • `` -> `...116` ## • `` -> `...117` ## • `` -> `...118` ## • `` -> `...119` ## • `` -> `...120` ## WARN [2025-09-27 21:54:41] Observed probabilities map skipped: expected 216 rows but found 80. result ##  ##  █▀▀ Searchlight Analysis Results ▀▀█  ##  ## ├─ Coverage  ## │  ├─ Voxels/Vertices in Mask:  216  ## │  └─ Voxels/Vertices with Results:  120  ## └─ Output Maps (Metrics)  ##    ├─  Accuracy  (Type:  DenseNeuroVol )  ##    ├─  AUC  (Type:  DenseNeuroVol ) if (plot_ok && !is.null(result$results$AUC)) {   auc_vals <- as.numeric(neuroim2::values(result$results$AUC))   auc_vals <- auc_vals[is.finite(auc_vals)]   if (length(auc_vals) > 0) {     safe_plot_hist(auc_vals, title = \"Searchlight AUC (centered)\")   } else {     message(\"No finite AUC values to plot.\")   } }"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Searchlight_Analysis.html","id":"run-a-randomized-searchlight-analysis","dir":"Articles","previous_headings":"","what":"Run a randomized searchlight analysis","title":"Searchlight Analysis","text":"randomized searchlight analysis iterative procedure searchlight regions sampled without replacement voxel set. classification analysis run region, result recorded center voxel voxels region. done niter times, iteration involves exhaustive sampling voxel set. performance voxel average performance set analyses given voxel included feature. result similar standard searchlight procedure, emphasizes contribution given voxel across different local contexts classification performance. principle offer slightly better spatial localization standard searchlight. randomized searchlight procedure can also faster, total number estimated models function nvoxels/radius * niter, smaller nvoxels many choices radius niter.","code":"result <- run_searchlight(model, radius=4, method=\"randomized\", niter=8) ## INFO [2025-09-27 21:54:41] Running randomized searchlight with radius = 4 and niter = 8 ## INFO [2025-09-27 21:54:41] 🔄 Starting randomized searchlight analysis: ## INFO [2025-09-27 21:54:41] ├─ Radius: 4 ## INFO [2025-09-27 21:54:41] └─ Iterations: 8 ## INFO [2025-09-27 21:54:41]  ## 📊 Iteration 1/8 ## INFO [2025-09-27 21:54:41] ⚡ Processing batch 1/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:43] ⚡ Processing batch 2/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:44] ⚡ Processing batch 3/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:45]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:54:45]  ## 📊 Iteration 2/8 ## INFO [2025-09-27 21:54:45] ⚡ Processing batch 1/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:46] ⚡ Processing batch 2/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:47] ⚡ Processing batch 3/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:49]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:54:49]  ## 📊 Iteration 3/8 ## INFO [2025-09-27 21:54:49] ⚡ Processing batch 1/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:50] ⚡ Processing batch 2/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:51] ⚡ Processing batch 3/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:52]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:54:52]  ## 📊 Iteration 4/8 ## INFO [2025-09-27 21:54:53] ⚡ Processing batch 1/4 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:54] ⚡ Processing batch 2/4 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:55] ⚡ Processing batch 3/4 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:56] ⚡ Processing batch 4/4 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:57]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 4 ## ├─ Processed: 4 ## └─ Skipped: 0 ## INFO [2025-09-27 21:54:57]  ## 📊 Iteration 5/8 ## INFO [2025-09-27 21:54:57] ⚡ Processing batch 1/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:54:58] ⚡ Processing batch 2/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:00] ⚡ Processing batch 3/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:01]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:55:01]  ## 📊 Iteration 6/8 ## INFO [2025-09-27 21:55:01] ⚡ Processing batch 1/2 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:02] ⚡ Processing batch 2/2 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:03]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 2 ## ├─ Processed: 2 ## └─ Skipped: 0 ## INFO [2025-09-27 21:55:04]  ## 📊 Iteration 7/8 ## INFO [2025-09-27 21:55:04] ⚡ Processing batch 1/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:05] ⚡ Processing batch 2/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:06] ⚡ Processing batch 3/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:07]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:55:07]  ## 📊 Iteration 8/8 ## INFO [2025-09-27 21:55:07] ⚡ Processing batch 1/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:08] ⚡ Processing batch 2/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:09] ⚡ Processing batch 3/3 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:11]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 3 ## ├─ Processed: 3 ## └─ Skipped: 0 ## INFO [2025-09-27 21:55:11]  ## ✨ Searchlight Analysis Complete ## INFO [2025-09-27 21:55:11] ├─ Total Models Fit: 24 ## INFO [2025-09-27 21:55:11] └─ All ROIs processed successfully! result ##  ##  █▀▀ Searchlight Analysis Results ▀▀█  ##  ## ├─ Coverage  ## │  ├─ Voxels/Vertices in Mask:  216  ## │  └─ Voxels/Vertices with Results:  120  ## └─ Output Maps (Metrics)  ##    ├─  Metric1  (Type:  DenseNeuroVol )  ##    ├─  Metric2  (Type:  DenseNeuroVol ) if (plot_ok && !is.null(result$results$AUC)) {   auc_vals <- as.numeric(neuroim2::values(result$results$AUC))   auc_vals <- auc_vals[is.finite(auc_vals)]   if (length(auc_vals) > 0) {     safe_plot_hist(auc_vals, title = \"Randomized Searchlight AUC (centered)\")   } else {     message(\"No finite AUC values to plot.\")   } }"},{"path":"http://bbuchsbaum.github.io/rMVPA/articles/Searchlight_Analysis.html","id":"using-different-classifiers","dir":"Articles","previous_headings":"","what":"Using different classifiers","title":"Searchlight Analysis","text":"classifiers MVPAModels registry can used searchlight analysis. Additional models can registered using register_mvpa_model(). example, run analysis using built-model: specify range values mtry tuning parameter. case, supplying tune_reps argument mvpa_model control number resamples used tune model parameters. default 10, speed execution time reducing 2. general, resamples required reliably estimate optimal tuning parameters. means whole-brain searchlight, parameter tuning generally impractical. classifier sda_notune good choice searchlight analyses, since “works well” default tuning parameters.","code":"svm_model <- load_model(\"svmLinear\")  model <- mvpa_model(model=svm_model, dataset=dataset$dataset, design=dataset$design, crossval=crossval) result_svm <- run_searchlight(model, radius=4, method=\"randomized\", niter=2) if (requireNamespace(\"randomForest\", quietly = TRUE)) {   rf_model <- load_model(\"rf\")   model <- mvpa_model(model = rf_model, dataset = dataset$dataset, design = dataset$design,                       crossval = crossval, tune_grid = data.frame(mtry = 2))   result_rf <- run_searchlight(model, radius = 4, method = \"randomized\", niter = 2) } else {   message(\"Package 'randomForest' not installed; skipping RF example.\") } ## INFO [2025-09-27 21:55:11] Running randomized searchlight with radius = 4 and niter = 2 ## INFO [2025-09-27 21:55:11] 🔄 Starting randomized searchlight analysis: ## INFO [2025-09-27 21:55:11] ├─ Radius: 4 ## INFO [2025-09-27 21:55:11] └─ Iterations: 2 ## INFO [2025-09-27 21:55:11]  ## 📊 Iteration 1/2 ## INFO [2025-09-27 21:55:11] ⚡ Processing batch 1/2 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:12] ⚡ Processing batch 2/2 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:14]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 2 ## ├─ Processed: 2 ## └─ Skipped: 0 ## INFO [2025-09-27 21:55:14]  ## 📊 Iteration 2/2 ## INFO [2025-09-27 21:55:14] ⚡ Processing batch 1/2 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:16] ⚡ Processing batch 2/2 (1 ROIs in this batch) ## INFO [2025-09-27 21:55:17]  ## ✨ MVPA Iteration Complete ## ├─ Total ROIs: 2 ## ├─ Processed: 2 ## └─ Skipped: 0 ## INFO [2025-09-27 21:55:17]  ## ✨ Searchlight Analysis Complete ## INFO [2025-09-27 21:55:17] ├─ Total Models Fit: 4 ## INFO [2025-09-27 21:55:17] └─ All ROIs processed successfully! if (requireNamespace(\"randomForest\", quietly = TRUE)) {   grid <- data.frame(mtry = c(2, 4, 6, 8))   model2 <- mvpa_model(model = rf_model, dataset = dataset$dataset, design = dataset$design,                        crossval = crossval, tune_grid = grid, tune_reps = 2)   result_rf_tuned <- run_searchlight(model2, radius = 6, method = \"randomized\", niter = 1) } else {   message(\"Package 'randomForest' not installed; skipping tuned RF example.\") }"},{"path":"http://bbuchsbaum.github.io/rMVPA/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Bradley Buchsbaum. Author, maintainer.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Buchsbaum B (2025). rMVPA: Multivoxel Pattern Analysis R. R package version 0.1.2, http://bbuchsbaum.github.io/rMVPA/.","code":"@Manual{,   title = {rMVPA: Multivoxel Pattern Analysis in R},   author = {Bradley Buchsbaum},   year = {2025},   note = {R package version 0.1.2},   url = {http://bbuchsbaum.github.io/rMVPA/}, }"},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan.html","id":null,"dir":"","previous_headings":"","what":"Contrast RSA Integration Plan for rMVPA","title":"Contrast RSA Integration Plan for rMVPA","text":"document outlines steps integrate Multi-Dimensional Signed Representational Voxel Encoding (MS-ReVE) approach rMVPA package, primarily new contrast_rsa_model. ** Always check items done. ** Conceptual plan signed_rsa_proposal.md","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan.html","id":"phase-1-core-model-implementation","dir":"","previous_headings":"","what":"Phase 1: Core Model Implementation","title":"Contrast RSA Integration Plan for rMVPA","text":"Define new S3/S4 class msreve_design. Include slots underlying mvpa_design object. Include slot user-defined contrast_matrix (C, K x Q). Document class purpose. (Optional) Add helper function orthogonalize_contrasts(C) users. Input: mvpa_dataset subset searchlight (sl_data), mvpa_design, cv_spec, estimation_method parameter. cv_spec object generated user functions R/crossval.R (e.g., blocked_cross_validation(mvpa_design$block_var)), defining specific CV strategy. Implement logic compute K x V_sl matrix Û_sl based cross-validation folds defined cv_spec (using helpers like train_indices() get_nfolds()). Support different estimation_methods (e.g., “average_betas”, potentially others later). Add unit tests function. Define new S3 class contrast_rsa_model (inheriting mvpa_model_spec inherits model_spec). Crucially, constructor must use create_model_spec(\"contrast_rsa_model\", ...) internally properly instantiate model object. Takes mvpa_dataset. Takes msreve_design object. Takes parameters: estimation_method, regression_type, output_metric. Add documentation examples constructor. Input: obj (contrast_rsa_model), sl_data, sl_info (containing center voxel index/ID). Step 1: Call compute_crossvalidated_means_sl get Û_sl. Step 2: Compute Ĝ_sl = Û_sl %*% t(Û_sl). Vectorize Ĝ_sl (dvec_sl). Create predictor matrix X_sl obj$design$contrast_matrix. (Reuse/adapt rsa_model_mat logic). Handle block_var exclusions necessary. Step 4: Run regression (using obj$regression_type) get β_sl (Q-vector). Reuse run_lm, run_lm_constrained, etc. Step 5: Compute Δ_sl = t(Û_sl) %*% C (V_sl x Q matrix). Step 6: Extract center voxel’s projection Δ_{v_c,sl} (Q-vector) using sl_info. Step 7: Calculate final result_vector based obj$output_metric (e.g., β_sl * Δ_{v_c,sl}). Step 8: Return named result_vector (Q-dimensional). Add robust error handling within function. Add unit tests method (mocking dependencies).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan.html","id":"phase-2-searchlight-integration","dir":"","previous_headings":"","what":"Phase 2: Searchlight Integration","title":"Contrast RSA Integration Plan for rMVPA","text":"Ensure searchlight generation code (volume surface) makes center voxel’s index/ID available sl_info object passed iterator function. Input: model_spec (contrast_rsa_model), slight (list searchlights), cind (center indices). Iterate searchlights. Extract data (sl_data) center voxel info (sl_info) searchlight. Call train_model.contrast_rsa_model(model_spec, sl_data, sl_info, ...) Collect results (Q-vectors) error status standard data frame format compatible combiners. Input: model_spec, good_results, bad_results. Extract center voxel IDs good_results$id. Extract list Q-vectors good_results$performance. Bind vectors N_voxels x Q matrix. Create Q separate output maps (e.g., SparseNeuroVec NeuroSurfaceVector), one per column (contrast). Name appropriately. Ensure output maps (layers) named based contrast names. Return result object (e.g., msreve_searchlight_result) containing list Q maps. Define method signature. Call run_searchlight_base internally. Pass mvpa_fun = msreve_iterate. Pass combiner = combine_msreve_standard. Handle method-specific arguments necessary (e.g., currently supporting “standard” method).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan.html","id":"phase-3-documentation--testing","dir":"","previous_headings":"","what":"Phase 3: Documentation & Testing","title":"Contrast RSA Integration Plan for rMVPA","text":"Create new vignette demonstrating use contrast_rsa_model. Include example data setup, model definition, execution, interpretation results. Write tests covering end--end workflow volume surface data. Ensure new functions classes clear Roxygen documentation. Update relevant sections package README overview documentation. Wrap train_model.contrast_rsa_model ROI-based analysis (analogous run_regional methods). Consider custom process_roi.contrast_rsa_model method needed whole-ROI processing differs significantly searchlight processing beyond train_model can handle.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan_phase2.html","id":null,"dir":"","previous_headings":"","what":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","title":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","text":"document outlines features refinements added contrast_rsa_model functionality based original proposal (signed_rsa_proposal.md) current implementation state. Keep things modular simple! God functions! functions 100 lines! ** always check checkboxes done **","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan_phase2.html","id":"core-engine-enhancements-section-c-of-proposal","dir":"","previous_headings":"","what":"Core Engine Enhancements (Section C of Proposal)","title":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","text":"Advanced Û Estimation (C.1): Implemented \"L2_norm\" \"crossnobis\" (requiring user-supplied whitening matrix W) options compute_crossvalidated_means_sl. (methods like internal Σ estimation crossnobis betas future enhancements needed, current implementation relies pre-computed W derived GLM residuals per best practice). RSA Regularization (C.3): Implement regularization options (\"ridge_hkb\" added Hoerl-Kennard-Baldwin lambda). (options like GCV, fixed lambda, elastic-net still pending future enhancement). RSA Collinearity Check (C.3): Implement check_collinearity=TRUE functionality contrast_rsa_model constructor check rank contrast RDM predictor matrix (Xmat). Normalized Δ_q Contributions (C.4): Add option (normalize_delta parameter contrast_rsa_model) calculate potentially use normalized voxel contributions (~Δ_q = Δ_q / ||Δ_q||).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan_phase2.html","id":"voxel-level-refinements-section-d-of-proposal","dir":"","previous_headings":"","what":"Voxel-Level Refinements (Section D of Proposal)","title":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","text":"Voxel Reliability Weighting (ρ_q,v) (D.1): Implement calculation voxel contribution reliability across cross-validation folds within train_model.contrast_rsa_model. requires storing fold-specific U_hat_sl Delta_sl. Context: Voxel Reliability (ρ_q,v)? β · Δ map answers: direction strongly voxel v contribute contrast q average within searchlight? Reliability (ρ_q,v) answers follow-: contribution repeatable across different subsets data (folds)? Intuition: Δ_q,v jumps wildly fold fold, ’s likely driven noise. ρ scales 0 (unreliable) 1 (perfectly stable). Formula: [ _{q,v} = 1 -  ] Numerator: Empirical fold--fold variance voxel’s contribution. Denominator: Adds expected noise variance (σ²_noise) prevent -penalizing stable signals measured limited data. Noise Variance Estimation (σ²_noise,q,v): represents expected variance Δ_q,v true signal zero. ’s derived within-condition residual variances (σ²_k,v(s)) estimated noise whitening/pre-processing stage, weighted contrast weights (w_qk) number trials (n_k(s)) per condition k fold s: [ ^2_{,q,v} =  {s=1}^{S} {k=1}^{K}  _{k,v}^{2(s)} ] (requires access within-condition residual variances, might need passed estimated differently depending exact preprocessing pipeline, e.g., using GLM residuals). Practical Use: Generate reliability-weighted maps: [ M^{}{q,v} = {q,v} ; q , {q,v} ] Context: Implementation Cost & Strategies ρ_q,v Challenge: Storing Δ_q,v every fold (S), contrast (Q), voxel (V) every searchlight (#SL) can consume significant RAM (e.g., S × Q × V × #SL × 8 bytes). --fly Welford variance: Update running mean sum squared differences (M2) Δ_q,v fold’s Δ_fold arrives. Discard Δ_fold afterwards. Requires O(Q × V) memory buffer per searchlight. R     # Pseudo-R Welford inside sphere loop     # Needs mean_D, m2_D (QxV) initialized     delta <- Delta_fold - mean_D     mean_D <- mean_D + delta / fold_id     m2_D <- m2_D + delta * (Delta_fold - mean_D)     # loop: var_D <- m2_D / (S - 1) Center-voxel : Compute store ρ_q,v center voxel searchlight. Reliability information gets implicitly smoothed across brain overlapping searchlights. Split-half reliability (S=2): using two folds (e.g., odd vs. even runs), variance analytic: Var = (Δ₁ - Δ₂)² / 4. Matches Walther et al. (2016) approach. Coarser cheap. Jack-knife (Leave-One-Run-, S >= 3): Recompute Δ leaving run s (Δ_(-s)). Variance computed S pseudo-values. Requires minimal extra buffering Δ_(-s) recomputed demand. jack_var = (S-1)/S * sum( (Delta_neg_s - mean(Delta_neg_s))^2 ) Bootstrap (Fold-level Resampling, S >= 3): Sample S folds replacement B times (e.g., B=100). Compute variance Δ across bootstrap samples. CPU scales B, uses pre-computed per-fold Δ (stored/cached) recomputes fly. Recommendation: Welford Jack-knife offer good precision low memory overhead S >= 3. Split-half viable S=2 coarse reliability sufficient.  [Future Plan] Detailed Implementation Notes Reliability (ρ_q,v) Based discussion implementation efficiency blueprint provided: Guiding Principles: Avoid modifying compute_crossvalidated_means_sl return fold-wise data. Compute fold-specific Δ (Delta_fold_sl) --fly within train_model.contrast_rsa_model. Use Welford’s online algorithm variance calculation minimize memory. Gate feature behind calc_reliability flag contrast_rsa_model constructor (defaulting FALSE). Proposed rho Formula: Use ICC-like form rho = sigma2_noise_param / (var_delta + sigma2_noise_param) sigma2_noise_param = (S-1) * var_delta S > 1 (number folds). simplifies rho = (S-1)/S var_delta > 0. Handle edge cases: var_delta = 0 (perfect stability), rho = 1. S = 1, rho = 0 (unless var_delta = 0, rho = 1). Implementation Steps: 1. contrast_rsa_model Constructor (R/contrast_rsa_model.R): * Add calc_reliability = FALSE parameter. * Store model spec via create_model_spec. * Update Roxygen docs. 2. train_model.contrast_rsa_model (R/contrast_rsa_model.R): * Initialize rho_vc_sl = rep(1, Q) (default: neutral weight). * obj$calc_reliability TRUE: * Get S = get_nfolds(cv_spec). * Get C, V_sl, Q, mvpa_des. * Initialize Welford accumulators: m_Delta_sl = matrix(0, V_sl, Q), M2_Delta_sl = matrix(0, V_sl, Q). * Loop s_idx 1 S: * Get train_indices_fold_s. * Handle empty/problematic folds (skip ensure NA propagation). * Compute U_hat_sl_fold_s (K x V_sl) using logic similar compute_cv_means (subsetting sl_data, aggregate, re-indexing, handling missing conditions -> NAs). * anyNA(U_hat_sl_fold_s), skip Welford update fold ensure NAs propagate correctly. * Delta_fold_sl = t(U_hat_sl_fold_s) %*% C (V_sl x Q). * Perform Welford update m_Delta_sl M2_Delta_sl using Delta_fold_sl. * loop (let S_eff number valid folds processed): * Initialize rho_sl = matrix(0, V_sl, Q). * S_eff > 1: * var_Delta_sl = M2_Delta_sl / (S_eff - 1). * sigma2_noise_param_sl = (S_eff - 1) * var_Delta_sl. * denominator_rho = var_Delta_sl + sigma2_noise_param_sl. * rho_sl = sigma2_noise_param_sl / denominator_rho. * Handle denominator_rho < 1e-10 (set rho_sl = 1). * Handle NA values rho_sl (set rho_sl = 0). * Else S_eff == 1: * Handle perfect stability case: rho_sl[M2_Delta_sl == 0] = 1. * Extract rho_vc_sl = rho_sl[center_idx, , drop = TRUE]. * Modify final metric calculation: R         final_delta_vc_sl = delta_vc_sl # Potentially normalized delta         (obj$output_metric == \"beta_delta\") {             # Apply reliability weight             result_vector <- beta_sl * final_delta_vc_sl * rho_vc_sl          } else (obj$output_metric == \"delta_only\") {             # Keep raw (potentially normalized) delta? apply rho?             # Decision needed: now, keep .             result_vector <- final_delta_vc_sl          } else { # beta_only             result_vector <- beta_sl         } Voxel-Specific RDM Reconstruction (r_v) (D.2): Implement calculation voxel-specific RDM reconstruction score (r_v) \"recon_score\" output metric. Context: Voxel Reconstruction Score (r_v)? metric answers: much single voxel v, specific profile contributions across contrasts Q, matter reproducing overall representational geometry (Ĝ_empirical) observed searchlight? Intuition: ’s “leave-one-voxel-” score. r_v ≈ 1, single voxel carries much information pairwise condition distances relevant contrasts. r_v ≈ 0, geometry relies pattern across voxels. Building One-Voxel Model RDM (Ĝ^(v)): Use voxel’s signed contributions (Δ_q,v) scaled overall contrast importance (β_q) searchlight. Project Q-dimensional profile back KxK condition space using contrast matrix C: [ ^{(v)} = C ; (1 {1,v}, , Q {Q,v}) ; C^T ] Calculating Score (r_v): Correlate vectorized lower triangle one-voxel RDM (Ĝ^(v)) vectorized lower triangle empirical RDM (Ĝ_empirical) searchlight: [ r_v = ( {}(^{(v)}), ; {}(_{}) ) ] Interpretation: map r_v (|r_v|) highlights voxels individually highly informative multi-contrast representational structure. Implementation Cost: low. Requires C, β_q, Δ_q,v, vec(Ĝ_empirical), already computed. matrix multiplications per voxel small (KxQ, QxQ, QxK). correlation two vectors length K(K-1)/2.","code":"# Pseudo-R for r_v inside sphere loop, after beta & Delta computed y_emp <- lower(G_hat_empirical) # Precompute beta_diag <- diag(beta)         # QxQ r_v <- numeric(V) for (v in 1:V) {    # Delta is V x Q or Q x V depending on implementation    # Assuming Delta is V x Q here:    voxel_loading_diag <- diag(beta * Delta[v, ]) # Corrected: element-wise product    G_hat_v <- C %*% voxel_loading_diag %*% t(C)    r_v[v] <- cor(lower(G_hat_v), y_emp) }"},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan_phase2.html","id":"additional-output-maps-section-e-of-proposal","dir":"","previous_headings":"","what":"Additional Output Maps (Section E of Proposal)","title":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","text":"Direction-Maps (~M_q,v) (E.1): Add output_metric option (\"beta_delta_norm\") contrast_rsa_model generate maps based normalized Δ_q (β_q * ~Δ_{q,v}). Reliability-Weighted Maps (M_q,v_reliab) (E.1): Add output_metric option (e.g., \"beta_delta_reliable\") generate maps weighted voxel reliability (ρ_{q,v} * β_q * Δ_{q,v}). Requires completion D.1. Composite Map (w_v) (E.2): Add output_metric option (\"composite\") calculate composite map representing net pull voxel (e.g., Σ_q (β_q * ~Δ_{q,v})), including orthonormality check.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan_phase2.html","id":"documentation--examples","dir":"","previous_headings":"","what":"Documentation & Examples","title":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","text":"Add Examples (@examples): Add runnable examples exported functions, particularly contrast_rsa_model() run_searchlight.contrast_rsa_model(), creating necessary dummy objects. Update Documentation: Ensure new parameters options added Phase 2 clearly documented.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan_phase2.html","id":"refactoring--code-quality","dir":"","previous_headings":"","what":"Refactoring & Code Quality","title":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","text":"Refactor wrap_out/create_searchlight_performance: Simplify interaction functions R/searchlight.R. (Done making wrap_out directly create spatial objects commenting create_searchlight_performance, adjusting print.searchlight_result). Check cv_spec Validity: Implement TODO check cv_spec validity R/compute_cv_means.R. Verify DESCRIPTION: Double-check necessary package dependencies (neuroim2, neurosurf, dplyr, purrr, etc.) correctly listed Imports field DESCRIPTION file. Review Block Exclusion Logic (C4): Addressed deriving condition_block_list msreve_design using train_model.contrast_rsa_model. Replace aggregate rowsum compute_cv_means (Audit Quick Win #2): Replaced stats::aggregate rowsum table calculating fold-wise condition means performance.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/contrast_rsa_plan_phase2.html","id":"appendix-context-on-interaction-effects-section-f","dir":"","previous_headings":"","what":"Appendix: Context on Interaction Effects (Section F)","title":"Contrast RSA / MS-ReVE Phase 2 Implementation Plan","text":"Interactions Matter RSA: Main effect contrasts test simple geometric predictions (e.g., animate vs. inanimate separation). Interactions test geometry extra structure beyond sum main effects. Construction: interaction contrast column (c_inter) element-wise product (⊙) two centered main effect columns (c_p, c_q): c_inter = c_p ⊙ c_q. Interaction RDM: model RDM interaction (R_inter = c_inter %*% t(c_inter)) predicts similarity (+1) condition pairs sharing interaction sign (e.g., [+p, +q] [-p, -q]) dissimilarity (-1) pairs differing interaction sign (e.g., [+p, +q] vs. [+p, -q]). captures pattern orthogonal main effect RDMs. Orthogonalization: ’s crucial orthogonalize full contrast matrix C_exp = [C_main | C_inter] (e.g., using rMVPA::contrasts(..., orth=TRUE) rMVPA::orthogonalize_contrasts()). ensures regression coefficient β_inter reflects variance uniquely explained interaction term accounting main effects. Interpretation: - Δ_inter,v = t(U_hat) %*% c_tilde_inter: Voxel v’s projection onto orthogonalized interaction contrast. - β_inter * Δ_inter,v: strongly voxel v contributes uniquely interaction pattern. - Example: voxel might respond strongly “animate-small” conditions, contributing positively animacy--size interaction, even response animacy size alone isn’t distinct. Workflow: Define interactions spec rMVPA::contrasts(), ensure orth=TRUE, run contrast_rsa_model. engine handles interaction columns like contrast.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"id_0-paper-summary--motivation","dir":"","previous_headings":"","what":"0 Paper Summary & Motivation","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"cross-nobis (.k.. cross-validated Mahalanobis) distance provides unbiased estimate true squared pattern distance multiplying pattern differences estimated independent data partitions. Ordinary (-fold) distances positively biased noise multiplied . Formal definition condition pair (k=(,j)) (M) partitions (Eq. 5, Diedrichsen & Kriegeskorte 2017): [ d_k = {mn} {k,m}^{T},{k,n}, {k,m}=b_{,m}-b_{j,m}, ] (P) number voxels/channels. Equivalent “single-fold-vs-rest” algebra can also used. Key properties * Unbiased: (E[d_k]=_k{T}k/P). * Can negative true distance ~0 – keep values, truncate. * Variance () times larger biased estimator decreases partitions. * Whitening: pre-multiply patterns (W={}{-1/2}) obtain Mahalanobis distances; crucial fMRI. (Sections 1–9 incorporate theory.)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"id_1-high-level-requirements","dir":"","previous_headings":"","what":"1 High-Level Requirements","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"Produce unbiased squared distances …(unchanged previous draft) // … existing content sections 1–9 crossnobis.md retained unchanged …","code":""},{"path":[]},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"a1-step-wise-implementation-table-adapted-from-user-note","dir":"","previous_headings":"Appendix A Detailed Implementation Table & Sanity-Check Code","what":"A.1 Step-wise Implementation Table (adapted from user note)","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"","code":"crossnobis_distance <- function(U_folds) {   K <- dim(U_folds)[1]; V <- dim(U_folds)[2]; M <- dim(U_folds)[3]   if (M < 2) rlang::abort(\"Need at least two partitions for cross-nobis.\")   pair_mat <- utils::combn(K, 2)   D <- ncol(pair_mat)   out <- numeric(D)   P <- V   for (p in seq_len(D)) {     i <- pair_mat[1, p]; j <- pair_mat[2, p]     deltas <- U_folds[i, , ] - U_folds[j, , ]   # V × M     ip <- tcrossprod(t(deltas))                 # M × M inner products     diag(ip) <- 0     out[p] <- sum(ip) / (P * M * (M - 1))   }   names(out) <- paste0(dimnames(U_folds)[[1]][pair_mat[1, ]], \"_vs_\",                         dimnames(U_folds)[[1]][pair_mat[2, ]])   out }"},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"a2-quick-sanity-check","dir":"","previous_headings":"Appendix A Detailed Implementation Table & Sanity-Check Code","what":"A.2 Quick Sanity-Check","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"","code":"set.seed(1) K <- 4; V <- 30; M <- 8 true <- matrix(rnorm(K*V), K, V)          # ground-truth patterns noise <- array(rnorm(K*V*M, sd = 3), c(K, V, M)) U_folds <- true + noise                   # simulated noisy means per fold cross_d <- crossnobis_distance(U_folds) mean(cross_d)   # ≈ 0 for pure noise case"},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"id_10-checkable-implementation-tickets","dir":"","previous_headings":"","what":"10 Checkable Implementation Tickets","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"section breaks implementation plan granular, checkable tasks specified R files new helper function. Always check task complete .","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"new-helper-function-eg-in-rcrossnobis_helpersr-or-similar","dir":"","previous_headings":"10 Checkable Implementation Tickets","what":"New Helper Function (e.g., in R/crossnobis_helpers.R or similar)","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"U_folds: K x V x M array condition means per fold (K=conditions, V=voxels, M=folds). P_voxels: Number voxels (V). Handle edge case: M < 2, abort informative message. Generate unique unordered condition pairs (e.g., using utils::combn(K, 2)). Initialize sum_cross_prods_k = 0. Calculate delta_k_m = U_folds[,,m] - U_folds[j,,m]. Calculate delta_k_n = U_folds[,,n] - U_folds[j,,n]. Add crossprod(delta_k_m, delta_k_n) sum_cross_prods_k. Calculate d_crossnobis_k = sum_cross_prods_k / (P_voxels * M * (M - 1)). Return named numeric vector d_crossnobis_k values, names like “condA_vs_condB”, ordered match lower-triangle vectorization. Handle potential NAs U_folds (e.g., condition missing fold): ensure resulting distances involving conditions NA, relevant pairs skipped. Add Roxygen documentation new function.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"rcompute_cv_meansr-changes-to-compute_crossvalidated_means_sl","dir":"","previous_headings":"10 Checkable Implementation Tickets","what":"R/compute_cv_means.R (Changes to compute_crossvalidated_means_sl)","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"Add new boolean argument return_folds = FALSE compute_crossvalidated_means_sl. return_folds = TRUE, change return value list: list(mean_estimate = U_hat_sl, fold_estimates = U_folds_array), U_folds_array (K x V x M). return_folds = FALSE (default), return U_hat_sl (mean_estimate list). Inside loop folds, store fold_means_mat_processed (K_fold x V matrix conditions present current fold) re-indexing full_fold_means. Collect fold_means_mat_processed (full_fold_means equivalent containing NAs absent conditions) U_folds_array (K x V x M). Ensure estimation_method == \"crossnobis\" (passed compute_cv_means) whitening_matrix_W provided, whitening (fold_means_mat %*% whitening_matrix_W) applied patterns form U_folds_array. (Current logic already fold_means_mat_processed). Update Roxygen compute_crossvalidated_means_sl detailing return_folds new list return type.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"rcontrast_rsa_modelr","dir":"","previous_headings":"10 Checkable Implementation Tickets","what":"R/contrast_rsa_model.R","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"Re-enable estimation_method = \"crossnobis\" match.arg(). (Remove rlang::abort ). Add argument whitening_matrix_W = NULL function signature. Store whitening_matrix_W model specification object (e.g., x$whitening_matrix_W <- whitening_matrix_W). Reflect “crossnobis” valid estimation_method. Document new whitening_matrix_W argument, purpose crossnobis, ’s passed compute_crossvalidated_means_sl. Declare U_hat_for_delta_calc (hold K x V matrix Δ projections). Declare dvec_sl (hold vector (dis)similarities regression). estimation_method = \"crossnobis\" (tells compute_cv_means handle whitening internally W passed). whitening_matrix_W = obj$whitening_matrix_W. return_folds = TRUE. Store result cv_outputs. Assign U_hat_for_delta_calc <- cv_outputs$mean_estimate. Let U_folds_data <- cv_outputs$fold_estimates. P_voxels <- ncol(sl_data). dvec_sl <- compute_crossnobis_distances_sl(U_folds_data, P_voxels). U_hat_for_delta_calc <- compute_crossvalidated_means_sl(sl_data, mvpa_des, cv_spec, obj$estimation_method, whitening_matrix_W = NULL) (Note: compute_cv_means correctly ignores W estimation_method “crossnobis”). G_hat_sl <- U_hat_for_delta_calc %*% t(U_hat_for_delta_calc). dvec_sl <- G_hat_sl[lower.tri(G_hat_sl)]. obj$estimation_method != \"crossnobis\", apply include_vec logic dvec_sl based G_hat_sl currently done. obj$estimation_method == \"crossnobis\", apply include_vec logic directly dvec_sl output compute_crossnobis_distances_sl (ensure mapping KxK is_intra_block_pair K(K-1)/2 dvec_sl elements correct). Calculate Delta_sl <- t(U_hat_for_delta_calc) %*% C_ord using consistently derived U_hat_for_delta_calc. (Rest RSA regression, metric calculation proceeds using dvec_sl beta_sl, Delta_sl appropriate). specific changes required whitening_matrix_W stored accessed model_spec train_model.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/crossnobis_plan.html","id":"rmsreve_designr","dir":"","previous_headings":"10 Checkable Implementation Tickets","what":"R/msreve_design.R","title":"Implementation Plan – Crossnobis Support for MS-ReVE / Contrast-RSA","text":"changes anticipated file based current crossnobis_plan.md.","code":""},{"path":[]},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/index.html","id":"introduction","dir":"","previous_headings":"Multivoxel Pattern Analysis in R","what":"Introduction","title":"Multivoxel Pattern Analysis in R","text":"rMVPA R library multivariate pattern analysis neuroimaging data. goal library make MVPA analyses easy. can used programmatically within R using command line interface. ‘rMVPA’ provides lightweight model registry efficient resampling methods machine learning. rMVPA provides infrastructure conducting machine learning analyses neuroimaging data. Documentation vignettes: https://bbuchsbaum.github.io/rMVPA/","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/index.html","id":"using-devtools","dir":"","previous_headings":"Multivoxel Pattern Analysis in R","what":"Using devtools","title":"Multivoxel Pattern Analysis in R","text":"install rMVPA within R, use devtools function install_github. need development version neuroim2 well. within R:","code":"#library(devtools) install_github(\"bbuchsbaum/neuroim2\") install_github(\"bbuchsbaum/rMVPA\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/index.html","id":"using-git-from-the-command-line","dir":"","previous_headings":"Multivoxel Pattern Analysis in R","what":"Using git from the command line","title":"Multivoxel Pattern Analysis in R","text":"","code":"git clone git@github.com:bbuchsbaum/rMVPA.git R CMD install rMVPA"},{"path":"http://bbuchsbaum.github.io/rMVPA/index.html","id":"optionally-install-command-line-scripts-for-coding-free-mvpa-analysis","dir":"","previous_headings":"Multivoxel Pattern Analysis in R","what":"Optionally install command line scripts for “coding-free” MVPA analysis:","title":"Multivoxel Pattern Analysis in R","text":"wget https://raw.githubusercontent.com/bbuchsbaum/rMVPA/master/scripts/MVPA_Searchlight.R wget https://raw.githubusercontent.com/bbuchsbaum/rMVPA/master/scripts/MVPA_Regional.R , move files folder PATH make executable: chmod +x MVPA_Searchlight.R chmod +x MVPA_Regional.R MS-ReVE functionality implemented R/contrast_rsa_model.R. file named contrast_rsa.R; references use contrast_rsa_model.R filename.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/MVPAModels.html","id":null,"dir":"Reference","previous_headings":"","what":"Pre-defined MVPA Classification Models — MVPAModels","title":"Pre-defined MVPA Classification Models — MVPAModels","text":"environment containing custom classification models MVPA analysis.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/MVPAModels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pre-defined MVPA Classification Models — MVPAModels","text":"","code":"MVPAModels"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/MVPAModels.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pre-defined MVPA Classification Models — MVPAModels","text":"environment following models: corclass Correlation-based classifier using template matching options (pearson, spearman, kendall) corsim Alias corclass sda_notune Shrinkage Discriminant Analysis (SDA) without parameter tuning sda_boot SDA bootstrap resampling feature selection glmnet_opt Elastic net classifier (glmnet) optimized alpha/lambda via EPSGO sparse_sda SDA sparsity constraints feature selection sda_ranking SDA feature ranking selection via higher criticism mgsda Multi-Group Sparse Discriminant Analysis lda_thomaz Modified LDA classifier high-dimensional data hdrda High-Dimensional Regularized Discriminant Analysis","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/MVPAModels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pre-defined MVPA Classification Models — MVPAModels","text":"Models accessed via load_model(name). model specification includes fit, predict, prob methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/MVPAModels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pre-defined MVPA Classification Models — MVPAModels","text":"","code":"# Load simple SDA classifier model <- load_model(\"sda_notune\")  # Load correlation classifier model <- load_model(\"corclass\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/add_interaction_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Interaction Contrasts to an msreve_design — add_interaction_contrasts","title":"Add Interaction Contrasts to an msreve_design — add_interaction_contrasts","text":"Creates new contrast columns representing pairwise interactions existing contrasts msreve_design object. Interactions computed element-wise products contrast vectors.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/add_interaction_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Interaction Contrasts to an msreve_design — add_interaction_contrasts","text":"","code":"add_interaction_contrasts(design, pairs = NULL, orthogonalize = TRUE)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/add_interaction_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Interaction Contrasts to an msreve_design — add_interaction_contrasts","text":"design object class msreve_design. pairs Optional two-column matrix list character vectors specifying pairs contrast column names. Default NULL uses pairwise combinations. orthogonalize Logical; TRUE (default) expanded contrast matrix passed orthogonalize_contrasts.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/add_interaction_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Interaction Contrasts to an msreve_design — add_interaction_contrasts","text":"updated msreve_design object non-zero interaction   columns appended. Zero interactions automatically skipped.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/add_interaction_contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Interaction Contrasts to an msreve_design — add_interaction_contrasts","text":"Interaction contrasts created element-wise multiplication pairs contrast vectors. resulting interaction zero vector (occurs original contrasts non-overlapping support, .e., conditions contrasts non-zero), interaction skipped informative message. commonly happens contrasts compare distinct subsets conditions, c(1,-1,0,0) c(0,0,1,-1).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/add_interaction_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Interaction Contrasts to an msreve_design — add_interaction_contrasts","text":"","code":"if (FALSE) { # \\dontrun{ # Example with non-overlapping contrasts (zero interaction) C1 <- matrix(c(1,-1,0,0, 0,0,1,-1), nrow=4,               dimnames=list(NULL, c(\"A\",\"B\"))) # A compares conditions 1 vs 2, B compares 3 vs 4 # Their interaction will be zero and skipped  # Example with overlapping contrasts (non-zero interaction)   C2 <- matrix(c(1,1,-1,-1, 1,-1,1,-1), nrow=4,              dimnames=list(NULL, c(\"Main1\",\"Main2\"))) # These contrasts overlap and will produce a meaningful interaction } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/as_roi.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert object to ROI — as_roi","title":"Convert object to ROI — as_roi","text":"Convert provided object ROIVolume ROISurface object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/as_roi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert object to ROI — as_roi","text":"","code":"as_roi(obj, data, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/as_roi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert object to ROI — as_roi","text":"obj object converted. data associated data object. ... Additional arguments passed methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/as_roi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert object to ROI — as_roi","text":"ROIVolume ROISurface object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/average_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Average NeuroVec Data by Labels — average_labels","title":"Average NeuroVec Data by Labels — average_labels","text":"Computes average brain activation pattern unique label/condition, optional normalization individual volumes averaging.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/average_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average NeuroVec Data by Labels — average_labels","text":"","code":"average_labels(   neurovec,   labels,   mask = NULL,   normalize = c(\"none\", \"scale\", \"center\", \"z\", \"unit\", \"percent\"),   normalize_by = c(\"volume\", \"voxel\"),   na.rm = TRUE,   return_matrix = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/average_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average NeuroVec Data by Labels — average_labels","text":"neurovec NeuroVec object containing neuroimaging data labels vector labels/conditions corresponding volume neurovec mask optional mask (NeuroVol logical array) restrict analysis specific voxels normalize Character string specifying normalization method applied volume averaging. Note averaging normalized volumes, resulting averages may maintain normalization properties (e.g., averaged z-scored data SD < 1): \"none\" normalization (default) \"scale\" Scale volume unit variance (divide SD) \"center\" Center volume (subtract mean) \"z\" Z-score normalization (center scale) \"unit\" Scale unit norm (L2 normalization) \"percent\" Convert percent signal change volume mean normalize_by Character string specifying normalization scope: \"volume\" Normalize within volume (default) \"voxel\" Normalize voxel across time na.rm Logical, whether remove NA values averaging (default TRUE) return_matrix Logical, TRUE returns averaged data matrix instead NeuroVec (default FALSE)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/average_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average NeuroVec Data by Labels — average_labels","text":"NeuroVec object averaged data (one volume per unique label), matrix return_matrix=TRUE.         returned object attributes: condition_labelsThe unique labels order n_averagedNumber volumes averaged label normalizationThe normalization method used","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/average_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average NeuroVec Data by Labels — average_labels","text":"","code":"if (FALSE) { # \\dontrun{ # Basic averaging averaged <- average_labels(scandat, condition_labels, mask)  # With z-score normalization of each volume averaged_norm <- average_labels(scandat, condition_labels, mask,                                  normalize = \"z\", normalize_by = \"volume\")  # Scale to unit norm for RSA averaged_unit <- average_labels(scandat, condition_labels, mask,                                 normalize = \"unit\")                                  # Get just the data matrix data_mat <- average_labels(scandat, condition_labels, mask,                            return_matrix = TRUE) } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/balance_partitions.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Cross-Validation Partitions — balance_partitions","title":"Balance Cross-Validation Partitions — balance_partitions","text":"Modifies cross-validation partitioning scheme ensure target class equal number samples within training fold, optionally within test fold, using either sub-sampling oversampling.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/balance_partitions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Cross-Validation Partitions — balance_partitions","text":"","code":"balance_partitions(obj, design, ...)  # Default S3 method balance_partitions(obj, design, method = \"subsample\", ...)  # S3 method for class 'blocked_cross_validation' balance_partitions(obj, design, method = \"subsample\", ...)  # S3 method for class 'kfold_cross_validation' balance_partitions(obj, design, method = \"subsample\", ...)  # S3 method for class 'twofold_blocked_cross_validation' balance_partitions(obj, design, method = \"subsample\", ...)  # S3 method for class 'bootstrap_blocked_cross_validation' balance_partitions(obj, design, method = \"subsample\", ...)  # S3 method for class 'sequential_blocked_cross_validation' balance_partitions(obj, design, method = \"subsample\", ...)  # S3 method for class 'custom_cross_validation' balance_partitions(obj, design, method = \"subsample\", ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/balance_partitions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Cross-Validation Partitions — balance_partitions","text":"obj `cross_validation` object (e.g., `blocked_cross_validation`, `kfold_cross_validation`). design `mvpa_design` object containing target labels (`.sa.targets`) corresponding original dataset samples. ... Additional arguments passed internal balancing functions: balance_test_set Logical. `TRUE` (default), balance test     sets fold well using specified `method`. **Note:**     Oversampling test set generally recommended can     lead misleading performance estimates. warning issued     `balance_test_set=TRUE` `method=\"oversample\"`. seed optional integer seed random number generator     reproducible sampling. `NULL` (default), result varies. method Character string specifying balancing method: - `\"subsample\"` (default): -samples majority classes match   size smallest class (sampling without replacement). - `\"oversample\"`: -samples minority classes match size   largest class (sampling replacement).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/balance_partitions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Cross-Validation Partitions — balance_partitions","text":"`custom_cross_validation` object sample indices   `.train_indices` (optionally `.test_indices`) fold   resampled ensure balanced representation target classes.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/balance_partitions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Cross-Validation Partitions — balance_partitions","text":"**Sub-sampling (`method=\"subsample\"`)**: 1. Identifies target class minimum number samples    (`min_count`) within set (train test). 2. *every* target class within set, randomly selects exactly    `min_count` samples *without replacement*. 3. Discards samples majority classes. **Oversampling (`method=\"oversample\"`)**: 1. Identifies target class maximum number samples    (`max_count`) within set (train test). 2. *every* target class within set, randomly selects exactly    `max_count` samples *replacement*. 3. Duplicates samples minority classes. Balancing guarantees process, target class appears equally often within balanced training (optionally testing) set. useful preventing classifiers biased towards majority classes. output always `custom_cross_validation` object balancing process defines specific, explicit sets indices fold, may longer strictly adhere original blocking k-fold structure.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/balance_partitions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Cross-Validation Partitions — balance_partitions","text":"","code":"# Create an imbalanced dataset design (more class 'b') design_df <- data.frame(condition = factor(rep(c(\"a\", \"b\", \"b\"), 20)),                        block = rep(1:6, each = 10)) des <- mvpa_design(design_df, y_train = ~ condition, block_var = ~ block)  # Create standard blocked partitions (likely unbalanced) cval_unbalanced <- blocked_cross_validation(des$block_var) print(\"Unbalanced Counts (Example Fold 1 Train):\") #> [1] \"Unbalanced Counts (Example Fold 1 Train):\" print(table(des$y_train[unlist(crossval_samples(cval_unbalanced,           design_df, des$y_train)$train[[1]]$idx)])) #>  #>  a  b  #> 16 34   # Balance using sub-sampling (default) cval_sub <- balance_partitions(cval_unbalanced, des, seed = 1) print(cval_sub) #> $sample_set #> $sample_set[[1]] #> $sample_set[[1]]$train #>  [1] 11 12 13 14 16 17 19 22 23 24 25 27 28 30 31 32 34 37 39 40 41 43 46 47 49 #> [26] 50 52 55 56 58 59 60 #>  #> $sample_set[[1]]$test #> [1]  1  3  4  6  7  8  9 10 #>  #>  #> $sample_set[[2]] #> $sample_set[[2]]$train #>  [1]  1  2  4  6  7  9 10 21 22 23 25 27 28 29 31 32 34 36 37 38 39 40 43 44 45 #> [26] 46 48 49 50 52 53 55 56 58 #>  #> $sample_set[[2]]$test #> [1] 11 13 15 16 18 19 #>  #>  #> $sample_set[[3]] #> $sample_set[[3]]$train #>  [1]  1  2  3  4  7 10 11 12 13 15 16 17 18 19 31 33 34 35 37 39 40 42 43 46 49 #> [26] 50 51 52 53 55 57 58 59 60 #>  #> $sample_set[[3]]$test #> [1] 21 22 24 25 27 28 #>  #>  #> $sample_set[[4]] #> $sample_set[[4]]$train #>  [1]  1  2  3  4  6  7 10 11 13 16 18 19 22 23 24 25 28 29 30 41 43 45 46 47 48 #> [26] 49 50 51 52 55 58 59 #>  #> $sample_set[[4]]$test #> [1] 31 32 33 34 35 37 39 40 #>  #>  #> $sample_set[[5]] #> $sample_set[[5]]$train #>  [1]  1  2  3  4  5  7  8  9 10 13 14 16 18 19 21 22 23 24 25 26 28 30 31 34 37 #> [26] 40 51 52 53 54 55 57 58 59 #>  #> $sample_set[[5]]$test #> [1] 43 45 46 47 49 50 #>  #>  #> $sample_set[[6]] #> $sample_set[[6]]$train #>  [1]  1  3  4  6  7  8 10 11 12 13 14 15 16 19 21 22 25 26 28 30 31 32 34 37 39 #> [26] 40 41 42 43 44 45 46 48 49 #>  #> $sample_set[[6]]$test #> [1] 51 52 55 56 58 59 #>  #>  #>  #> $nfolds #> [1] 6 #>  #> attr(,\"class\") #> [1] \"custom_cross_validation\" \"cross_validation\"        #> [3] \"list\"                    print(\"Subsample Balanced Counts (Example Fold 1 Train):\") #> [1] \"Subsample Balanced Counts (Example Fold 1 Train):\" print(table(crossval_samples(cval_sub, design_df, des$y_train)$ytrain[[1]])) #>  #>  a  b  #> 16 16   # Balance using over-sampling cval_over <- balance_partitions(cval_unbalanced, des, method = \"oversample\", seed = 2) #> Warning: Oversampling the test set ('balance_test_set = TRUE', method = 'oversample') is generally not recommended and may lead to inflated performance metrics. print(cval_over) #> $sample_set #> $sample_set[[1]] #> $sample_set[[1]]$train #>  [1] 11 12 13 13 13 13 14 14 15 16 16 18 18 18 19 19 20 21 21 21 22 23 23 25 28 #> [26] 28 28 28 28 29 29 29 31 31 32 32 33 33 34 34 36 36 37 37 37 38 39 41 43 43 #> [51] 44 46 49 49 51 52 54 54 55 55 57 57 58 58 58 58 59 60 #>  #> $sample_set[[1]]$test #>  [1] 1 1 1 1 2 2 4 4 6 8 8 9 #>  #>  #> $sample_set[[2]] #> $sample_set[[2]]$train #>  [1]  1  1  1  3  4  5  6  7  7  7  8 10 22 22 22 22 23 23 23 25 25 28 28 29 29 #> [26] 30 32 32 34 34 34 35 36 36 37 38 38 38 40 40 40 41 41 42 43 43 44 45 46 47 #> [51] 49 49 49 50 51 52 52 54 54 55 56 56 56 58 59 60 #>  #> $sample_set[[2]]$test #>  [1] 11 13 14 16 16 16 18 18 18 19 19 19 20 20 #>  #>  #> $sample_set[[3]] #> $sample_set[[3]]$train #>  [1]  1  2  3  5  5  6  7  7  7  7  9 10 10 11 11 15 16 16 18 19 20 31 31 31 32 #> [26] 32 32 34 34 35 37 37 37 39 39 40 40 40 40 41 41 42 42 42 43 43 43 44 45 45 #> [51] 46 46 46 47 48 48 49 50 50 51 52 54 55 58 58 59 #>  #> $sample_set[[3]]$test #>  [1] 21 22 22 22 24 24 24 25 25 27 28 28 29 30 #>  #>  #> $sample_set[[4]] #> $sample_set[[4]]$train #>  [1]  1  3  6  7  7  7  9 10 10 12 13 13 13 14 14 14 14 16 17 17 18 19 19 21 21 #> [26] 23 24 25 25 25 25 27 27 27 28 28 28 42 42 43 43 43 45 45 45 45 46 46 46 46 #> [51] 46 48 48 49 50 52 52 53 53 53 54 55 55 55 57 57 58 59 #>  #> $sample_set[[4]]$test #>  [1] 31 32 33 33 34 35 37 37 37 38 39 40 #>  #>  #> $sample_set[[5]] #> $sample_set[[5]]$train #>  [1]  1  1  1  1  1  3  4  4  4  7  8  9  9 10 11 12 12 12 13 13 13 15 17 20 20 #> [26] 21 21 21 22 22 22 22 23 23 23 24 24 25 25 31 31 31 31 32 32 32 33 33 34 34 #> [51] 35 37 37 37 38 38 39 39 40 40 51 52 52 57 58 59 #>  #> $sample_set[[5]]$test #>  [1] 41 41 43 45 46 46 46 46 47 48 49 49 50 50 #>  #>  #> $sample_set[[6]] #> $sample_set[[6]]$train #>  [1]  1  3  5  7  8  8  9 11 11 13 13 13 14 14 15 15 16 16 16 17 18 18 19 20 21 #> [26] 21 22 24 25 25 25 26 26 27 28 28 28 28 30 30 31 31 32 33 34 34 34 39 39 40 #> [51] 40 41 42 42 43 43 44 46 46 47 48 49 49 49 49 49 #>  #> $sample_set[[6]]$test #>  [1] 52 52 53 54 54 54 55 55 57 57 58 58 58 59 #>  #>  #>  #> $nfolds #> [1] 6 #>  #> attr(,\"class\") #> [1] \"custom_cross_validation\" \"cross_validation\"        #> [3] \"list\"                    print(\"Oversample Balanced Counts (Example Fold 1 Train):\") #> [1] \"Oversample Balanced Counts (Example Fold 1 Train):\" print(table(crossval_samples(cval_over, design_df, des$y_train)$ytrain[[1]])) #>  #>  a  b  #> 34 34"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/binary_classification_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Classification results for binary outcome — binary_classification_result","title":"Classification results for binary outcome — binary_classification_result","text":"Constructs binary classification result object based observed predicted values, well optional parameters.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/binary_classification_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classification results for binary outcome — binary_classification_result","text":"","code":"binary_classification_result(   observed,   predicted,   probs,   testind = NULL,   test_design = NULL,   predictor = NULL )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/binary_classification_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classification results for binary outcome — binary_classification_result","text":"observed vector observed true values. predicted vector predicted values. probs matrix predicted probabilities, one column per level. testind row indices test observations (optional). test_design optional design test data. predictor optional predictor object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/binary_classification_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classification results for binary outcome — binary_classification_result","text":"binary classification result object, class attribute set \"binary_classification_result\".","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/category_rdm.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Hypothesis RDM from Category Structure — category_rdm","title":"Create Hypothesis RDM from Category Structure — category_rdm","text":"Creates RDM based category membership, items category high similarity items different categories low similarity.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/category_rdm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Hypothesis RDM from Category Structure — category_rdm","text":"","code":"category_rdm(   categories,   within_category_sim = 0.8,   between_category_sim = 0.2,   as_dist = TRUE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/category_rdm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Hypothesis RDM from Category Structure — category_rdm","text":"categories named vector factor names/levels labels values category assignments within_category_sim Similarity value items within category (default: 0.8) between_category_sim Similarity value items different categories (default: 0.2) as_dist Logical; TRUE return dist object, otherwise return matrix (default: TRUE)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/category_rdm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Hypothesis RDM from Category Structure — category_rdm","text":"dist object matrix representing category-based RDM","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/category_rdm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Hypothesis RDM from Category Structure — category_rdm","text":"","code":"# Create category structure categories <- c(cat = \"animal\", dog = \"animal\", bird = \"animal\",                car = \"vehicle\", plane = \"vehicle\", boat = \"vehicle\")  # Create category-based RDM rdm <- category_rdm(categories)  # Custom similarity values rdm <- category_rdm(categories,                     within_category_sim = 0.9,                    between_category_sim = 0.1)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/classification_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a classification_result instance — classification_result","title":"Create a classification_result instance — classification_result","text":"Constructs classification result object based observed predicted values, well optional parameters.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/classification_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a classification_result instance — classification_result","text":"","code":"classification_result(   observed,   predicted,   probs,   testind = NULL,   test_design = NULL,   predictor = NULL )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/classification_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a classification_result instance — classification_result","text":"observed vector observed true values. predicted vector predicted values. probs matrix predicted probabilities, one column per level. testind row indices test observations (optional). test_design optional design test data. predictor optional predictor object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/classification_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a classification_result instance — classification_result","text":"classification result object, can one : regression_result,   binary_classification_result, multiway_classification_result.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/classification_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a classification_result instance — classification_result","text":"","code":"# A vector of observed values yobs <- factor(rep(letters[1:4], 5))  # Predicted probabilities probs <- data.frame(a = runif(1:20), b = runif(1:20), c = runif(1:20), d = runif(1:20)) probs <- sweep(probs, 1, rowSums(probs), \"/\")  # Get the max probability per row and use this to determine the predicted class maxcol <- max.col(probs) predicted <- levels(yobs)[maxcol]  # Construct a classification result cres <- classification_result(yobs, predicted, probs)  # Compute default performance measures (Accuracy, AUC) performance(cres) #>    Accuracy         AUC  #>  0.25000000 -0.08666667"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/coalesce_join2.html","id":null,"dir":"Reference","previous_headings":"","what":"Coalesce Join Two Data Frames — coalesce_join2","title":"Coalesce Join Two Data Frames — coalesce_join2","text":"function performs specified type join two data frames coalesces joined columns based common column names.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/coalesce_join2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coalesce Join Two Data Frames — coalesce_join2","text":"","code":"coalesce_join2(   x,   y,   by = NULL,   suffix = c(\".x\", \".y\"),   join = dplyr::full_join,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/coalesce_join2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coalesce Join Two Data Frames — coalesce_join2","text":"x data frame joined. y second data frame joined. character vector variables join . NULL (default), function use common column names 'x' 'y'. suffix character vector length 2, specifying suffixes used making unique common column names 'x' 'y'. default c(\".x\", \".y\"). join join function used joining data frames. default dplyr::full_join. ... Additional arguments passed join function.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/coalesce_join2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coalesce Join Two Data Frames — coalesce_join2","text":"data frame resulting specified join operation coalesced columns.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_randomized.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine Custom Randomized Searchlight Results — combine_custom_randomized","title":"Combine Custom Randomized Searchlight Results — combine_custom_randomized","text":"Internal function combine results randomized custom searchlight run. Averages results metric across overlapping spheres.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_randomized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine Custom Randomized Searchlight Results — combine_custom_randomized","text":"","code":"combine_custom_randomized(dataset, iteration_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_randomized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine Custom Randomized Searchlight Results — combine_custom_randomized","text":"dataset original mvpa_dataset object. iteration_results raw tibble output ** iterations `mvpa_iterate`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_randomized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine Custom Randomized Searchlight Results — combine_custom_randomized","text":"`searchlight_result` object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine Custom Standard Searchlight Results — combine_custom_standard","title":"Combine Custom Standard Searchlight Results — combine_custom_standard","text":"Internal function combine results standard custom searchlight run. Creates `searchlight_result` object NeuroVol/NeuroSurface metric.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine Custom Standard Searchlight Results — combine_custom_standard","text":"","code":"combine_custom_standard(dataset, iteration_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_standard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine Custom Standard Searchlight Results — combine_custom_standard","text":"dataset original mvpa_dataset object. iteration_results raw tibble output `mvpa_iterate`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_custom_standard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine Custom Standard Searchlight Results — combine_custom_standard","text":"`searchlight_result` object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_msreve_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine MS-ReVE (Contrast RSA) Searchlight Results — combine_msreve_standard","title":"Combine MS-ReVE (Contrast RSA) Searchlight Results — combine_msreve_standard","text":"function gathers Q-dimensional performance vectors successful searchlight center combines Q separate output maps.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_msreve_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine MS-ReVE (Contrast RSA) Searchlight Results — combine_msreve_standard","text":"","code":"combine_msreve_standard(model_spec, good_results, bad_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_msreve_standard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine MS-ReVE (Contrast RSA) Searchlight Results — combine_msreve_standard","text":"model_spec contrast_rsa_model specification. good_results tibble containing successful results train_model.contrast_rsa_model. row corresponds searchlight center. Expected columns include id (center voxel global index) performance (named numeric vector length Q). bad_results tibble containing information failed searchlights (error reporting).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_msreve_standard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine MS-ReVE (Contrast RSA) Searchlight Results — combine_msreve_standard","text":"searchlight_result object containing: results named list SparseNeuroVec NeuroSurfaceVector objects,     one contrast (Q maps total). ... standard searchlight metadata.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_prediction_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine prediction tables — combine_prediction_tables","title":"Combine prediction tables — combine_prediction_tables","text":"Combines multiple prediction tables (e.g., different models regions) single table. Supports weighted combination collapsing regions.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_prediction_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine prediction tables — combine_prediction_tables","text":"","code":"combine_prediction_tables(   predtabs,   wts = rep(1, length(predtabs)),   collapse_regions = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_prediction_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine prediction tables — combine_prediction_tables","text":"predtabs list prediction tables (data frames) combined. wts vector weights, length predtabs. Default equal weights. collapse_regions logical value; TRUE, regions collapsed final prediction table.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_prediction_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine prediction tables — combine_prediction_tables","text":"combined prediction table (data frame).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_prediction_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine prediction tables — combine_prediction_tables","text":"","code":"# Create example prediction tables observed = factor(sample(letters[1:2], 10, replace = TRUE)) predtab1 <- data.frame(.rownum = 1:10,                        roinum = rep(1, 10),                        observed = observed,                        prob_A = runif(10),                        prob_B = runif(10)) predtab2 <- data.frame(.rownum = 1:10,                        roinum = rep(2, 10),                        observed = observed,                        prob_A = runif(10),                        prob_B = runif(10))  # Combine the tables combined_table <- combine_prediction_tables(list(predtab1, predtab2))"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_randomized.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine randomized classifier results — combine_randomized","title":"Combine randomized classifier results — combine_randomized","text":"function combines randomized classifier results good results data frame normalizes performance matrix number instances voxel index.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_randomized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine randomized classifier results — combine_randomized","text":"","code":"combine_randomized(model_spec, good_results, bad_results = NULL)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_randomized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine randomized classifier results — combine_randomized","text":"model_spec list containing model specification. good_results data frame containing successful classifier results. bad_results data frame containing unsuccessful classifier results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_randomized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine randomized classifier results — combine_randomized","text":"list containing combined normalized performance matrix along information dataset.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_rsa_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine RSA standard classifier results — combine_rsa_standard","title":"Combine RSA standard classifier results — combine_rsa_standard","text":"function combines RSA standard classifier results good results data frame binding performance rows together.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_rsa_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine RSA standard classifier results — combine_rsa_standard","text":"","code":"combine_rsa_standard(model_spec, good_results, bad_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_rsa_standard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine RSA standard classifier results — combine_rsa_standard","text":"model_spec list containing model specification. good_results data frame containing successful classifier results. bad_results data frame containing unsuccessful classifier results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_rsa_standard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine RSA standard classifier results — combine_rsa_standard","text":"list containing combined performance matrix along information dataset.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine standard classifier results — combine_standard","title":"Combine standard classifier results — combine_standard","text":"function combines standard classifier results good results data frame binding performance rows together optionally computes observed probabilities.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine standard classifier results — combine_standard","text":"","code":"combine_standard(model_spec, good_results, bad_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_standard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine standard classifier results — combine_standard","text":"model_spec list containing model specification good_results data frame containing successful classifier results bad_results data frame containing unsuccessful classifier results","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_standard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine standard classifier results — combine_standard","text":"list containing combined performance matrix information","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_vector_rsa_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine Vector RSA standard classifier results — combine_vector_rsa_standard","title":"Combine Vector RSA standard classifier results — combine_vector_rsa_standard","text":"function combines Vector RSA standard classifier results good results data frame binding performance rows together.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_vector_rsa_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine Vector RSA standard classifier results — combine_vector_rsa_standard","text":"","code":"combine_vector_rsa_standard(model_spec, good_results, bad_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_vector_rsa_standard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine Vector RSA standard classifier results — combine_vector_rsa_standard","text":"model_spec list containing model specification. good_results data frame containing successful classifier results. bad_results data frame containing unsuccessful classifier results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/combine_vector_rsa_standard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine Vector RSA standard classifier results — combine_vector_rsa_standard","text":"list containing combined performance matrix along information dataset.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_crossvalidated_means_sl.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Cross-Validated Condition Means within a Searchlight — compute_crossvalidated_means_sl","title":"Compute Cross-Validated Condition Means within a Searchlight — compute_crossvalidated_means_sl","text":"helper function calculates mean activation pattern condition using data cross-validation folds.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_crossvalidated_means_sl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Cross-Validated Condition Means within a Searchlight — compute_crossvalidated_means_sl","text":"","code":"compute_crossvalidated_means_sl(   sl_data,   mvpa_design,   cv_spec,   estimation_method = \"average\",   whitening_matrix_W = NULL,   return_folds = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_crossvalidated_means_sl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Cross-Validated Condition Means within a Searchlight — compute_crossvalidated_means_sl","text":"sl_data numeric matrix (samples x voxels/vertices) containing data current searchlight. mvpa_design mvpa_design object associated dataset, containing condition labels block information. cv_spec object describing cross-validation scheme, typically created functions like \\link{blocked_cross_validation}, \\link{twofold_blocked_cross_validation}, \\link{kfold_cross_validation}, etc. (inheriting cross_validation). object determines training/test folds defined. estimation_method Character string specifying method estimate means. Currently supported: \"average\" (simple mean training samples per condition). \"average\": Simple mean training samples per condition. \"L2_norm\": Identical \"average\" condition pattern (row) finally scaled unit L2 norm. Useful need equalise overall pattern energy across conditions RSA. \"crossnobis\": Applies pre-computed whitening matrix (see `whitening_matrix_W`) average pattern condition within cross-validation training fold, averaging whitened patterns across folds. aims produce noise-normalized condition representations. Default \"average\". whitening_matrix_W Optional V x V numeric matrix, V number voxels/features `sl_data`. matrix whitening transformation (e.g., Σ_noise^(-1/2)) derived GLM residuals. Required used `estimation_method = \"crossnobis\"`. return_folds Logical, TRUE, function returns list containing overall mean estimate (`mean_estimate`) array per-fold estimates (`fold_estimates`). FALSE (default), overall mean estimate returned.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_crossvalidated_means_sl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Cross-Validated Condition Means within a Searchlight — compute_crossvalidated_means_sl","text":"`return_folds = FALSE` (default): numeric matrix (K x V_sl) K number   conditions V_sl number voxels/vertices searchlight. row   represents cross-validated mean pattern condition k.   `return_folds = TRUE`: list two elements: `mean_estimate` K x V_sl matrix described . `fold_estimates` K x V_sl x M array, M number folds,       containing mean estimate condition fold.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_performance-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Performance for an Object — compute_performance","title":"Compute Performance for an Object — compute_performance","text":"Delegates calculation performance metrics appropriate method.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_performance-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Performance for an Object — compute_performance","text":"","code":"compute_performance(obj, result)  # S3 method for class 'mvpa_model' compute_performance(obj, result)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_performance-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Performance for an Object — compute_performance","text":"obj Model specification object capable computing performance. result classification/regression result evaluate.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_performance-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Performance for an Object — compute_performance","text":"Named numeric vector performance metrics.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/compute_performance-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Performance for an Object — compute_performance","text":"","code":"cres <- binary_classification_result(   observed  = factor(c(\"a\", \"b\")),   predicted = factor(c(\"a\", \"b\")),   probs     = matrix(c(0.8, 0.2, 0.3, 0.7), ncol = 2,                      dimnames = list(NULL, c(\"a\", \"b\"))) ) dummy <- list(performance = performance) class(dummy) <- \"mvpa_model\" compute_performance(dummy, cres) #> Error in UseMethod(\"compute_performance\"): no applicable method for 'compute_performance' applied to an object of class \"mvpa_model\""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrast_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor for contrast_rsa_model — contrast_rsa_model","title":"Constructor for contrast_rsa_model — contrast_rsa_model","text":"Creates contrast_rsa_model specification object, encapsulates necessary parameters design information Multi-Dimensional Signed Representational Voxel Encoding (MS-ReVE) style analysis.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrast_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for contrast_rsa_model — contrast_rsa_model","text":"","code":"contrast_rsa_model(   dataset,   design,   estimation_method = \"average\",   regression_type = \"lm\",   output_metric = c(\"beta_delta\"),   check_collinearity = FALSE,   normalize_delta = FALSE,   allow_nonorth_composite = FALSE,   calc_reliability = FALSE,   whitening_matrix_W = NULL,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrast_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for contrast_rsa_model — contrast_rsa_model","text":"dataset object class mvpa_dataset, containing neuroimaging data associated metadata. design object class msreve_design, containing underlying mvpa_design contrast matrix. Created \\link{msreve_design}. estimation_method Character string specifying method estimate cross-validated condition means (Û) distances. Supported: \"average\": Simple mean training samples per condition (Û). \"L2_norm\": Like \"average\", Û rows L2-normalized. \"crossnobis\": Computes unbiased squared Euclidean distances directly using Crossnobis method. Results distance vector RSA, Û matrix \\(G_empirical\\) construction way. U_hat \\(\\Delta\\) calculation still computed using \"average\" method internally selected. Requires `return_folds=TRUE` `compute_crossvalidated_means_sl`. Passed compute_crossvalidated_means_sl (\"average\", \"L2_norm\", get per-fold means \"crossnobis\"). regression_type Character string specifying method RSA regression (regressing empirical RDM/Second Moment Matrix onto contrast RDMs). Options align rsa_model: \"pearson\", \"spearman\", \"lm\", \"rfit\". Additional options ridge regression: \"ridge_hkb\" (Hoerl-Kennard-Baldwin lambda). Default \"lm\". output_metric Character vector specifying one output metrics compute. Multiple metrics can requested simultaneously returned named list. Duplicates removed preserving order first occurrence. Supported options: \"beta_delta\": product RSA regression coefficient (beta_q)         voxel's projection onto contrast (delta_q,v).         primary signed contribution metric. \"beta_only\": RSA regression coefficient (beta_q). \"delta_only\": voxel's projection onto contrast (delta_q,v). \"recon_score\": Voxel-specific RDM reconstruction score (r_v), correlating RDM implied voxel's loadings empirical RDM. \"beta_delta_norm\": Similar `beta_delta`, uses L2-normalized voxel contribution vector (delta_q,v). Requires `normalize_delta=TRUE` meaningful. \"beta_delta_reliable\": Reliability-weighted contributions, \\(\\rho_{q,v} \\beta_q \\Delta_{q,v}\\), \\(\\rho_{q,v}\\) reflects fold-wise stability. \"composite\": Sum beta-weighted, L2-normalized voxel contributions (Σ_q β_q ~Δ_q,v). Represents net projection onto positive diagonal contrast space. Interpretation requires caution contrasts orthonormal. Default c(\"beta_delta\"). check_collinearity Logical, whether check collinearity among contrast RDMs using regression_type = \"lm\". Default FALSE. normalize_delta Logical. TRUE, voxel contribution vector (delta_q,v) normalized unit L2 norm potentially multiplied beta_q \"beta_delta\" output metric. Default FALSE. allow_nonorth_composite Logical. FALSE (default) composite metric return NA contrast matrix orthonormal, avoid mis-interpretation. TRUE, composite score returned regardless, warning still emitted. calc_reliability Logical. TRUE, voxel-wise contribution reliability (ρ values) estimated across cross-validation folds training can incorporated output metrics. Default FALSE. whitening_matrix_W Optional V x V numeric matrix (voxels x voxels). Required `estimation_method = \"crossnobis\"` Mahalanobis (rather Euclidean) distances desired. matrix (e.g., \\(\\Sigma_{noise}^{-1/2}\\)) passed `compute_crossvalidated_means_sl` whiten per-fold estimates distance calculation. Default `NULL` (Euclidean distances Crossnobis). ... Additional arguments passed create_model_spec.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrast_rsa_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for contrast_rsa_model — contrast_rsa_model","text":"object class contrast_rsa_model, mvpa_model_spec,   model_spec, list.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrast_rsa_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Constructor for contrast_rsa_model — contrast_rsa_model","text":"model designed MS-ReVE style analyses goal understand different predefined contrasts contribute representational structure observed neural data, particularly fine-grained (e.g., voxel) level. involves: 1. Estimating cross-validated condition mean patterns (Û) distances (Crossnobis). 2. Constructing empirical second-moment matrix (Ĝ) Û using Crossnobis distances directly. 3. Creating theoretical second-moment matrices (RDMs) contrast vector. 4. Regressing vectorized empirical RDM/distances onto vectorized contrast RDMs get β coefficients. 5. Projecting voxel patterns (Û) onto contrast space get Δ (delta) values. 6. Combining β Δ form final output metric (e.g., beta_delta). **Cross-Validation Compatibility:** `estimation_method` relies `compute_crossvalidated_means_sl` , turn, requires cross-validation specification (`cv_spec` derived `mvpa_design$crossval`) provide deterministic, partition-based set training indices fold. Therefore, cross-validation schemes like `bootstrap_blocked_cross_validation` (use resampling replacement training folds) **suitable** use model, align assumptions `compute_crossvalidated_means_sl`. Schemes like `blocked_cross_validation`, `kfold_cross_validation`, `custom_cross_validation` (define clear partitions) appropriate. `twofold_blocked_cross_validation` `sequential_blocked_cross_validation`, compatibility also depends whether `train_indices` methods can deterministically define training sets fold iterated `compute_crossvalidated_means_sl`.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrast_rsa_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor for contrast_rsa_model — contrast_rsa_model","text":"","code":"# --- Minimal Setup --- # 1. Create dummy data and an mvpa_dataset    # Dummy data: 16 samples, 10 voxels, 4 conditions, 2 runs   set.seed(123)   n_samples <- 16   n_voxels <- 10   n_conditions <- 4 # condA, condB, condC, condD   n_runs <- 2    dummy_sl_data <- matrix(rnorm(n_samples * n_voxels), n_samples, n_voxels)   colnames(dummy_sl_data) <- paste0(\"V\", 1:n_voxels)    dummy_mask <- neuroim2::NeuroVol(array(1, c(2,2,2)), neuroim2::NeuroSpace(c(2,2,2)))    condition_labels <- factor(rep(paste0(\"cond\", LETTERS[1:n_conditions]), each = n_samples / n_conditions))   run_labels <- factor(rep(1:n_runs, each = n_samples / n_runs))    # Create mvpa_dataset (without Y and block_var)   mvpa_dat <- rMVPA::mvpa_dataset(     train_data = dummy_sl_data,     mask = dummy_mask   ) #> Error: train_data does not inherit from class NeuroVec    # Create mvpa_design   mvpa_des <- rMVPA::mvpa_design(     train_design = data.frame(condition = condition_labels, run = run_labels),     y_train = ~condition,     block_var = ~run   )    K <- mvpa_des$ncond # Use mvpa_des here    C_mat <- matrix(0, nrow = K, ncol = 2) #> Error in matrix(0, nrow = K, ncol = 2): non-numeric matrix extent   rownames(C_mat) <- levels(mvpa_des$Y) # Use mvpa_des here #> Error: object 'C_mat' not found   C_mat[\"condA\", 1] <- 1; C_mat[\"condB\", 1] <- 1 #> Error: object 'C_mat' not found   C_mat[\"condC\", 1] <- -1; C_mat[\"condD\", 1] <- -1 #> Error: object 'C_mat' not found   C_mat[\"condA\", 2] <- 1; C_mat[\"condB\", 2] <- -1 #> Error: object 'C_mat' not found   C_mat <- scale(C_mat, center = TRUE, scale = FALSE) #> Error: object 'C_mat' not found   colnames(C_mat) <- c(\"AB_vs_CD\", \"A_vs_B\") #> Error: object 'C_mat' not found    msreve_des <- rMVPA::msreve_design(     mvpa_design = mvpa_des, # Use mvpa_des here     contrast_matrix = C_mat   ) #> Error: object 'C_mat' not found    # --- Example 1: Basic contrast_rsa_model ---   model_basic <- contrast_rsa_model(     dataset = mvpa_dat,     design = msreve_des   ) #> Error: object 'mvpa_dat' not found   print(model_basic) #> Error: object 'model_basic' not found    # --- Example 1b: Requesting multiple metrics ---   model_multi_metric <- contrast_rsa_model(     dataset = mvpa_dat,     design = msreve_des,     output_metric = c(\"beta_delta\", \"recon_score\", \"beta_only\")   ) #> Error: object 'mvpa_dat' not found   print(model_multi_metric) #> Error: object 'model_multi_metric' not found    # --- Example 2: Using L2_norm for U_hat and normalize_delta ---   model_l2_norm_delta <- contrast_rsa_model(     dataset = mvpa_dat,     design = msreve_des,     estimation_method = \"L2_norm\",     normalize_delta = TRUE,     output_metric = \"beta_delta_norm\"   ) #> Error: object 'mvpa_dat' not found   print(model_l2_norm_delta) #> Error: object 'model_l2_norm_delta' not found    # --- Example 3: Ridge Regression (HKB) ---   model_ridge <- contrast_rsa_model(     dataset = mvpa_dat,     design = msreve_des,     regression_type = \"ridge_hkb\"   ) #> Error: object 'mvpa_dat' not found   print(model_ridge) #> Error: object 'model_ridge' not found    # --- Example 4: Reconstruction Score Output ---   model_recon <- contrast_rsa_model(     dataset = mvpa_dat,     design = msreve_des,     output_metric = \"recon_score\"   ) #> Error: object 'mvpa_dat' not found   print(model_recon) #> Error: object 'model_recon' not found    # --- Example 5: Composite Score Output ---   C_mat_ortho <- rMVPA::orthogonalize_contrasts(C_mat) #> Error: object 'C_mat' not found   msreve_des_ortho <- rMVPA::msreve_design(       mvpa_design = mvpa_des, # Use mvpa_des here       contrast_matrix = C_mat_ortho   ) #> Error: object 'C_mat_ortho' not found   print(paste(\"Is contrast matrix orthonormal:\", attr(msreve_des_ortho, \"is_orthonormal\"))) #> Error: object 'msreve_des_ortho' not found    model_composite <- contrast_rsa_model(     dataset = mvpa_dat,     design = msreve_des_ortho,     output_metric = \"composite\",     normalize_delta = TRUE    ) #> Error: object 'mvpa_dat' not found   print(model_composite) #> Error: object 'model_composite' not found    # --- Example 6: Crossnobis estimation_method ---   # This only shows setting the method. Actual training would require passing   # a pre-computed whitening_matrix_W to compute_crossvalidated_means_sl,   # which is called by train_model.contrast_rsa_model.   model_crossnobis <- contrast_rsa_model(       dataset = mvpa_dat,       design = msreve_des,       estimation_method = \"crossnobis\"   ) #> Error: object 'mvpa_dat' not found   print(model_crossnobis) #> Error: object 'model_crossnobis' not found"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Contrast Matrices — contrasts","title":"Generate Contrast Matrices — contrasts","text":"Creates numeric contrast matrix use RSA encoding models, based condition labels specification.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Contrast Matrices — contrasts","text":"","code":"contrasts(   labels = NULL,   spec,   metadata = NULL,   data = NULL,   centre = TRUE,   scale = c(\"none\", \"sd\", \"l2\"),   orth = FALSE,   keep_attr = TRUE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Contrast Matrices — contrasts","text":"labels Character vector. Required `metadata` NULL. Specifies unique condition labels desired order rows contrast matrix. spec Formula. Defines contrasts. `metadata` NULL, uses mini-DSL (see Details). `metadata` provided, uses standard R formula syntax referencing columns `metadata` (excluding `label` column). metadata Optional tibble/data.frame. provided, must contain `label` column matching conditions, columns representing features factors used `spec` formula. `labels` argument ignored `metadata` provided. data Ignored version. Reserved future extensions allowing direct input feature matrices RDMs PCA/MDS contrasts. centre Logical. TRUE (default), columns resulting matrix mean-centered. scale Character string specifying scaling method centering (`orth=FALSE`). Options: `\"none\"` (default), `\"sd\"` (divide sample standard deviation), `\"l2\"` (divide L2 norm / vector length get unit vectors). argument *ignored* `orth = TRUE`. orth Logical. FALSE (default), matrix columns represent specified contrasts directly (centering/scaling). TRUE, orthonormal basis column space computed via QR decomposition. Resulting columns orthogonal unit length (L2 norm = 1). keep_attr Logical. TRUE (default) `orth = TRUE`, original column names (orthogonalization) stored `attr(C, \"source\")`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Contrast Matrices — contrasts","text":"numeric matrix (K x Q), K number labels Q   number contrasts/orthogonal components.   `orth = TRUE` `keep_attr = TRUE`, includes attributes detailing   source (`\"source\"`) dropped (`\"dropped\"`) columns due rank deficiency.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Contrast Matrices — contrasts","text":"function provides two main ways define contrasts: Via `labels` vector `spec` formula using mini-DSL like         `~ factor1(levelA + levelB ~ levelC + .) + factor2(...)`. Via `metadata` tibble (containing condition labels predictor columns)         standard R formula `spec` (e.g., `~ pred1 + pred2 + pred1:pred2`). function automatically handles centering, scaling, optional orthogonalization. **Mini-DSL `spec` (`metadata` NULL):** formula form `~ name1(levelsA ~ levelsB) + name2(...)`. `name1`, `name2`, etc., become factor/contrast names. used         generate initial binary (+1/-1/0) columns. `levelsA` condition labels (`labels` argument) separated `+`.         get coded +1 named factor. `levelsB` condition labels separated `+`, `.` (period).         get coded -1 named factor. `.` means \"labels listed `levelsA`\". Labels mentioned factor definition get coded 0 factor. Interaction terms (e.g., `factorName1:factorName2`) can included `spec`.         passed `model.matrix` computes based         previously generated factor columns. `centre = TRUE` (default), resulting columns `model.matrix` mean-centered. binary factors created DSL (e.g. +1/-1/0 coding), groups balanced, might already near zero-mean. explicit centering step ensures property regardless input balance.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"orthogonalization","dir":"Reference","previous_headings":"","what":"Orthogonalization","title":"Generate Contrast Matrices — contrasts","text":"`orth = TRUE`, uses `qr.Q(qr(C))` find orthonormal basis. number columns output rank input matrix. Columns renamed `Orth1`, `Orth2`, etc. Scaling ignored columns already unit L2 norm. `keep_attr = TRUE`:   `attr(C_orth, \"source\")` stores names original columns   formed basis orthogonalized matrix.   `attr(C_orth, \"dropped\")` stores names original columns   linearly dependent thus part basis, .","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"scaling","dir":"Reference","previous_headings":"","what":"Scaling","title":"Generate Contrast Matrices — contrasts","text":"Applied ** centering `orth=FALSE`. `\"none\"`: scaling. `\"sd\"`: `scale(..., center=FALSE, scale=TRUE)`. Uses sample standard deviation (N-1 denominator).         Note columns unique values (e.g., centered +/-1 contrast), SD         can slightly different depending whether number items even odd,         due N-1 denominator. might lead minor differences scaled norms. `\"l2\"`: Divides column L2 norm (`sqrt(sum(x^2))`).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"specific-behaviors","dir":"Reference","previous_headings":"","what":"Specific Behaviors","title":"Generate Contrast Matrices — contrasts","text":"`orth = TRUE` input matrix one column potential centering,         column scaled unit L2 norm. Centering still depends `centre` argument. `centre = FALSE` `orth = TRUE`, QR decomposition performed         *uncentered* columns. mini-DSL `. ` notation used `levelsB` `levelsA` already contains         `labels`, `levelsB` becomes empty, potentially resulting constant (zero)         column centering. warning issued case.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"masking","dir":"Reference","previous_headings":"","what":"Masking","title":"Generate Contrast Matrices — contrasts","text":"function masks `stats::contrasts` function. use base R function, explicitly call `stats::contrasts()`.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Contrast Matrices — contrasts","text":"","code":"labs <- c(\"faces\",\"animals\",\"plants\",\"tools\",           \"vehicles\",\"furniture\",\"buildings\",\"food\")  # 1) Mini-DSL: 2x2 Factorial (Animacy x Size) + Interaction, Orthonormal C1 <- contrasts(         labels = labs,         spec   = ~ anim( faces + animals + plants + food ~ . )                  + size( faces + animals + tools + furniture ~ . )                  + anim:size,         orth   = TRUE) print(colnames(C1)) #> [1] \"Orth1\" \"Orth2\" \"Orth3\" print(attr(C1, \"source\")) #> [1] \"anim\"      \"size\"      \"anim:size\" print(round(crossprod(C1), 5)) #>       Orth1 Orth2 Orth3 #> Orth1     1     0     0 #> Orth2     0     1     0 #> Orth3     0     0     1  # 2) Mini-DSL: One-vs-rest, Centered, Unit Length (L2) C2 <- contrasts(labels = labs,                 spec   = ~ faces( faces ~ . ) + tools( tools ~ . ),                 scale = \"l2\") print(round(colSums(C2^2), 5)) # Should be 1 #> faces tools  #>     1     1   # 3) Metadata + Formula: Centered, Scaled (SD) meta <- tibble::tribble(   ~label,      ~anim, ~size,   \"faces\",        1,    0,   \"animals\",      1,    0,   \"plants\",       1,    1,   \"tools\",        0,    0,   \"vehicles\",     0,    1,   \"furniture\",    0,    0,   \"buildings\",    0,    1,   \"food\",         1,    1) # Note: labels argument is ignored here, order comes from meta$label # Also note: This function masks stats::contrasts C3 <- contrasts(metadata = meta,                 spec     = ~ anim + size + anim:size,                 scale    = \"sd\") print(round(colMeans(C3), 5)) # Should be 0 #>      anim      size anim:size  #>         0         0         0  print(round(apply(C3, 2, sd), 5)) # Should be 1 #>      anim      size anim:size  #>         1         1         1"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Distance Function Object — create_dist","title":"Create a Distance Function Object — create_dist","text":"Constructs generic distance function object, storing: name: name (method) distance (e.g., \"euclidean\", \"cordist\", \"mahalanobis\"). labels: (Optional) vector labels associated data rows. ...: Additional parameters relevant specific distance method         (e.g., correlation method cordist, number components pcadist, etc.).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Distance Function Object — create_dist","text":"","code":"create_dist(name, labels = NULL, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Distance Function Object — create_dist","text":"name character string specifying distance method (e.g., \"euclidean\", \"cordist\"). labels vector row labels (optional), primarily informational/reference purposes. ... Additional parameters distance method (e.g. `method=\"pearson\"` correlation, whiten=TRUE PCA-based distances).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Distance Function Object — create_dist","text":"S3 object class c(name, \"distfun\") can passed pairwise_dist().","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_dist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Distance Function Object — create_dist","text":"object used pairwise_dist() compute N x N matrix pairwise distances rows data matrix. distance function object exclude -block comparisons reorder rows label. tasks (needed) handled downstream (example, second_order_similarity).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Distance Function Object — create_dist","text":"","code":"# Create a Euclidean distance function object dist_obj_euc <- create_dist(\"euclidean\")  # Create a correlation distance function object with a specified correlation method dist_obj_cor <- create_dist(\"cordist\", method=\"spearman\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_mvpa_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Cross-Validation Folds — create_mvpa_folds","title":"Create Cross-Validation Folds — create_mvpa_folds","text":"Generates list row indices k-fold cross-validation. Can perform stratified sampling y factor.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_mvpa_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Cross-Validation Folds — create_mvpa_folds","text":"","code":"create_mvpa_folds(y, k = 5, list = TRUE, seed = NULL)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_mvpa_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Cross-Validation Folds — create_mvpa_folds","text":"y vector, typically response variable. k Integer, number folds. list Logical, TRUE, return list indices fold. FALSE, return vector fold assignments observation. seed Optional integer reproducible fold creation.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_mvpa_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Cross-Validation Folds — create_mvpa_folds","text":"`list=TRUE`, list k integer vectors. `list=FALSE`, integer         vector fold assignments.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_searchlight_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Searchlight Performance Object — create_searchlight_performance","title":"Create Searchlight Performance Object — create_searchlight_performance","text":"Creates searchlight_performance object expected structure tests","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_searchlight_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Searchlight Performance Object — create_searchlight_performance","text":"","code":"create_searchlight_performance(data, metric_name, indices = NULL)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_searchlight_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Searchlight Performance Object — create_searchlight_performance","text":"data NeuroVol NeuroSurface object metric_name Character string naming metric indices Numeric vector center indices (optional)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/create_searchlight_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Searchlight Performance Object — create_searchlight_performance","text":"searchlight_performance object","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/cross_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"bootstrap_blocked_cross_validation — bootstrap_blocked_cross_validation","title":"bootstrap_blocked_cross_validation — bootstrap_blocked_cross_validation","text":"Bootstrap Blocked Cross-Validation Specification function constructs cross-validation specification using predefined blocking variable. function constructs cross-validation specification using predefined blocking variable, dividing block specified number folds. function constructs cross-validation specification uses user-supplied set training test indices.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/cross_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bootstrap_blocked_cross_validation — bootstrap_blocked_cross_validation","text":"","code":"bootstrap_blocked_cross_validation(block_var, nreps = 10, weights = NULL)  blocked_cross_validation(block_var)  sequential_blocked_cross_validation(block_var, nfolds = 2, nreps = 4)  custom_cross_validation(sample_set)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/cross_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bootstrap_blocked_cross_validation — bootstrap_blocked_cross_validation","text":"block_var integer vector indicating cross-validation blocks. block indicated unique integer. nreps number repetitions cross-validation procedure. weights numeric vector length `block_var`, representing weights sample. Higher weights indicate observations sampled often. provided, samples treated equally likely. nfolds number folds divide sequence trials within block. sample_set list training test sample indices. element list must named list two elements: \"train\" \"test\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/cross_validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"bootstrap_blocked_cross_validation — bootstrap_blocked_cross_validation","text":"list containing cross-validation specification, class attributes \"bootstrap_blocked_cross_validation\", \"cross_validation\", \"list\". list containing cross-validation specification, class attributes \"blocked_cross_validation\", \"cross_validation\", \"list\". list containing cross-validation specification, class attributes \"sequential_blocked_cross_validation\", \"cross_validation\", \"list\". list containing custom cross-validation specification, class attributes \"custom_cross_validation\", \"cross_validation\", \"list\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/cross_validation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"bootstrap_blocked_cross_validation — bootstrap_blocked_cross_validation","text":"function constructs cross-validation specification using predefined blocking variable creates bootstrap resamples within blocks. function first checks provided weights non-negative normalizes sum 1. constructs list containing block variable, number folds, block indices, number repetitions, weights. output list assigned class `\"bootstrap_blocked_cross_validation\"`, `\"cross_validation\"`, `\"list\"`. function constructs list containing block variable, number folds, block indices. output list assigned class `\"blocked_cross_validation\"`, `\"cross_validation\"`, `\"list\"`. function constructs list containing block variable, number folds, number repetitions, block indices. output list assigned class `\"sequential_blocked_cross_validation\"`, `\"cross_validation\"`, `\"list\"`. custom_cross_validation class allows users define cross-validation structure providing set training test indices. can useful situations standard cross-validation methods (e.g., k-fold, leave-one-) adequately represent desired validation structure. function constructs list containing sample set number folds, derived length sample set. output list assigned class `\"custom_cross_validation\"`, `\"cross_validation\"`, `\"list\"`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/cross_validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bootstrap_blocked_cross_validation — bootstrap_blocked_cross_validation","text":"","code":"block_var <- rep(1:5, each=50) weights <- runif(length(block_var)) weights[1] = 0 cval <- bootstrap_blocked_cross_validation(block_var, weights=weights) X <- matrix(rnorm(length(block_var) * 10), length(block_var), 10) y <- rep(letters[1:5], length.out=length(block_var))  sam <- crossval_samples(cval, as.data.frame(X), y) block_var <- rep(1:5, each=50) cval <- blocked_cross_validation(block_var) X <- matrix(rnorm(length(block_var) * 10), length(block_var), 10) y <- rep(letters[1:5], length.out=length(block_var))  sam <- crossval_samples(cval, as.data.frame(X), y) block_var <- rep(1:5, each=50) nfolds <- 2 nreps <- 4 cval <- sequential_blocked_cross_validation(block_var, nfolds, nreps) X <- matrix(rnorm(length(block_var) * 10), length(block_var), 10) y <- rep(letters[1:5], length.out=length(block_var))  sam <- crossval_samples(cval, as.data.frame(X), y) sample_set <- list(   list(train = 1:80, test = 81:100),   list(train = 1:60, test = 61:100),   list(train = 1:40, test = 41:100) ) cval <- custom_cross_validation(sample_set) X <- matrix(rnorm(100 * 10), 100, 10) y <- rep(letters[1:4], length.out=100)  sam <- crossval_samples(cval, as.data.frame(X), y)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_block.html","id":null,"dir":"Reference","previous_headings":"","what":"Block Cross-Validation Data Preparation — crossv_block","title":"Block Cross-Validation Data Preparation — crossv_block","text":"function prepares data block cross-validation dividing dataset based provided block variable. creates subsets training testing data block without performing analysis fitting models.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_block.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block Cross-Validation Data Preparation — crossv_block","text":"","code":"crossv_block(data, y, block_var, id = \".id\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_block.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Block Cross-Validation Data Preparation — crossv_block","text":"data data frame containing training data. y response vector. block_var integer vector defining cross-validation blocks. id character string specifying identifier output data frame.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_block.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Block Cross-Validation Data Preparation — crossv_block","text":"tibble containing training testing data, response vectors, block IDs fold.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_block.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Block Cross-Validation Data Preparation — crossv_block","text":"","code":"X <- data.frame(x1 = rnorm(100), x2 = rnorm(100)) y <- rep(letters[1:4], 25) block_var <- rep(1:4, each = 25) cv <- crossv_block(X, y, block_var)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_bootstrap_block.html","id":null,"dir":"Reference","previous_headings":"","what":"Block Bootstrap Cross-Validation Data Preparation — crossv_bootstrap_block","title":"Block Bootstrap Cross-Validation Data Preparation — crossv_bootstrap_block","text":"function prepares data block bootstrap cross-validation dividing dataset based provided block variable. creates subsets training testing data block using bootstrap sampling within training blocks, without performing analysis fitting models.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_bootstrap_block.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block Bootstrap Cross-Validation Data Preparation — crossv_bootstrap_block","text":"","code":"crossv_bootstrap_block(   data,   y,   block_var,   nreps = 5,   id = \".id\",   weights = NULL )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_bootstrap_block.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Block Bootstrap Cross-Validation Data Preparation — crossv_bootstrap_block","text":"data data frame containing training data. y response vector. block_var integer vector defining cross-validation blocks. nreps integer specifying number bootstrap repetitions. id character string specifying identifier output data frame. weights optional numeric vector weights used bootstrap sampling.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_bootstrap_block.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Block Bootstrap Cross-Validation Data Preparation — crossv_bootstrap_block","text":"tibble containing training testing data, response vectors, block IDs fold.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_bootstrap_block.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Block Bootstrap Cross-Validation Data Preparation — crossv_bootstrap_block","text":"function first checks length `block_var` vector matches length response vector `y`. creates list block indices ensures one block bootstrap. weights provided, function splits weights according block variable. function performs bootstrap sampling within training blocks keeps test set fixed. block, generates list training indices using bootstrap sampling creates corresponding training testing data sets.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_k.html","id":null,"dir":"Reference","previous_headings":"","what":"K-fold Cross-Validation Data Preparation — crossv_k","title":"K-fold Cross-Validation Data Preparation — crossv_k","text":"function prepares data k-fold cross-validation dividing dataset k folds. creates subsets training testing data fold without performing analysis fitting models.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-fold Cross-Validation Data Preparation — crossv_k","text":"","code":"crossv_k(data, y, k = 5, id = \".id\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-fold Cross-Validation Data Preparation — crossv_k","text":"data data frame containing training data. y response vector. k integer specifying number folds cross-validation. id character string specifying identifier output data frame.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"K-fold Cross-Validation Data Preparation — crossv_k","text":"tibble containing training testing data, response vectors, fold IDs fold.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossv_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"K-fold Cross-Validation Data Preparation — crossv_k","text":"","code":"data <- iris[,-5] y <- iris$Species result <- crossv_k(data, y, k = 5)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossval_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"crossval_samples — crossval_samples","title":"crossval_samples — crossval_samples","text":"Apply cross-validation scheme split data training testing sets.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossval_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"crossval_samples — crossval_samples","text":"","code":"crossval_samples(obj, data, y, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossval_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"crossval_samples — crossval_samples","text":"obj cross-validation control object. data data frame containing predictors. y vector containing response variable. ... Extra arguments passed specific cross-validation methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossval_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"crossval_samples — crossval_samples","text":"tibble containing training testing sets fold.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/crossval_samples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"crossval_samples — crossval_samples","text":"","code":"cval <- kfold_cross_validation(len = 20, nfolds = 4) dat  <- as.data.frame(matrix(rnorm(20 * 2), 20, 2)) y    <- factor(rep(letters[1:4], 5)) crossval_samples(cval, dat, y) #> # A tibble: 4 × 5 #>   ytrain       ytest        train               test               .id   #>   <named list> <named list> <named list>        <named list>       <chr> #> 1 <fct [15]>   <fct [5]>    <resample [15 x 2]> <resample [5 x 2]> 01    #> 2 <fct [15]>   <fct [5]>    <resample [15 x 2]> <resample [5 x 2]> 02    #> 3 <fct [15]>   <fct [5]>    <resample [15 x 2]> <resample [5 x 2]> 03    #> 4 <fct [15]>   <fct [5]>    <resample [15 x 2]> <resample [5 x 2]> 04"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/custom_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Custom Performance Metric to Prediction Result — custom_performance","title":"Apply Custom Performance Metric to Prediction Result — custom_performance","text":"function applies user-supplied performance metric prediction result object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/custom_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Custom Performance Metric to Prediction Result — custom_performance","text":"","code":"custom_performance(x, custom_fun, split_list = NULL)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/custom_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Custom Performance Metric to Prediction Result — custom_performance","text":"x prediction result object. custom_fun function used compute performance metrics, .e., custom_fun(x). split_list optional named list splitting groups. provided, performance metric computed group returned named vector.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/custom_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Custom Performance Metric to Prediction Result — custom_performance","text":"named vector calculated custom performance metric(s).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/custom_performance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Custom Performance Metric to Prediction Result — custom_performance","text":"function allows users apply custom performance metric prediction result object. split list provided, performance metric computed group separately, results returned named vector.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/custom_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Custom Performance Metric to Prediction Result — custom_performance","text":"","code":"cres <- binary_classification_result(   observed  = factor(c(\"A\", \"B\")),   predicted = factor(c(\"A\", \"A\")),   probs = matrix(c(0.9, 0.1,                    0.6, 0.4),                  ncol = 2, byrow = TRUE,                  dimnames = list(NULL, c(\"A\", \"B\"))) ) acc_fun <- function(x) mean(x$observed == x$predicted) custom_performance(cres, acc_fun) #> Error in Ops.factor(x$observed, x$predicted): level sets of factors are different"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/data_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Sample from Dataset — data_sample","title":"Extract Sample from Dataset — data_sample","text":"Extract sample given dataset object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/data_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Sample from Dataset — data_sample","text":"","code":"data_sample(obj, vox, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/data_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Sample from Dataset — data_sample","text":"obj input dataset object. vox voxel indices/coordinates. ... Additional arguments methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/data_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Sample from Dataset — data_sample","text":"sample extracted dataset.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/distance-constructors.html","id":null,"dir":"Reference","previous_headings":"","what":"Distance Function Constructors — cordist","title":"Distance Function Constructors — cordist","text":"convenience functions build specific types distance function objects via create_dist. returns S3 object inheriting c(\"<method>\", \"distfun\").","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/distance-constructors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distance Function Constructors — cordist","text":"","code":"cordist(labels = NULL, method = c(\"pearson\", \"spearman\"))  mahadist(labels = NULL)  eucdist(labels = NULL)  robustmahadist(labels = NULL)  pcadist(   labels = NULL,   ncomp = 2,   whiten = TRUE,   threshfun = NULL,   dist_method = c(\"euclidean\", \"manhattan\", \"cosine\") )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/distance-constructors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distance Function Constructors — cordist","text":"labels Optional vector row labels (directly used distance calculation). method cordist, correlation method: \"pearson\" \"spearman\". ncomp pcadist, number components (function threshold). whiten pcadist, whether whiten principal components (logical). threshfun pcadist, optional function determines many PCs retain based pres$sdev^2. dist_method pcadist, base distance measure PC space (\"euclidean\", \"manhattan\", \"cosine\").","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/distance-constructors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distance Function Constructors — cordist","text":"S3 object class c(\"<method>\", \"distfun\").","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/distance-constructors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distance Function Constructors — cordist","text":"- cordist(labels, method=\"pearson\") → correlation-based distance. - mahadist(labels) → Mahalanobis distance. - eucdist(labels) → Euclidean distance. - robustmahadist(labels) → Mahalanobis distance using robust covariance. - pcadist(labels, ...) → distance reduced PCA space.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/distance-constructors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distance Function Constructors — cordist","text":"","code":"dist_obj_1 <- cordist(method=\"pearson\") dist_obj_2 <- mahadist() dist_obj_3 <- eucdist() dist_obj_4 <- robustmahadist() dist_obj_5 <- pcadist(ncomp=2, dist_method=\"cosine\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_merge_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge searchlight results — do_merge_results","title":"Merge searchlight results — do_merge_results","text":"function merges searchlight results, combining first result rest results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_merge_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge searchlight results — do_merge_results","text":"","code":"do_merge_results(r1, good_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_merge_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge searchlight results — do_merge_results","text":"r1 list indices representing searchlight results merged. good_results data frame containing valid searchlight results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_merge_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge searchlight results — do_merge_results","text":"combined searchlight result object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_randomized.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform randomized searchlight analysis — do_randomized","title":"Perform randomized searchlight analysis — do_randomized","text":"function performs randomized searchlight analysis using specified model, radius, number iterations. can customized different MVPA functions, combiners, permutation options.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_randomized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform randomized searchlight analysis — do_randomized","text":"","code":"do_randomized(   model_spec,   radius,   niter,   mvpa_fun = mvpa_iterate,   combiner = pool_randomized,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_randomized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform randomized searchlight analysis — do_randomized","text":"model_spec object specifying model used searchlight analysis. radius radius searchlight sphere. niter number iterations randomized searchlight. mvpa_fun MVPA function used searchlight analysis (default mvpa_iterate). combiner function used combine results (default pool_randomized). ... Additional arguments passed MVPA function.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform standard searchlight analysis — do_standard","title":"Perform standard searchlight analysis — do_standard","text":"function performs standard searchlight analysis using specified model radius. can customized different MVPA functions, combiners, permutation options.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform standard searchlight analysis — do_standard","text":"","code":"do_standard(   model_spec,   radius,   mvpa_fun = mvpa_iterate,   combiner = combine_standard,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/do_standard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform standard searchlight analysis — do_standard","text":"model_spec object specifying model used searchlight analysis. radius radius searchlight sphere. mvpa_fun MVPA function used searchlight analysis (default mvpa_iterate). combiner function used combine results (default combine_standard). ... Additional arguments passed MVPA function.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.feature_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate model performance for feature RSA — evaluate_model.feature_rsa_model","title":"Evaluate model performance for feature RSA — evaluate_model.feature_rsa_model","text":"Computes correlation-based metrics (diag correlation, mean correlation, voxel correlation), MSE, R^2, optionally performs permutation tests (via helper function).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.feature_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate model performance for feature RSA — evaluate_model.feature_rsa_model","text":"","code":"evaluate_model.feature_rsa_model(   object,   predicted,   observed,   nperm = 0,   save_distributions = FALSE,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.feature_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate model performance for feature RSA — evaluate_model.feature_rsa_model","text":"object feature RSA model predicted Matrix predicted values (feature space F voxel space X) observed Matrix observed values (actual voxel space X) nperm Number permutations statistical testing (default: 0, permutation) save_distributions Logical indicating whether save full permutation distributions ... Additional arguments","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.feature_rsa_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate model performance for feature RSA — evaluate_model.feature_rsa_model","text":"list containing performance metrics optional permutation results","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.vector_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate model performance for vector RSA — evaluate_model.vector_rsa_model","title":"Evaluate model performance for vector RSA — evaluate_model.vector_rsa_model","text":"Computes mean second-order similarity score handles permutation testing.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.vector_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate model performance for vector RSA — evaluate_model.vector_rsa_model","text":"","code":"evaluate_model.vector_rsa_model(   object,   predicted,   observed,   roi_data_for_perm = NULL,   nperm = 0,   save_distributions = FALSE,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.vector_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate model performance for vector RSA — evaluate_model.vector_rsa_model","text":"object vector RSA model specification. predicted Ignored (vector RSA predict typical sense). observed computed second-order similarity scores (vector train_model). roi_data_for_perm New parameter nperm Number permutations model spec. save_distributions Logical, whether save full permutation distributions. ... Additional arguments.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/evaluate_model.vector_rsa_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate model performance for vector RSA — evaluate_model.vector_rsa_model","text":"list containing mean RSA score (`rsa_score`), raw scores,   optional permutation results (`p_values`, `z_scores`, `permutation_distributions`).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Feature-Based RSA Design — feature_rsa_design","title":"Create a Feature-Based RSA Design — feature_rsa_design","text":"Creates design feature-based Representational Similarity Analysis (RSA). can either supply similarity matrix S (optionally select dimensions) directly supply feature matrix F.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Feature-Based RSA Design — feature_rsa_design","text":"","code":"feature_rsa_design(   S = NULL,   F = NULL,   labels,   k = 0,   max_comps = 10,   block_var = NULL )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Feature-Based RSA Design — feature_rsa_design","text":"S symmetric similarity matrix representing feature space relationships. NULL, must supply F. F feature space matrix (observations features). supplied, overrides S k. labels Vector labels corresponding rows/columns S observations F. k Integer specifying number feature dimensions retain using S. 0 (default), automatically determines dimensions using eigenvalue threshold > 1 (minimum 2 dimensions kept). parameter ignored F supplied directly (k becomes ncol(F)). max_comps Initial upper limit number components derived feature space F subsequent `feature_rsa_model` methods (PCA, PLS). value automatically capped final feature dimensionality `k`. Default 10. block_var Optional blocking variable cross-validation. provided `crossval` `NULL` `feature_rsa_model`, blocked cross-validation scheme generated using vector.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Feature-Based RSA Design — feature_rsa_design","text":"feature_rsa_design object (S3 class) containing: S input similarity matrix (used) F Feature space projection matrix (k dimensions) labels Vector observation labels k final number feature dimensions used max_comps upper limit components (<= k) block_var Optional blocking variable cross-validation","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Feature-Based RSA Design — feature_rsa_design","text":"function defines feature space representation analysis. F supplied directly, used -, `k` becomes `ncol(F)`. S supplied, eigen decomposition S performed. `k` determines many eigenvectors form feature matrix F. `k=0`, dimensions eigenvalues > 1 kept (minimum 2). `max_comps` sets upper bound number components model-fitting methods (like PCA, PLS `feature_rsa_model`) can use, exceed final feature dimensionality `k`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Feature-Based RSA Model — feature_rsa_model","title":"Create a Feature-Based RSA Model — feature_rsa_model","text":"Creates model feature-based Representational Similarity Analysis (RSA) relates neural patterns (X) predefined feature space (F).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Feature-Based RSA Model — feature_rsa_model","text":"","code":"feature_rsa_model(   dataset,   design,   method = c(\"pls\", \"pca\", \"glmnet\"),   crossval = NULL,   cache_pca = FALSE,   alpha = 0.5,   cv_glmnet = FALSE,   lambda = NULL,   nperm = 0,   permute_by = c(\"features\", \"observations\"),   save_distributions = FALSE,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Feature-Based RSA Model — feature_rsa_model","text":"dataset mvpa_dataset object containing neural data (X). design feature_rsa_design object specifying feature space (F) including component limit (`max_comps`). method Character string specifying analysis method. One : pls Partial Least Squares regression predicting X F. pca Principal Component Analysis F, followed regression predicting X PCs. glmnet Elastic net regression predicting X F using glmnet multivariate Gaussian response. crossval Optional cross-validation specification. cache_pca Logical, TRUE method \"pca\", cache PCA decomposition feature matrix F across cross-validation folds involving training rows. Defaults FALSE. alpha Numeric value 0 1, used method=\"glmnet\". Controls elastic net mixing parameter: 1 lasso (default), 0 ridge, values mixture. Defaults 0.5 (equal mix ridge lasso). cv_glmnet Logical, TRUE method=\"glmnet\", use cv.glmnet automatically select optimal lambda value via cross-validation. Defaults FALSE. lambda Optional numeric value sequence values, used method=\"glmnet\" cv_glmnet=FALSE. Specifies regularization parameter. NULL (default), sequence automatically determined glmnet. nperm Integer, number permutations run statistical testing model performance metrics merging cross-validation folds. Default 0 (permutation testing). permute_by DEPRECATED. Permutation always done shuffling rows predicted matrix. save_distributions Logical, TRUE nperm > 0, save full null distributions permutation test. Defaults FALSE. ... Additional arguments (currently unused).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Feature-Based RSA Model — feature_rsa_model","text":"feature_rsa_model object (S3 class).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_rsa_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Feature-Based RSA Model — feature_rsa_model","text":"Feature RSA models analyze well feature matrix F (defined `design`) relates neural data X. `max_comps` parameter, inherited `design` object, sets upper limit number components used:   - pca: Performs PCA F. `max_comps` limits number principal components     (selected variance explained) used predict X. Actual components used: `min(max_comps, available_PCs)`.   - pls: Performs PLS regression predicting X F. `max_comps` sets     maximum number PLS components compute. Actual components used may fewer based PLS algorithm.   - glmnet: Performs elastic net regression predicting X F using glmnet package     multivariate Gaussian response family. regularization (lambda) can automatically selected via cross-validation     cv_glmnet=TRUE. alpha parameter controls balance L1 (lasso) L2 (ridge) regularization. **Performance Metrics** (computed `evaluate_model` cross-validation):   - `mean_correlation`: Average correlation predicted observed patterns corresponding trials/conditions (diagonal prediction-observation correlation matrix).   - `cor_difference`: `mean_correlation` minus average -diagonal correlation (`mean_correlation` - `off_diag_correlation`). Measures much better model predicts correct trial/condition compared incorrect ones.   - `mean_rank_percentile`: Average percentile rank diagonal correlations. condition, ranks well model's prediction correlates correct observed pattern compared incorrect patterns. Values range 0 1, 0.5 expected chance 1 indicating perfect discrimination.   - `voxel_correlation`: Correlation vectorized predicted observed data matrices across trials voxels.   - `mse`: Mean Squared Error predicted observed values.   - `r_squared`: Proportion variance observed data explained predicted data.   - `p_*`, `z_*`: `nperm > 0`, permutation-based p-values z-scores metrics, assessing significance null distribution generated shuffling predicted trial labels. number components actually used (`ncomp`) region/searchlight also included performance output.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selection.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Selection Methods — feature_selection","title":"Feature Selection Methods — feature_selection","text":"Feature Selection Methods","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selection.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Feature Selection Methods — feature_selection","text":"Two feature selection methods available: FTest One-way ANOVA F-test feature catscore Correlation-adjusted t-scores using sda.ranking","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selection.html","id":"cutoff-types","dir":"Reference","previous_headings":"","what":"Cutoff Types","title":"Feature Selection Methods — feature_selection","text":"Two types cutoffs supported: top_k/topk Select top k features top_p/topp Select top p percent features (0 < p <= 1)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selector.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a feature selection specification — feature_selector","title":"Create a feature selection specification — feature_selector","text":"function creates feature selection specification using provided method, cutoff type, cutoff value.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a feature selection specification — feature_selector","text":"","code":"feature_selector(method, cutoff_type, cutoff_value)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a feature selection specification — feature_selector","text":"method type feature selection method use. Supported methods \"FTest\" \"catscore\". cutoff_type type threshold used select features. Supported cutoff types \"top_k\" \"top_p\". cutoff_value numeric value threshold cutoff.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a feature selection specification — feature_selector","text":"list class name equal method argument.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a feature selection specification — feature_selector","text":"available feature selection methods :   - FTest: Computes one-way ANOVA every column feature matrix.   - catscore: Computes correlation adjusted t-test every column matrix using sda.ranking sda package.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/feature_selector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a feature selection specification — feature_selector","text":"","code":"fsel <- feature_selector(\"FTest\", \"top_k\", 1000) fsel <- feature_selector(\"FTest\", \"top_p\", .1) class(fsel) == \"FTest\" #> [1]  TRUE FALSE FALSE"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/filter_roi.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Region of Interest (ROI) — filter_roi","title":"Filter Region of Interest (ROI) — filter_roi","text":"Filter ROI removing columns missing values zero std dev.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/filter_roi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Region of Interest (ROI) — filter_roi","text":"","code":"filter_roi(roi, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/filter_roi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Region of Interest (ROI) — filter_roi","text":"roi list containing train test ROI data. ... Additional arguments passed methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/filter_roi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Region of Interest (ROI) — filter_roi","text":"list filtered train test ROI data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/fit_model-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Model — fit_model","title":"Fit Model — fit_model","text":"Fit classification regression model.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/fit_model-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Model — fit_model","text":"","code":"fit_model(   obj,   roi_x,   y,   wts,   param,   lev = NULL,   last = FALSE,   classProbs = FALSE,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/fit_model-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Model — fit_model","text":"obj model fitting object. roi_x ROI containing training data. y response vector. wts set case weights. param Tuning parameters. lev Factor levels (classification). last Logical indicating last iteration. classProbs Logical indicating class probabilities returned. ... Additional arguments passed method-specific function.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/fit_model-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Model — fit_model","text":"","code":"# \\donttest{   ds <- gen_sample_dataset(     D = c(6, 6, 6), nobs = 20,     response_type = \"categorical\",     data_mode = \"image\", nlevels = 2   )   mdl <- load_model(\"sda_notune\")   mspec <- mvpa_model(     model = mdl,     dataset = ds$dataset,     design  = ds$design,     model_type = \"classification\"   )   grid <- tune_grid(mspec, ds$dataset$train_data, ds$design$y_train, len = 1)   fit  <- fit_model(mspec, ds$dataset$train_data,                    ds$design$y_train, wts = NULL, param = grid) #> Error in UseMethod(\"fit_model\"): no applicable method for 'fit_model' applied to an object of class \"c('mvpa_model', 'model_spec', 'list')\" # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/format_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Format Result Object — format_result","title":"Format Result Object — format_result","text":"Format Result Object","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/format_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format Result Object — format_result","text":"","code":"format_result(obj, result, error_message, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/format_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format Result Object — format_result","text":"obj result object formatted. result result object formatted. error_message optional error message. ... Additional arguments passed method-specific function.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/format_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format Result Object — format_result","text":"","code":"# \\donttest{ dataset <- gen_sample_dataset(D = c(6, 6, 6), nobs = 20,                               response_type = \"categorical\",                               data_mode = \"image\") cval <- blocked_cross_validation(dataset$design$block_var) model <- load_model(\"sda_notune\") mspec <- mvpa_model(model, dataset$dataset, dataset$design,                     \"classification\", crossval = cval) # Typically called internally during processing format_result(mspec, result = NULL, error_message = \"example\",               context = list(test = 1, ytest = factor(\"a\"))) #> Error in UseMethod(\"format_result\"): no applicable method for 'format_result' applied to an object of class \"c('mvpa_model', 'model_spec', 'list')\" # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/gen_sample_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Sample Dataset for MVPA Analysis — gen_sample_dataset","title":"Generate Sample Dataset for MVPA Analysis — gen_sample_dataset","text":"Creates synthetic dataset testing demonstration MVPA analyses.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/gen_sample_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Sample Dataset for MVPA Analysis — gen_sample_dataset","text":"","code":"gen_sample_dataset(   D,   nobs,   response_type = c(\"categorical\", \"continuous\"),   data_mode = c(\"image\", \"surface\"),   spacing = c(1, 1, 1),   blocks = 5,   nlevels = 5,   external_test = FALSE,   ntest_obs = nobs,   split_by = NULL,   na_cols = 0 )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/gen_sample_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Sample Dataset for MVPA Analysis — gen_sample_dataset","text":"D data dimension(s): vector length 2 3 image data, single number surface data nobs number observations response_type Either 'categorical' 'continuous' data_mode Either 'image' 'surface' spacing voxel spacing (default: c(1,1,1)) blocks number 'blocks' data (cross-validation) nlevels number category levels (used response_type='categorical') external_test Whether generate external test set ntest_obs number test observations (default: nobs) split_by Optional factor splitting analyses na_cols number columns randomly set NA (default: 0)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/gen_sample_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Sample Dataset for MVPA Analysis — gen_sample_dataset","text":"list containing: dataset mvpa_dataset object containing: train_data: Training data NeuroVec ROISurface test_data: Test data (external_test=TRUE) mask: Binary mask indicating valid voxels/vertices  design mvpa_design object containing: y_train: Response variable training y_test: Response variable test set (external_test=TRUE) block_var: Block variable cross-validation split_by: Optional splitting factor","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/gen_sample_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Sample Dataset for MVPA Analysis — gen_sample_dataset","text":"","code":"# Generate categorical image dataset dataset <- gen_sample_dataset(   D = c(10,10,10),   nobs = 100,   response_type = \"categorical\",   data_mode = \"image\",   blocks = 3,   nlevels = 2 )  # Generate continuous surface dataset surf_data <- gen_sample_dataset(   D = 1000,  # number of vertices   nobs = 50,   response_type = \"continuous\",   data_mode = \"surface\" ) #> loading /home/runner/work/_temp/Library/neurosurf/extdata/std.8_lh.inflated.asc  # Generate dataset with external test set test_dataset <- gen_sample_dataset(   D = c(8,8,8),   nobs = 80,   response_type = \"categorical\",   nlevels = 3,   external_test = TRUE ) #> external test"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_nfolds.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Number of Folds — get_nfolds","title":"Get the Number of Folds — get_nfolds","text":"S3 generic method retrieve number folds cross-validation specification object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_nfolds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Number of Folds — get_nfolds","text":"","code":"get_nfolds(obj, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_nfolds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Number of Folds — get_nfolds","text":"obj cross-validation specification object (e.g., inheriting `cross_validation`). ... Additional arguments passed methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_nfolds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Number of Folds — get_nfolds","text":"integer representing number folds.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_nfolds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Number of Folds — get_nfolds","text":"","code":"cval <- kfold_cross_validation(len = 20, nfolds = 4) get_nfolds(cval) #> [1] 4"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Multiple Data Samples — get_samples","title":"Get Multiple Data Samples — get_samples","text":"Extract multiple data samples based list voxel/index sets dataset object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Multiple Data Samples — get_samples","text":"","code":"get_samples(obj, vox_list)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Multiple Data Samples — get_samples","text":"obj input dataset object. vox_list list vectors containing voxel indices extract.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Multiple Data Samples — get_samples","text":"list data samples.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_searchlight.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Searchlight Iterator — get_searchlight","title":"Generate Searchlight Iterator — get_searchlight","text":"Generate searchlight iterator suitable given data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_searchlight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Searchlight Iterator — get_searchlight","text":"","code":"get_searchlight(obj, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_searchlight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Searchlight Iterator — get_searchlight","text":"obj input dataset object. ... Additional arguments methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_searchlight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Searchlight Iterator — get_searchlight","text":"searchlight iterator object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_unique_regions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Unique Region IDs — get_unique_regions","title":"Get Unique Region IDs — get_unique_regions","text":"Extract unique region IDs region mask, handling volume surface data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_unique_regions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Unique Region IDs — get_unique_regions","text":"","code":"get_unique_regions(region_mask, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_unique_regions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Unique Region IDs — get_unique_regions","text":"region_mask region mask object (NeuroVol NeuroSurface) ... Additional arguments passed methods","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/get_unique_regions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Unique Region IDs — get_unique_regions","text":"sorted vector unique region IDs greater 0","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/group_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Group Means of a Matrix — group_means","title":"Compute Group Means of a Matrix — group_means","text":"function calculates average vector level grouping variable given matrix.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/group_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Group Means of a Matrix — group_means","text":"","code":"group_means(X, margin, group)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/group_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Group Means of a Matrix — group_means","text":"X matrix group means calculated. margin integer specifying margin average . Use 1 averaging rows, 2 averaging columns. group grouping variable, either factor integer vector, defines groups calculate means .","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/group_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Group Means of a Matrix — group_means","text":"matrix number rows columns (depending margin) input matrix X, number columns rows corresponding number unique groups grouping variable.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/group_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Group Means of a Matrix — group_means","text":"","code":"# Create a random matrix data <- matrix(rnorm(100 * 100), 100, 100)  # Define a grouping variable groups <- factor(rep(1:5, each = 20))  # Calculate group means for each row row_means <- group_means(data, margin = 1, group = groups)  # Calculate group means for each column col_means <- group_means(data, margin = 2, group = groups)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_crossval-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-Validation Availability — has_crossval","title":"Cross-Validation Availability — has_crossval","text":"Determine whether cross-validation specified object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_crossval-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-Validation Availability — has_crossval","text":"","code":"has_crossval(obj)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_crossval-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-Validation Availability — has_crossval","text":"obj Model specification object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_crossval-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-Validation Availability — has_crossval","text":"Logical indicating cross-validation performed.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_crossval-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-Validation Availability — has_crossval","text":"","code":"ds <- gen_sample_dataset(D = c(4, 4, 4), nobs = 10) cval <- blocked_cross_validation(ds$design$block_var) mdl <- load_model(\"sda_notune\") mspec <- mvpa_model(mdl, ds$dataset, ds$design,                     \"classification\", crossval = cval) has_crossval(mspec) #> [1] TRUE"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_test_set-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Test Set Availability — has_test_set","title":"Test Set Availability — has_test_set","text":"Determine whether object contains separate test set.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_test_set-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test Set Availability — has_test_set","text":"","code":"has_test_set(obj)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_test_set-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test Set Availability — has_test_set","text":"obj Object query.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_test_set-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test Set Availability — has_test_set","text":"Logical indicating test set exists.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/has_test_set-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test Set Availability — has_test_set","text":"","code":"ds <- gen_sample_dataset(D = c(4, 4, 4), nobs = 10, external_test = TRUE) #> external test has_test_set(ds$design) #> Error in UseMethod(\"has_test_set\"): no applicable method for 'has_test_set' applied to an object of class \"c('mvpa_design', 'list')\""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/kfold_cross_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"kfold_cross_validation — kfold_cross_validation","title":"kfold_cross_validation — kfold_cross_validation","text":"Construct cross-validation specification randomly partitions input set nfolds folds.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/kfold_cross_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"kfold_cross_validation — kfold_cross_validation","text":"","code":"kfold_cross_validation(len, nfolds = 10)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/kfold_cross_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"kfold_cross_validation — kfold_cross_validation","text":"len integer representing number observations. nfolds integer specifying number cross-validation folds.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/kfold_cross_validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"kfold_cross_validation — kfold_cross_validation","text":"object class \"kfold_cross_validation\", \"cross_validation\", \"list\" containing block_var nfolds.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/kfold_cross_validation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"kfold_cross_validation — kfold_cross_validation","text":"function creates k-fold cross-validation scheme cases data needs split specified number folds evaluation. returns object class \"kfold_cross_validation\", \"cross_validation\", \"list\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/kfold_cross_validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"kfold_cross_validation — kfold_cross_validation","text":"","code":"cval <- kfold_cross_validation(len=100, nfolds=10) sample_data <- as.data.frame(matrix(rnorm(100*10), 100, 10)) sample_y <- rep(letters[1:5], 20) samples <- crossval_samples(cval, data = sample_data, y = sample_y) stopifnot(nrow(samples) == 10)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/load_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a Pre-defined MVPA Model — load_model","title":"Load a Pre-defined MVPA Model — load_model","text":"Retrieves model specification pre-defined set MVPA models.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/load_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a Pre-defined MVPA Model — load_model","text":"","code":"load_model(name)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/load_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a Pre-defined MVPA Model — load_model","text":"name Character string specifying model load. Must pre-defined MVPA model name: corclass Correlation-based classifier template matching sda_notune Simple Shrinkage Discriminant Analysis without tuning sda_boot SDA bootstrap resampling glmnet_opt Elastic net EPSGO parameter optimization sparse_sda SDA sparsity constraints sda_ranking SDA automatic feature ranking mgsda Multi-Group Sparse Discriminant Analysis lda_thomaz Modified LDA high-dimensional data hdrda High-Dimensional Regularized Discriminant Analysis","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/load_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a Pre-defined MVPA Model — load_model","text":"list containing model specification following components: type Model type: \"Classification\" \"Regression\" library Required R package(s) model label Human-readable model name parameters Data frame describing tunable parameters grid Function generate parameter tuning grid fit Function fit model predict Function generate predictions prob Function generate class probabilities (classification )","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/load_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a Pre-defined MVPA Model — load_model","text":"","code":"# Load custom MVPA model model <- load_model(\"sda_notune\")  # Load correlation classifier with parameter tuning options corr_model <- load_model(\"corclass\") print(corr_model$parameters)  # View tunable parameters #>   parameters     class                                           label #> 1     method character correlation type: pearson, spearman, or kendall #> 2     robust   logical                                   mean or huber"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/make_feature_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Contrasts from a Feature Matrix (Optional PCA) — make_feature_contrasts","title":"Generate Contrasts from a Feature Matrix (Optional PCA) — make_feature_contrasts","text":"Creates contrasts based matrix rows represent conditions columns represent features (e.g., neural network embeddings, semantic features). Optionally performs PCA reduce dimensionality.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/make_feature_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Contrasts from a Feature Matrix (Optional PCA) — make_feature_contrasts","text":"","code":"make_feature_contrasts(   features,   labels = NULL,   use_pca = TRUE,   centre_pca = TRUE,   scale_pca = FALSE,   pve = 0.9,   n_pcs = NULL,   prefix = \"Feat_\" )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/make_feature_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Contrasts from a Feature Matrix (Optional PCA) — make_feature_contrasts","text":"features numeric matrix (K x P) K number conditions P number features. Row names, present, correspond condition labels. Column names recommended. labels Optional character vector condition labels. provided, rows `features` matrix reordered match order. NULL, order `rownames(features)` used (available). use_pca Logical. TRUE (default), performs Principal Component Analysis (PCA) features. FALSE, uses raw features directly. centre_pca Logical. `use_pca = TRUE`, features centered PCA? (Default: TRUE) Note: Reordering rows based `labels` argument happens ** PCA. scale_pca Logical. `use_pca = TRUE`, features scaled unit variance PCA? (Default: FALSE, scaling can affect variance explained). Note: Reordering rows based `labels` argument happens ** PCA. pve Numeric (0 1). `use_pca = TRUE`, selects minimum number principal components (PCs) needed explain least proportion variance. Ignored `n_pcs` specified. (Default: 0.9) n_pcs Integer. `use_pca = TRUE`, selects exactly number principal components. Takes precedence `pve`. (Default: NULL) prefix Character string prepend column names output matrix (e.g., \"Feat_\", \"PCA_\"). (Default: \"Feat_\")","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/make_feature_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Contrasts from a Feature Matrix (Optional PCA) — make_feature_contrasts","text":"numeric matrix (K x Q) K matches number conditions/labels   Q number selected features principal components.   Rows ordered according `labels` `rownames(features)`.   Columns named using `prefix` either original feature names   (`use_pca=FALSE`) component numbers (e.g., \"PCA_PC1\", \"PCA_PC2\").","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/make_feature_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Contrasts from a Feature Matrix (Optional PCA) — make_feature_contrasts","text":"","code":"# Example feature matrix (4 conditions, 5 features) feat_mat <- matrix(rnorm(20), nrow = 4,                    dimnames = list(paste0(\"Cond\", 1:4), paste0(\"F\", 1:5)))  # Use raw features (first 3) C_raw <- make_feature_contrasts(feat_mat[, 1:3], use_pca = FALSE, prefix=\"RawFeat_\") print(C_raw) #>       RawFeat_F1  RawFeat_F2 RawFeat_F3 #> Cond1 -0.1192940  2.67029247 -1.1008429 #> Cond2  0.2962191  0.07558749 -0.9032616 #> Cond3 -0.3867527 -0.27008920  1.0620304 #> Cond4 -0.5690379  0.56529799  0.0182128  # Use PCA, selecting top 2 PCs C_pca <- make_feature_contrasts(feat_mat, use_pca = TRUE, n_pcs = 2, prefix=\"PCA_\") print(C_pca) #>           PCA_PC1      PCA_PC2 #> Cond1  2.72244071 -0.001983375 #> Cond2 -0.66942072 -1.129628508 #> Cond3 -2.11147684  0.376485036 #> Cond4  0.05845684  0.755126847  # Use PCA, selecting >= 80% variance explained C_pca_pve <- make_feature_contrasts(feat_mat, use_pca = TRUE, pve = 0.8, prefix=\"PCA_\") print(C_pca_pve) #>           PCA_PC1 #> Cond1  2.72244071 #> Cond2 -0.66942072 #> Cond3 -2.11147684 #> Cond4  0.05845684  # Reorder based on labels C_pca_reorder <- make_feature_contrasts(feat_mat, labels=c(\"Cond3\", \"Cond1\", \"Cond4\", \"Cond2\"),                                       use_pca = TRUE, n_pcs = 2, prefix=\"PCA_\") print(C_pca_reorder) #>           PCA_PC1      PCA_PC2 #> Cond3  2.11147684 -0.376485036 #> Cond1 -2.72244071  0.001983375 #> Cond4 -0.05845684 -0.755126847 #> Cond2  0.66942072  1.129628508"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a MANOVA Design — manova_design","title":"Create a MANOVA Design — manova_design","text":"function creates MANOVA design object containing formula expression named list data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a MANOVA Design — manova_design","text":"","code":"manova_design(formula, data)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a MANOVA Design — manova_design","text":"formula formula expression specifying MANOVA regression model. data named list containing dissimilarity matrices auxiliary variables.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a MANOVA Design — manova_design","text":"MANOVA design object class attributes \"manova_design\" \"list\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a MANOVA Design — manova_design","text":"function takes formula expression named list data input, returns MANOVA design object. object list contains formula expression named list data class attributes \"manova_design\" \"list\". object can used MANOVA analysis related multivariate statistical methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a MANOVA Design — manova_design","text":"","code":"# Create a MANOVA design formula <- y ~ x1 + x2 data_list <- list(   y = dissimilarity_matrix_y,   x1 = dissimilarity_matrix_x1,   x2 = dissimilarity_matrix_x2 ) #> Error: object 'dissimilarity_matrix_y' not found manova_design_obj <- manova_design(formula, data_list) #> Error: object 'data_list' not found"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a MANOVA Model — manova_model","title":"Create a MANOVA Model — manova_model","text":"function creates MANOVA model object containing `mvpa_dataset` instance `manova_design` instance.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a MANOVA Model — manova_model","text":"","code":"manova_model(dataset, design)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a MANOVA Model — manova_model","text":"dataset mvpa_dataset instance. design manova_design instance.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a MANOVA Model — manova_model","text":"MANOVA model object class attributes \"manova_model\" \"list\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a MANOVA Model — manova_model","text":"function takes `mvpa_dataset` instance `manova_design` instance input, returns MANOVA model object. object list contains dataset design class attributes \"manova_model\" \"list\". object can used multivariate statistical analysis using MANOVA method.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/manova_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a MANOVA Model — manova_model","text":"","code":"# Create a MANOVA model dataset <- create_mvpa_dataset(data_matrix, labels, subject_ids) #> Error in create_mvpa_dataset(data_matrix, labels, subject_ids): could not find function \"create_mvpa_dataset\" formula <- y ~ x1 + x2 data_list <- list(   y = dissimilarity_matrix_y,   x1 = dissimilarity_matrix_x1,   x2 = dissimilarity_matrix_x2 ) #> Error: object 'dissimilarity_matrix_y' not found design <- manova_design(formula, data_list) #> Error: object 'data_list' not found manova_model_obj <- manova_model(dataset, design) #> Error: object 'dataset' not found"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_classif_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge Multiple Classification/Regression Results — merge_classif_results","title":"Merge Multiple Classification/Regression Results — merge_classif_results","text":"function merges two classification/regression result objects.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_classif_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge Multiple Classification/Regression Results — merge_classif_results","text":"","code":"merge_classif_results(x, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_classif_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge Multiple Classification/Regression Results — merge_classif_results","text":"x first classification/regression result object. ... Additional classification/regression result objects.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_classif_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge Multiple Classification/Regression Results — merge_classif_results","text":"single merged classification/regression result object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge Predictions — merge_predictions","title":"Merge Predictions — merge_predictions","text":"Combine predictions multiple models test set.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge Predictions — merge_predictions","text":"","code":"merge_predictions(obj1, rest, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge Predictions — merge_predictions","text":"obj1 first object containing predictions. rest objects containing predictions. ... Additional arguments. Methods generic may implement specific arguments `weights` control predictions combined.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge Predictions — merge_predictions","text":"combined object merged predictions.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge Results for MANOVA Model — merge_results.manova_model","title":"Merge Results for MANOVA Model — merge_results.manova_model","text":"function takes computed -log(p-values) `train_model.manova_model` single ROI/searchlight formats standard output tibble. function takes computed coefficients/correlations/t-values train_model.rsa_model single ROI/searchlight formats standard output tibble. Aggregates results (scores) calls evaluate_model. Vector RSA typically involve folds way classifiers, mainly formats output train_model specific ROI/sphere.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge Results for MANOVA Model — merge_results.manova_model","text":"","code":"# S3 method for class 'manova_model' merge_results(obj, result_set, indices, id, ...)  # S3 method for class 'mvpa_model' merge_results(obj, result_set, indices, id, ...)  # S3 method for class 'binary_classification_result' merge_results(x, ...)  # S3 method for class 'regression_result' merge_results(x, ...)  # S3 method for class 'multiway_classification_result' merge_results(x, ...)  # S3 method for class 'regional_mvpa_result' merge_results(x, ...)  # S3 method for class 'rsa_model' merge_results(obj, result_set, indices, id, ...)  # S3 method for class 'vector_rsa_model' merge_results(obj, result_set, indices, id, ...)  # S3 method for class 'feature_rsa_model' merge_results(obj, result_set, indices, id, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge Results for MANOVA Model — merge_results.manova_model","text":"obj vector RSA model specification (contains nperm etc.). result_set tibble processor. Expected contain output `train_model.vector_rsa_model` (scores vector) likely within `$result[[1]]`. indices Voxel indices current ROI/searchlight sphere. id Identifier current ROI/searchlight center. ... Additional arguments. x regional_mvpa_result object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge Results for MANOVA Model — merge_results.manova_model","text":"tibble row formatted performance metrics ROI/sphere. merged regional_mvpa_result object. tibble row formatted \"performance\" metrics (coefficients/t-values/correlations) ROI/sphere. tibble row final performance metrics ROI/sphere.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge Multiple Results — merge_results","title":"Merge Multiple Results — merge_results","text":"Merge Multiple Results","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge Multiple Results — merge_results","text":"","code":"merge_results(obj, result_set, indices, id, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge Multiple Results — merge_results","text":"obj base object containing merge specifications result_set List results merged indices List indices corresponding result id Identifier merged result ... Additional arguments passed specific merge methods","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge Multiple Results — merge_results","text":"merged result object containing: Combined results input objects Associated indices Merged metadata","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/merge_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge Multiple Results — merge_results","text":"","code":"# \\donttest{ ds <- gen_sample_dataset(D = c(5, 5, 5), nobs = 20, nlevels = 2) model <- load_model(\"sda_notune\") mspec <- mvpa_model(   model = model,   dataset = ds$dataset,   design = ds$design,   model_type = \"classification\" ) result_set <- tibble::tibble(   result = list(NULL),   error = FALSE,   error_message = \"~\" ) merge_results(mspec, result_set, indices = list(1:10), id = 1) #> Warning: Unknown or uninitialised column: `test_ind`. #> Warning: Unknown or uninitialised column: `probs`. #> Error: length(observed) not equal to length(predicted) # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/msreve_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor for msreve_design — msreve_design","title":"Constructor for msreve_design — msreve_design","text":"Creates msreve_design object, encapsulates necessary design information Multi-Dimensional Signed Representational Voxel Encoding (MS-ReVE) analysis.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/msreve_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for msreve_design — msreve_design","text":"","code":"msreve_design(   mvpa_design,   contrast_matrix,   name = \"msreve_design_01\",   include_interactions = FALSE,   nuisance_rdms = NULL )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/msreve_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for msreve_design — msreve_design","text":"mvpa_design object class \\codemvpa_design, containing information conditions, blocks, cross-validation. contrast_matrix numeric matrix (\\codeK x Q) \\codeK number conditions \\codeQ number contrasts. column represents contrast vector. highly recommended columns named identify contrasts. name optional character string name design. include_interactions Logical. TRUE, automatically add pairwise interaction contrasts using add_interaction_contrasts. nuisance_rdms Optional named list K x K matrices dist objects representing nuisance RDMs included additional predictors MS-ReVE regression. typically temporal spatial nuisance patterns accounted primary interest.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/msreve_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for msreve_design — msreve_design","text":"object class \\codemsreve_design, list containing:   \\itemmvpa_designThe input \\codemvpa_design object.   \\itemcontrast_matrixThe input \\codecontrast_matrix.   \\itemnameThe name design.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/msreve_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor for msreve_design — msreve_design","text":"","code":"# Assume 'mvpa_des_obj' is a pre-existing mvpa_design object # e.g. from mvpa_design(data=my_data_frame, formula = ~ condition_labels + run_labels, #                       block_var = \"run_labels\") # Let\\'s say mvpa_des_obj implies 6 conditions based on unique(my_data_frame$condition_labels) K <- 6 # Number of conditions Q <- 2 # Number of contrasts  # Example contrast matrix (K x Q) C_mat <- matrix(c(  # C1: Cond 1,2,3 vs 4,5,6   1,  1,  1, -1, -1, -1,  # C2: Cond 1,2 vs 3 (and 0 for 4,5,6 for simplicity here)   1,  1, -2,  0,  0,  0 ), nrow = K, ncol = Q, byrow = FALSE) colnames(C_mat) <- c(\"GroupComparison\", \"SubComparison\")  # if (inherits(mvpa_des_obj, \"mvpa_design\")) { #  design_obj <- msreve_design(mvpa_des_obj, C_mat, name=\"example_msreve\") #  print(design_obj) # } # # # Automatically add pairwise interactions # design_obj_int <- msreve_design(mvpa_des_obj, C_mat, #                                include_interactions = TRUE) # colnames(design_obj_int$contrast_matrix)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/multiway_classification_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Multiway Classification Result Object — multiway_classification_result","title":"Create a Multiway Classification Result Object — multiway_classification_result","text":"function creates multiway classification result object containing observed predicted values, class probabilities, test design, test indices, predictor.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/multiway_classification_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Multiway Classification Result Object — multiway_classification_result","text":"","code":"multiway_classification_result(   observed,   predicted,   probs,   testind = NULL,   test_design = NULL,   predictor = NULL )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/multiway_classification_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Multiway Classification Result Object — multiway_classification_result","text":"observed vector observed values. predicted vector predicted values. probs matrix class probabilities. testind vector indices test data (optional). test_design test design (optional). predictor predictor used multiway classification model (optional).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/multiway_classification_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Multiway Classification Result Object — multiway_classification_result","text":"list class attributes \"multiway_classification_result\", \"classification_result\", \"list\" containing observed predicted values, class probabilities, test design, test indices, predictor.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an MVPA Dataset Object — mvpa_dataset","title":"Create an MVPA Dataset Object — mvpa_dataset","text":"Creates dataset object MVPA analysis encapsulates training dataset, optional test dataset, voxel mask.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an MVPA Dataset Object — mvpa_dataset","text":"","code":"mvpa_dataset(train_data, test_data = NULL, mask)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an MVPA Dataset Object — mvpa_dataset","text":"train_data training data set: NeuroVec instance test_data Optional test data set: NeuroVec instance (default: NULL) mask set voxels include: NeuroVol instance","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an MVPA Dataset Object — mvpa_dataset","text":"mvpa_dataset object (S3 class) containing: train_data training data NeuroVec instance test_data test data NeuroVec instance (provided, otherwise NULL) mask binary mask defining valid voxels NeuroVol instance has_test_set Logical flag indicating whether dataset test set","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an MVPA Dataset Object — mvpa_dataset","text":"","code":"# Create dataset from NeuroVec objects train_vec <- NeuroVec(array(rnorm(1000*100), c(10,10,10,100))) #> Error in NeuroVec(array(rnorm(1000 * 100), c(10, 10, 10, 100))): could not find function \"NeuroVec\" mask_vol <- NeuroVol(array(1, c(10,10,10))) #> Error in NeuroVol(array(1, c(10, 10, 10))): could not find function \"NeuroVol\" dataset <- mvpa_dataset(train_vec, mask=mask_vol) #> Error: object 'train_vec' not found  # Create dataset with test data test_vec <- NeuroVec(array(rnorm(1000*20), c(10,10,10,20))) #> Error in NeuroVec(array(rnorm(1000 * 20), c(10, 10, 10, 20))): could not find function \"NeuroVec\" dataset_with_test <- mvpa_dataset(train_vec, test_vec, mask=mask_vol) #> Error: object 'train_vec' not found"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an MVPA Design Object — mvpa_design","title":"Create an MVPA Design Object — mvpa_design","text":"Creates design object MVPA analysis encapsulates training testing designs, response variables, optional blocking splitting factors.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an MVPA Design Object — mvpa_design","text":"","code":"mvpa_design(   train_design,   test_design = NULL,   y_train,   y_test = NULL,   block_var = NULL,   split_by = NULL,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an MVPA Design Object — mvpa_design","text":"train_design data frame containing training design matrix test_design Optional data frame containing test design matrix (default: NULL) y_train Formula vector specifying training response variable y_test Optional formula vector specifying test response variable (default: NULL) block_var Optional formula vector specifying blocking variable cross-validation split_by Optional formula vector splitting analyses ... Additional arguments (currently unused)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an MVPA Design Object — mvpa_design","text":"mvpa_design object (S3 class) containing: train_design Data frame training design test_design Data frame test design (provided) y_train Training response variable y_test Test response variable (provided) block_var Blocking variable cross-validation (provided) split_by Splitting factor (provided)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an MVPA Design Object — mvpa_design","text":"y_train y_test can specified either formulas (e.g., ~ condition) vectors. formulas used, evaluated within respective design matrices. block_var split_by can also specified formulas vectors. formulas, evaluated within training design matrix.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an MVPA Design Object — mvpa_design","text":"","code":"# Basic design with only training data train_df <- data.frame(condition = rep(c(\"A\", \"B\"), each = 50),                        block = rep(1:5, each = 20),                        group = rep(c(\"Group1\", \"Group2\"), 50)) design <- mvpa_design(train_df, y_train = ~ condition)  # Design with test data and blocking variable test_df <- data.frame(condition = rep(c(\"A\", \"B\"), each = 25)) design_with_test <- mvpa_design(   train_df,    test_df,    y_train = ~ condition,    y_test = ~ condition,   block_var = ~ block )  # Design with split_by factor design_split <- mvpa_design(   train_df,    y_train = ~ condition,   split_by = ~ group )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_iterate.html","id":null,"dir":"Reference","previous_headings":"","what":"Iterate MVPA Analysis Over Multiple ROIs — mvpa_iterate","title":"Iterate MVPA Analysis Over Multiple ROIs — mvpa_iterate","text":"Performs multivariate pattern analysis (MVPA) across multiple regions interest (ROIs) using batch processing parallel computation.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_iterate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iterate MVPA Analysis Over Multiple ROIs — mvpa_iterate","text":"","code":"mvpa_iterate(   mod_spec,   vox_list,   ids = 1:length(vox_list),   batch_size = as.integer(0.1 * length(ids)),   verbose = TRUE,   processor = NULL,   analysis_type = c(\"searchlight\", \"regional\") )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_iterate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iterate MVPA Analysis Over Multiple ROIs — mvpa_iterate","text":"mod_spec MVPA model specification object containing dataset analyze, compute_performance (logical indicating whether compute performance metrics), return_predictions (logical indicating whether return predictions). vox_list list voxel indices coordinates defining ROI analyze. ids Vector identifiers ROI analysis. Defaults 1:length(vox_list). batch_size Integer specifying number ROIs process per batch. Defaults 10% total ROIs. verbose Logical indicating whether print progress messages. Defaults TRUE. processor Optional custom processing function. NULL, uses default processor. Must accept parameters (obj, roi, rnum) return tibble. analysis_type Character indicating type analysis. Defaults \"searchlight\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_iterate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iterate MVPA Analysis Over Multiple ROIs — mvpa_iterate","text":"tibble containing results ROI columns: result List column analysis results (NULL return_predictions=FALSE). indices List column ROI indices used. performance List column performance metrics (computed). id ROI identifier. error Logical indicating error occurred. error_message Error message applicable. warning Logical indicating warning occurred. warning_message Warning message applicable.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_iterate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Iterate MVPA Analysis Over Multiple ROIs — mvpa_iterate","text":"function processes ROIs batches manage memory usage. batch: Extracts ROI data dataset. Filters ROIs fewer 2 voxels. Processes ROI using either default custom processor. Combines results across batches.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an MVPA Model — mvpa_model","title":"Create an MVPA Model — mvpa_model","text":"Create MVPA model based classification regression model MVPAModels registry.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an MVPA Model — mvpa_model","text":"","code":"mvpa_model(   model,   dataset,   design,   model_type = c(\"classification\", \"regression\"),   crossval = NULL,   feature_selector = NULL,   tune_grid = NULL,   tune_reps = 15,   performance = NULL,   class_metrics = TRUE,   compute_performance = TRUE,   return_predictions = TRUE,   return_fits = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an MVPA Model — mvpa_model","text":"model character string naming model MVPAModels registry, custom model specification list. dataset `mvpa_dataset` instance. design `mvpa_design` instance. model_type character string indicating problem type: \"classification\" \"regression\". crossval optional `cross_validation` instance. feature_selector optional `feature_selector` instance. tune_grid optional parameter tuning grid `data.frame`. tune_reps number replications used parameter tuning. relevant `tune_grid` supplied. performance optional custom function computing performance metrics. class_metrics logical flag indicating whether compute performance metrics class. compute_performance logical indicating whether compute store performance measures voxel set (defaults TRUE). return_predictions logical indicating whether return row-wise predictions voxel set (defaults TRUE). return_fits logical indicating whether return model fit voxel set (defaults FALSE).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an MVPA Model — mvpa_model","text":"`performance` supplied, must function takes one argument returns named list scalar values. argument function takes class deriving `classification_result` appropriate problem hand. See example .","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an MVPA Model — mvpa_model","text":"","code":"mod <- load_model(\"sda\") arr_data <- array(rnorm(6*6*6*100), c(6,6,6,100)) sp <- neuroim2::NeuroSpace(c(6,6,6,100)) traindat <- neuroim2::NeuroVec(arr_data, sp) mask <- neuroim2::LogicalNeuroVol(array(rnorm(6*6*6)>-.2, c(6,6,6)), neuroim2::NeuroSpace(c(6,6,6)))  mvdset <- mvpa_dataset(traindat,mask=mask) design <- data.frame(fac=rep(letters[1:4], 25), block=rep(1:10, each=10)) cval <- blocked_cross_validation(design$block) mvdes <- mvpa_design(design, ~ fac, block_var=~block) #> Error in mvpa_design(design, ~fac, block_var = ~block): argument \"y_train\" is missing, with no default  custom_perf <- function(result) {   c(accuracy=sum(result$observed == result$predicted)/length(result$observed)) } mvpmod <- mvpa_model(mod, dataset=mvdset, design=mvdes, crossval=cval, performance=custom_perf) #> Error: object 'mvdes' not found ret <- run_searchlight(mvpmod) #> Error: object 'mvpmod' not found stopifnot(\"accuracy\" %in% names(ret)) #> Error: object 'ret' not found"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_surface_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Surface-Based MVPA Dataset Object — mvpa_surface_dataset","title":"Create a Surface-Based MVPA Dataset Object — mvpa_surface_dataset","text":"Creates dataset object surface-based MVPA analysis encapsulates training dataset, optional test dataset, vertex mask.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_surface_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Surface-Based MVPA Dataset Object — mvpa_surface_dataset","text":"","code":"mvpa_surface_dataset(train_data, test_data = NULL, mask = NULL, name = \"\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_surface_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Surface-Based MVPA Dataset Object — mvpa_surface_dataset","text":"train_data training data set: must inherit NeuroSurfaceVector test_data Optional test data set: must inherit NeuroSurfaceVector (default: NULL) mask Optional binary mask vertices. NULL, creates mask training data indices name Optional label identify dataset (e.g., \"lh\" \"rh\" indicate hemisphere)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_surface_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Surface-Based MVPA Dataset Object — mvpa_surface_dataset","text":"mvpa_surface_dataset object (S3 class) containing: train_data training data NeuroSurfaceVector instance test_data test data NeuroSurfaceVector instance (provided) mask numeric vector indicating valid vertices (1) excluded vertices (0) name Character string identifier dataset has_test_set Logical flag indicating whether dataset test set","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_surface_dataset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Surface-Based MVPA Dataset Object — mvpa_surface_dataset","text":"mask provided, one created automatically using indices training data. mask numeric vector length equal number nodes surface geometry.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_surface_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Surface-Based MVPA Dataset Object — mvpa_surface_dataset","text":"","code":"if (FALSE) { # \\dontrun{ # Create surface dataset with automatic mask train_surf <- NeuroSurfaceVector(geometry, data) dataset <- mvpa_surface_dataset(train_surf, name=\"lh\")  # Create dataset with test data and custom mask test_surf <- NeuroSurfaceVector(geometry, test_data) mask <- numeric(length(nodes(geometry))) mask[roi_indices] <- 1 dataset <- mvpa_surface_dataset(train_surf, test_surf, mask, name=\"rh\") } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_sysinfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Report System and Package Information for rMVPA — mvpa_sysinfo","title":"Report System and Package Information for rMVPA — mvpa_sysinfo","text":"Gathers displays information R session, operating system, rMVPA version, key dependencies. information helpful debugging, reporting issues, ensuring reproducibility.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_sysinfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report System and Package Information for rMVPA — mvpa_sysinfo","text":"","code":"mvpa_sysinfo()"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_sysinfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Report System and Package Information for rMVPA — mvpa_sysinfo","text":"Invisibly returns list containing gathered system package         information. primarily called side effect: printing         formatted information console.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/mvpa_sysinfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report System and Package Information for rMVPA — mvpa_sysinfo","text":"","code":"if (FALSE) { # \\dontrun{ # Display system information in the console mvpa_sysinfo()  # Capture the information in a variable sys_info <- mvpa_sysinfo() print(sys_info$r_version) print(sys_info$dependencies$rsample) } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/new-analysis-overview.html","id":null,"dir":"Reference","previous_headings":"","what":"Extending the MVPA Framework: Creating a New Analysis Type — new-analysis-overview","title":"Extending the MVPA Framework: Creating a New Analysis Type — new-analysis-overview","text":"documentation describes implement **new MVPA analysis type** within package. MVPA framework designed extensible via S3 generics. providing necessary methods classes, can integrate custom analyses (beyond standard classification, regression, RSA).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/new-analysis-overview.html","id":"overview","dir":"Reference","previous_headings":"","what":"Overview","title":"Extending the MVPA Framework: Creating a New Analysis Type — new-analysis-overview","text":"1. **Define Model Specification**    - Create S3 class inheriting model_spec, e.g. \"myanalysis_model\".    - class hold **parameters** **configuration** needed analysis      (e.g., hyperparameters, references, design objects).    - Construct using function like create_model_spec(\"myanalysis_model\", ...). 2. **Implement Required Generics**    - train_model.myanalysis_model(obj, train_dat, ...):      Defines \"train\" execute analysis subset data      (e.g., ROI voxel intensities).      - might involve fitting specialized model, computing metric,        unsupervised transform.      - Return structured object (often named list model fit) can        handled framework.    - process_roi.myanalysis_model(mod_spec, roi, rnum, ...) (Optional):      need custom per-ROI logic beyond default pipeline, implement      process_roi method class. method called automatically      run_regional(...) region.      - default, framework calls train_model ROI's data,        want skip alter flow, provide custom process_roi method.    - (Optional) predict_model.myanalysis_model(...) evaluate_model.myanalysis_model(...):      analysis involves separate test step specialized evaluation, can      define S3 methods.    - (Optional) run_future.myanalysis_model(...), merge_results.myanalysis_model(...), etc.:      need custom behavior parallelization merging partial results, override      generics well. 3. **Use `run_regional()` `run_searchlight()`**    - new model class defined, can pass object class      run_regional(...) run_searchlight(...) just like built-analysis.    - framework automatically dispatches calls train_model.myanalysis_model      (optionally process_roi.myanalysis_model), returning result object      consistent MVPA analyses.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/new-analysis-overview.html","id":"why-these-pieces-are-needed","dir":"Reference","previous_headings":"","what":"Why These Pieces Are Needed","title":"Extending the MVPA Framework: Creating a New Analysis Type — new-analysis-overview","text":"- **Model Specification**: Provides blueprint pipeline handle analysis   (data need, store intermediate results, etc.). - **Train Model Generic**: Tells pipeline chunk data   (ROI subset, searchlight voxel set, cross-validation fold).   core analysis. - **process_roi**: analysis requires complex per-region logic default   pipeline (e.g., skipping certain steps, altering data structure), implementing   process_roi.myanalysis_model gives full control.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/new-analysis-overview.html","id":"example-code-skeleton","dir":"Reference","previous_headings":"","what":"Example Code Skeleton","title":"Extending the MVPA Framework: Creating a New Analysis Type — new-analysis-overview","text":"","code":"# Minimal template for a new analysis model  myanalysis_model <- function(dataset, design, param1=NULL, param2=5, ...) {   # Create an object of class \"myanalysis_model\"   create_model_spec(     \"myanalysis_model\",     dataset  = dataset,     design   = design,     param1   = param1,     param2   = param2,     ...   ) }  # S3 method to \"train\" your analysis train_model.myanalysis_model <- function(obj, train_dat, y, indices, ...) {   # train_dat = subset of voxel intensities or features   # y = optional labels/response if relevant   # indices = location info    # 1) Do your computations (model fitting, metrics, transforms, etc.)   fit_object <- your_method(train_dat, some_params=obj$param1)    # 2) Return a structure. The pipeline may store or evaluate it further.   list(     fit = fit_object,     # any other stuff you want to keep   ) }  # Optional custom ROI processor process_roi.myanalysis_model <- function(mod_spec, roi, rnum, ...) {   # If you want to skip or augment the default cross-validation / train_model approach   # in run_regional, define your logic here.   # Otherwise, the default calls train_model(...) on the region's data. }  # You can now call: # new_model <- myanalysis_model(dataset, design, param1=\"xyz\") # results_regional <- run_regional(new_model, region_mask) # results_searchlight <- run_searchlight(new_model, radius=8, method=\"standard\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Number of Observations — nobs","title":"Get Number of Observations — nobs","text":"Retrieve number observations object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Number of Observations — nobs","text":"","code":"nobs(x)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Number of Observations — nobs","text":"x input object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Number of Observations — nobs","text":"number observations.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nresponses.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Response Categories — nresponses","title":"Number of Response Categories — nresponses","text":"Get number response categories levels.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nresponses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Response Categories — nresponses","text":"","code":"nresponses(x)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nresponses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of Response Categories — nresponses","text":"x object extract number categories.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/nresponses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of Response Categories — nresponses","text":"number response categories.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/orthogonalize_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Orthogonalize a Contrast Matrix — orthogonalize_contrasts","title":"Orthogonalize a Contrast Matrix — orthogonalize_contrasts","text":"Orthogonalizes columns contrast matrix using QR decomposition. resulting matrix orthonormal columns spanning space original columns, rank input matrix. Sign output columns heuristically aligned input columns.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/orthogonalize_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orthogonalize a Contrast Matrix — orthogonalize_contrasts","text":"","code":"orthogonalize_contrasts(C)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/orthogonalize_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orthogonalize a Contrast Matrix — orthogonalize_contrasts","text":"C numeric matrix (K x Q) columns represent contrast vectors.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/orthogonalize_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orthogonalize a Contrast Matrix — orthogonalize_contrasts","text":"orthogonalized matrix. input matrix C rank-deficient   (rank < Q), output matrix Q columns, first   rank(C) columns non-zero form orthonormal basis;   subsequent columns zero vectors. Column names C preserved.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/orthogonalize_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Orthogonalize a Contrast Matrix — orthogonalize_contrasts","text":"","code":"K <- 6 # Number of conditions Q <- 2 # Number of contrasts C_orig <- matrix(c( 1,  1,  1, -1, -1, -1,  # Contrast 1                     1, -1,  0,  1, -1,  0), # Contrast 2 (not orthogonal to C1)                  nrow=K, ncol=Q) colnames(C_orig) <- c(\"MainEffect\", \"InteractionLike\") C_ortho <- orthogonalize_contrasts(C_orig) # print(round(crossprod(C_ortho), 10)) # Should be close to identity matrix  # Example with a rank-deficient matrix (3rd contrast is sum of first two) C_rank_def <- cbind(C_orig, C_orig[,1] + C_orig[,2]) colnames(C_rank_def) <- c(\"C1\", \"C2\", \"C3_dependent\") C_ortho_def <- orthogonalize_contrasts(C_rank_def) #> Warning: Input matrix C is rank-deficient (rank 2 < 3 columns). The output matrix has 3 columns, but only the first 2 are non-zero and form an orthonormal basis. Subsequent columns are zero vectors. # print(round(crossprod(C_ortho_def), 10)) # The 3rd column of C_ortho_def will be zeros."},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Performance Metrics — performance","title":"Compute Performance Metrics — performance","text":"Generic function compute performance metrics result objects.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Performance Metrics — performance","text":"","code":"performance(x, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Performance Metrics — performance","text":"x Result object classification regression analysis. ... Additional arguments passed methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Performance Metrics — performance","text":"Named numeric vector performance metrics.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Performance Metrics — performance","text":"","code":"cres <- binary_classification_result(   observed  = factor(c(\"a\", \"b\")),   predicted = factor(c(\"a\", \"b\")),   probs     = matrix(c(0.8, 0.2, 0.3, 0.7), ncol = 2,                      dimnames = list(NULL, c(\"a\", \"b\"))) ) performance(cres)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance.regression_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Performance Metrics for Regression Result — performance.regression_result","title":"Calculate Performance Metrics for Regression Result — performance.regression_result","text":"function calculates performance metrics regression result object, including R-squared, Root Mean Squared Error (RMSE), Spearman correlation.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance.regression_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Performance Metrics for Regression Result — performance.regression_result","text":"","code":"# S3 method for class 'regression_result' performance(x, split_list = NULL, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance.regression_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Performance Metrics for Regression Result — performance.regression_result","text":"x regression_result object. split_list Split results indexed sub-groups (supported regression analyses yet). ... extra args (used).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance.regression_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Performance Metrics for Regression Result — performance.regression_result","text":"named vector calculated performance metrics: R-squared, RMSE, Spearman correlation.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/performance.regression_result.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Performance Metrics for Regression Result — performance.regression_result","text":"function calculates following performance metrics given regression result object: - R-squared: proportion variance observed data predictable fitted model. - RMSE: root mean squared error, measure differences predicted observed values. - Spearman correlation: measure monotonic relationship predicted observed values.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/pool_randomized.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine randomized searchlight results by pooling — pool_randomized","title":"Combine randomized searchlight results by pooling — pool_randomized","text":"function combines randomized searchlight results pooling good results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/pool_randomized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine randomized searchlight results by pooling — pool_randomized","text":"","code":"pool_randomized(model_spec, good_results, bad_results)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/pool_randomized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine randomized searchlight results by pooling — pool_randomized","text":"model_spec object specifying model used searchlight analysis. good_results data frame containing valid searchlight results. bad_results data frame containing invalid searchlight results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/pool_randomized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine randomized searchlight results by pooling — pool_randomized","text":"object containing combined searchlight results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predict_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Model Output — predict_model","title":"Predict Model Output — predict_model","text":"Generic function predict outcomes fitted model object using new data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predict_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Model Output — predict_model","text":"","code":"predict_model(object, fit, newdata, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predict_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Model Output — predict_model","text":"object fitted model object prediction method defined. fit fitted model object, often returned `train_model`. (Note: models, `object` might fit). newdata New data (e.g., matrix data frame) make predictions. structure compatible model trained . ... Additional arguments passed specific prediction methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predict_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict Model Output — predict_model","text":"Predictions whose structure depends specific method (e.g., vector,   matrix, data frame).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predicted_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Predicted Class from Probability Matrix — predicted_class","title":"Calculate the Predicted Class from Probability Matrix — predicted_class","text":"function calculates predicted class matrix predicted probabilities. class highest probability selected predicted class.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predicted_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Predicted Class from Probability Matrix — predicted_class","text":"","code":"predicted_class(prob)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predicted_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Predicted Class from Probability Matrix — predicted_class","text":"prob matrix predicted probabilities column names indicating classes.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predicted_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Predicted Class from Probability Matrix — predicted_class","text":"vector predicted classes corresponding highest probability row input matrix.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/predicted_class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Predicted Class from Probability Matrix — predicted_class","text":"","code":"prob <- matrix(c(0.2, 0.8,                  0.6, 0.4),                nrow = 2, byrow = TRUE,                dimnames = list(NULL, c(\"A\", \"B\"))) predicted_class(prob)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prep_regional.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare regional data for MVPA analysis — prep_regional","title":"Prepare regional data for MVPA analysis — prep_regional","text":"function processes input data prepares regions MVPA analysis extracting voxel indices region interest (ROI) specified region_mask.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prep_regional.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare regional data for MVPA analysis — prep_regional","text":"","code":"prep_regional(model_spec, region_mask)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prep_regional.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare regional data for MVPA analysis — prep_regional","text":"model_spec model specification object. region_mask mask representing different regions brain image.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prep_regional.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare regional data for MVPA analysis — prep_regional","text":"list containing information regions processing:   * allrois: vector unique ROI labels.   * region_vec: vector representation region_mask.   * region_set: sorted vector unique ROI labels region_mask.   * vox_iter: list containing voxel indices ROI.   * lens: vector containing number voxels ROI.   * keep: logical vector indicating ROI kept analysis (one voxel).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prep_regional.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare regional data for MVPA analysis — prep_regional","text":"","code":"# Create example inputs model_spec <- list(dataset = \"Example dataset\") region_mask <- matrix(c(rep(0, 5), rep(1, 5), rep(2, 5), rep(3, 5)), nrow = 5)  # Prepare regional data regional_data <- prep_regional(model_spec, region_mask) #> Error in UseMethod(\"get_unique_regions\"): no applicable method for 'get_unique_regions' applied to an object of class \"c('matrix', 'array', 'double', 'numeric')\""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.feature_rsa_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for Feature RSA Design — print.feature_rsa_design","title":"Print Method for Feature RSA Design — print.feature_rsa_design","text":"Print Method Feature RSA Design","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.feature_rsa_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for Feature RSA Design — print.feature_rsa_design","text":"","code":"# S3 method for class 'feature_rsa_design' print(x, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.feature_rsa_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for Feature RSA Design — print.feature_rsa_design","text":"x feature_rsa_design object. ... Additional arguments (ignored).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.feature_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for Feature RSA Model — print.feature_rsa_model","title":"Print Method for Feature RSA Model — print.feature_rsa_model","text":"Print Method Feature RSA Model","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.feature_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for Feature RSA Model — print.feature_rsa_model","text":"","code":"# S3 method for class 'feature_rsa_model' print(x, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.feature_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for Feature RSA Model — print.feature_rsa_model","text":"x feature_rsa_model object. ... Additional arguments (ignored).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.mvpa_sysinfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Print mvpa_sysinfo Object — print.mvpa_sysinfo","title":"Print mvpa_sysinfo Object — print.mvpa_sysinfo","text":"Formats prints system information gathered mvpa_sysinfo. method provides user-friendly display system configuration.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.mvpa_sysinfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print mvpa_sysinfo Object — print.mvpa_sysinfo","text":"","code":"# S3 method for class 'mvpa_sysinfo' print(x, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.mvpa_sysinfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print mvpa_sysinfo Object — print.mvpa_sysinfo","text":"x object class `mvpa_sysinfo`. ... Ignored.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.vector_rsa_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for vector_rsa_design — print.vector_rsa_design","title":"Print Method for vector_rsa_design — print.vector_rsa_design","text":"Print Method vector_rsa_design","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.vector_rsa_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for vector_rsa_design — print.vector_rsa_design","text":"","code":"# S3 method for class 'vector_rsa_design' print(x, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.vector_rsa_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for vector_rsa_design — print.vector_rsa_design","text":"x vector_rsa_design object. ... Additional arguments (ignored).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.vector_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for vector_rsa_model — print.vector_rsa_model","title":"Print Method for vector_rsa_model — print.vector_rsa_model","text":"Print Method vector_rsa_model","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.vector_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for vector_rsa_model — print.vector_rsa_model","text":"","code":"# S3 method for class 'vector_rsa_model' print(x, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/print.vector_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for vector_rsa_model — print.vector_rsa_model","text":"x object class vector_rsa_model. ... Additional arguments (ignored).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prob_observed.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability of Observed Class — prob_observed","title":"Probability of Observed Class — prob_observed","text":"Extract predicted probability observed class.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prob_observed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability of Observed Class — prob_observed","text":"","code":"prob_observed(x)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prob_observed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability of Observed Class — prob_observed","text":"x object extract probability.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/prob_observed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability of Observed Class — prob_observed","text":"vector predicted probabilities.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/process_roi-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Process ROI — process_roi","title":"Process ROI — process_roi","text":"Process region interest (ROI) return formatted results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/process_roi-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process ROI — process_roi","text":"","code":"process_roi(mod_spec, roi, rnum, ...)  # Default S3 method process_roi(mod_spec, roi, rnum, center_global_id = NA, ...)  # S3 method for class 'custom_internal_model_spec' process_roi(mod_spec, roi, rnum, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/process_roi-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process ROI — process_roi","text":"mod_spec model specification object. roi region interest data. rnum numeric string identifier ROI. ... Additional arguments passed method-specific function. center_global_id Optional global ID center voxel. Defaults NA.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/process_roi-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process ROI — process_roi","text":"tibble row containing performance metrics ROI.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/process_roi-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process ROI — process_roi","text":"","code":"# \\donttest{   ds <- gen_sample_dataset(c(4, 4, 4), 20, blocks = 2)   cv <- blocked_cross_validation(ds$design$block_var)   mdl <- load_model(\"sda_notune\")   spec <- mvpa_model(     model = mdl,     dataset = ds$dataset,     design = ds$design,     model_type = \"classification\",     crossval = cv   )   vox <- sample(which(ds$dataset$mask > 0), 30)   samp <- data_sample(ds$dataset, vox)   roi_obj <- as_roi(samp, ds$dataset) #> Error in as_roi(samp, ds$dataset): could not find function \"as_roi\"   process_roi(spec, roi_obj, 1) #> Error in process_roi(spec, roi_obj, 1): could not find function \"process_roi\" # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rMVPA-package.html","id":null,"dir":"Reference","previous_headings":"","what":"rMVPA: Multivoxel Pattern Analysis in R — rMVPA-package","title":"rMVPA: Multivoxel Pattern Analysis in R — rMVPA-package","text":"R package facilitate multivoxel pattern analysis neuroimaging data R.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rMVPA-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"rMVPA: Multivoxel Pattern Analysis in R — rMVPA-package","text":"Maintainer: Bradley Buchsbaum brad.buchsbaum@gmail.com","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rMVPA.html","id":null,"dir":"Reference","previous_headings":"","what":"rMVPA: A package for multi-voxel pattern analysis (MVPA) — rMVPA","title":"rMVPA: A package for multi-voxel pattern analysis (MVPA) — rMVPA","text":"rMVPA package provides comprehensive suite tools advanced neuroimaging data analysis using multi-voxel pattern analysis (MVPA). supports various techniques including region--interest (ROI) searchlight analyses. Key functionalities cover: Classification-based MVPA Representational Similarity Analysis (RSA), including standard RSA,         vector-based RSA, feature-based RSA. Contrast RSA (MS-ReVE style analyses) Flexible cross-validation schemes Feature selection methods Tools constructing managing MVPA datasets designs.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rMVPA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"rMVPA: A package for multi-voxel pattern analysis (MVPA) — rMVPA","text":"Maintainer: Bradley Buchsbaum brad.buchsbaum@gmail.com","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regional_mvpa_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a regional_mvpa_result instance — regional_mvpa_result","title":"Create a regional_mvpa_result instance — regional_mvpa_result","text":"Constructs regional MVPA result object stores results MVPA analysis specific region.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regional_mvpa_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a regional_mvpa_result instance — regional_mvpa_result","text":"","code":"regional_mvpa_result(   model_spec,   performance_table,   prediction_table,   vol_results,   fits = fits )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regional_mvpa_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a regional_mvpa_result instance — regional_mvpa_result","text":"model_spec model specification object. performance_table data frame performance measures. prediction_table data frame prediction results. vol_results list voxel-level results. fits Optional model fits.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regional_mvpa_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a regional_mvpa_result instance — regional_mvpa_result","text":"regional_mvpa_result object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regional_mvpa_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a regional_mvpa_result instance — regional_mvpa_result","text":"","code":"# Create example inputs model_spec <- list(dataset = \"Example dataset\") performance_table <- data.frame(accuracy = c(0.8, 0.85)) prediction_table <- data.frame(observed = factor(rep(letters[1:2], 5)),                                 predicted = factor(rep(letters[1:2], 5))) vol_results <- list(vol1 = \"Example vol_result 1\", vol2 = \"Example vol_result 2\") fits <- list(fit1 = \"Example fit 1\", fit2 = \"Example fit 2\")  # Construct a regional_mvpa_result regional_result <- regional_mvpa_result(model_spec, performance_table,                                         prediction_table, vol_results, fits = fits)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/register_mvpa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a Custom MVPA Model — register_mvpa_model","title":"Register a Custom MVPA Model — register_mvpa_model","text":"Adds user-defined model specification rMVPA model registry (MVPAModels).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/register_mvpa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a Custom MVPA Model — register_mvpa_model","text":"","code":"register_mvpa_model(name, model_spec)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/register_mvpa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a Custom MVPA Model — register_mvpa_model","text":"name character string, unique name model. model_spec list containing model specification. must include elements: `type` (\"Classification\" \"Regression\"), `library` (character vector required packages *model *, rMVPA's wrappers), `label` (character, usually name), `parameters` (data.frame tunable parameters: parameter, class, label), `grid` (function generate tuning grid, takes x, y, len args), `fit` (function), `predict` (function), `prob` (function classification, takes modelFit, newdata; return matrix/df colnames levels).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/register_mvpa_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Register a Custom MVPA Model — register_mvpa_model","text":"","code":"if (FALSE) { # \\dontrun{ # Example of how a user might define an e1071 SVM spec my_svm_spec <- list(   type = \"Classification\", library = \"e1071\", label = \"my_svm\",   parameters = data.frame(parameter = \"cost\", class = \"numeric\", label = \"Cost (C)\"),   # grid should return a data.frame with columns matching 'parameter' names in 'parameters'   grid = function(x, y, len = NULL) {       data.frame(cost = if (is.null(len) || len == 1) 1 else 10^seq(-2, 2, length.out = len))   },   # fit function receives: x, y, wts (weights), param (current params from grid),    # lev (levels of y), last (unused), weights (unused), classProbs (unused by e1071::svm)   fit = function(x, y, wts, param, lev, last, weights, classProbs, ...) {      e1071::svm(x, y, cost = param$cost, probability = TRUE, ...) # Ensure probability=TRUE for prob   },   # predict function receives: modelFit (output of $fit), newdata   predict = function(modelFit, newdata, ...) {      predict(modelFit, newdata, ...)   },   # prob function receives: modelFit, newdata   # Should return a matrix/df with columns named as in levels(y)   prob = function(modelFit, newdata, ...) {     pred_obj <- predict(modelFit, newdata, probability = TRUE)     attr(pred_obj, \"probabilities\")    } ) register_mvpa_model(\"my_svm\", my_svm_spec) # Now load_model(\"my_svm\") would work. } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regression_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Regression Result Object — regression_result","title":"Create a Regression Result Object — regression_result","text":"function creates regression result object containing observed predicted values, test design, test indices, predictor.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regression_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Regression Result Object — regression_result","text":"","code":"regression_result(   observed,   predicted,   testind = NULL,   test_design = NULL,   predictor = NULL )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regression_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Regression Result Object — regression_result","text":"observed vector observed values. predicted vector predicted values. testind vector indices test data (optional). test_design test design (optional). predictor predictor used regression model (optional).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/regression_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Regression Result Object — regression_result","text":"list class attributes \"regression_result\", \"classification_result\", \"list\" containing observed predicted values, test design, test indices, predictor.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a design for an RSA (Representational Similarity Analysis) model — rsa_design","title":"Construct a design for an RSA (Representational Similarity Analysis) model — rsa_design","text":"function constructs design RSA model using provided formula, data, optional parameters.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a design for an RSA (Representational Similarity Analysis) model — rsa_design","text":"","code":"rsa_design(   formula,   data,   block_var = NULL,   split_by = NULL,   keep_intra_run = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a design for an RSA (Representational Similarity Analysis) model — rsa_design","text":"formula formula expression specifying dissimilarity-based regression function. data named list containing dissimilarity matrices auxiliary variables. block_var optional formula, character name integer vector designating block structure. split_by optional formula indicating grouping structure evaluating test performance. keep_intra_run logical indicating whether include within-run comparisons (default: FALSE).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a design for an RSA (Representational Similarity Analysis) model — rsa_design","text":"list class attributes \"rsa_design\" \"list\", containing: formula input formula data input data split_by split_by formula split_groups Grouping structure split_by block_var Block structure include Logical vector including/excluding comparisons model_mat Model matrix generated rsa_model_mat","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Construct a design for an RSA (Representational Similarity Analysis) model — rsa_design","text":"function creates RSA design based input parameters. checks validity input data handles splitting conditions evaluation test performance. also processes optional block structures within-run comparisons.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a design for an RSA (Representational Similarity Analysis) model — rsa_design","text":"","code":"dismat <- dist(matrix(rnorm(100*100), 100, 100)) rdes <- rsa_design(~ dismat, list(dismat=dismat))"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct an RSA (Representational Similarity Analysis) model — rsa_model","title":"Construct an RSA (Representational Similarity Analysis) model — rsa_model","text":"function creates RSA model object taking MVPA (Multi-Variate Pattern Analysis) dataset RSA design.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct an RSA (Representational Similarity Analysis) model — rsa_model","text":"","code":"rsa_model(   dataset,   design,   distmethod = \"spearman\",   regtype = \"pearson\",   check_collinearity = TRUE,   nneg = NULL,   semipartial = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct an RSA (Representational Similarity Analysis) model — rsa_model","text":"dataset instance mvpa_dataset. design instance rsa_design created rsa_design(). distmethod character string specifying method used compute distances observations. One : \"pearson\" \"spearman\" (defaults \"spearman\"). regtype character string specifying analysis method. One : \"pearson\", \"spearman\", \"lm\", \"rfit\" (defaults \"pearson\"). check_collinearity Logical indicating whether check collinearity design matrix. applies regtype=\"lm\". Default TRUE. nneg named list variables (predictors) non-negative regression coefficients enforced (regtype=\"lm\"). Defaults NULL (constraints). semipartial Logical indicating whether compute semi-partial correlations \"lm\" case (nneg used). Defaults FALSE.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct an RSA (Representational Similarity Analysis) model — rsa_model","text":"object class \"rsa_model\" (\"list\"), containing: dataset    : input dataset design     : RSA design distmethod : distance method used regtype    : regression type nneg       : named list constrained variables, semipartial: whether compute semi-partial correlations","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/rsa_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct an RSA (Representational Similarity Analysis) model — rsa_model","text":"","code":"# Create a random MVPA dataset data <- matrix(rnorm(100 * 100), 100, 100) labels <- factor(rep(1:2, each = 50)) mvpa_data <- mvpa_dataset(data, labels) #> Error: train_data does not inherit from class NeuroVec  # Create an RSA design with two distance matrices dismat1 <- dist(data) dismat2 <- dist(matrix(rnorm(100*100), 100, 100)) rdes <- rsa_design(~ dismat1 + dismat2, list(dismat1=dismat1, dismat2=dismat2))  # Create an RSA model with standard 'lm' (returns t-values): rsa_mod <- rsa_model(mvpa_data, rdes, regtype=\"lm\") #> Error: object 'mvpa_data' not found  # Create an RSA model enforcing non-negativity for dismat2 only: # Requires the 'glmnet' package to be installed # rsa_mod_nneg <- rsa_model(mvpa_data, rdes, regtype=\"lm\", #                          nneg = list(dismat2 = TRUE))  # Create an RSA model using 'lm' but returning semi-partial correlations: rsa_mod_sp <- rsa_model(mvpa_data, rdes, regtype=\"lm\",                         semipartial = TRUE) #> Error: object 'mvpa_data' not found  # Train the model fit_params <- train_model(rsa_mod_sp, mvpa_data$train_data) #> Error: object 'rsa_mod_sp' not found # 'fit_params' = named vector of semi-partial correlations for each predictor"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_regional.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a Custom Analysis Function Regionally — run_custom_regional","title":"Run a Custom Analysis Function Regionally — run_custom_regional","text":"Applies user-defined function data within specified region interest (ROI) returns results tibble.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_regional.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a Custom Analysis Function Regionally — run_custom_regional","text":"","code":"run_custom_regional(   dataset,   region_mask,   custom_func,   ...,   .cores = 1,   .verbose = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_regional.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a Custom Analysis Function Regionally — run_custom_regional","text":"dataset `mvpa_dataset` `mvpa_surface_dataset` object. region_mask `NeuroVol` `NeuroSurface` object region identified unique integer greater 0. custom_func function apply ROI's data. accept two arguments: `roi_data`: matrix tibble containing data           (samples x features) current ROI. `roi_info`: list containing `id` (region number)           `indices` (feature indices ROI). function *must* return named list single-row data frame (tibble) containing scalar metric values. ... Optional arguments passed `mvpa_iterate` (e.g., `batch_size`). .cores Number cores use parallel processing via `future` framework. Defaults 1 (sequential). Set using `future::plan()` beforehand control. .verbose Logical. `TRUE`, prints progress messages iteration. Defaults `FALSE`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_regional.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a Custom Analysis Function Regionally — run_custom_regional","text":"`tibble` row corresponds ROI. includes: `id`: ROI identifier (region number). Columns corresponding names returned `custom_func`. `error`: Logical indicating error occurred ROI. `error_message`: error message error occurred.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_regional.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run a Custom Analysis Function Regionally — run_custom_regional","text":"function provides simplified interface applying custom analyses per ROI without needing define full `mvpa_model` specification implement S3 methods. leverages parallel processing iteration capabilities `rMVPA`. user-supplied `custom_func` performs core calculation ROI. framework handles extracting data, iterating ROIs (potentially parallel), catching errors `custom_func`, formatting output convenient flat table.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_regional.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a Custom Analysis Function Regionally — run_custom_regional","text":"","code":"# Generate sample dataset dset_info <- gen_sample_dataset(D = c(8,8,8), nobs = 50, nlevels = 2) dataset_obj <- dset_info$dataset design_obj <- dset_info$design # Not used by custom_func here, but needed for setup  # Create a region mask with 3 ROIs mask_arr <- array(0, dim(dataset_obj$mask)) mask_arr[1:4, 1:4, 1:4] <- 1 mask_arr[5:8, 1:4, 1:4] <- 2 mask_arr[1:4, 5:8, 5:8] <- 3 region_mask_vol <- NeuroVol(mask_arr, space(dataset_obj$mask)) #> Error in NeuroVol(mask_arr, space(dataset_obj$mask)): could not find function \"NeuroVol\"  # Define a custom function: calculate mean and sd for each ROI my_roi_stats <- function(roi_data, roi_info) {   # roi_data is samples x features matrix   # roi_info$id is the region number   # roi_info$indices are the feature indices   mean_signal <- mean(roi_data, na.rm = TRUE)   sd_signal <- sd(roi_data, na.rm = TRUE)   num_features <- ncol(roi_data)   list(     roi_id = roi_info$id, # Can include id if desired, or rely on output table     mean_signal = mean_signal,     sd_signal = sd_signal,     n_features = num_features   ) }  # Run the custom regional analysis # \\donttest{ # Set up parallel processing (optional)  custom_results <- run_custom_regional(dataset_obj, region_mask_vol, my_roi_stats,                                       .cores = 2, .verbose = TRUE) #> Error: object 'region_mask_vol' not found print(custom_results) #> Error: object 'custom_results' not found  # Example with an error in one ROI my_error_func <- function(roi_data, roi_info) {   if (roi_info$id == 2) {     stop(\"Something went wrong in ROI 2!\")   }   list(mean_signal = mean(roi_data)) }  error_results <- run_custom_regional(dataset_obj, region_mask_vol, my_error_func) #> Error: object 'region_mask_vol' not found print(error_results) #> Error: object 'error_results' not found  # Clean up parallel plan future::plan(future::sequential) # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_searchlight.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a Custom Analysis Function in a Searchlight — run_custom_searchlight","title":"Run a Custom Analysis Function in a Searchlight — run_custom_searchlight","text":"Applies user-defined function data within searchlight sphere returns results, typically `NeuroVol` `NeuroSurface` objects within `searchlight_result` structure.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_searchlight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a Custom Analysis Function in a Searchlight — run_custom_searchlight","text":"","code":"run_custom_searchlight(   dataset,   custom_func,   radius,   method = c(\"standard\", \"randomized\"),   niter = 100,   ...,   .cores = 1,   .verbose = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_searchlight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a Custom Analysis Function in a Searchlight — run_custom_searchlight","text":"dataset `mvpa_dataset` `mvpa_surface_dataset` object. custom_func function apply within searchlight sphere. accept two arguments: `sl_data`: matrix tibble containing data           (samples x features_in_sphere) current sphere. `sl_info`: list containing information sphere,           including `center_index` (index center voxel/vertex),           `indices` (indices features within sphere),           potentially `coords` (coordinates center). function *must* return named list single-row data frame (tibble) containing scalar metric values. spheres must return named metrics. radius radius searchlight sphere (mm volumes, vertex connections surfaces - see `neuroim2::spherical_roi`). method type searchlight: \"standard\" (systematically covers center voxels) \"randomized\" (samples spheres randomly, useful large datasets). Defaults \"standard\". niter number iterations \"randomized\" searchlight. Ignored `method = \"standard\"`. Defaults 100. ... Optional arguments passed `mvpa_iterate` (e.g., `batch_size`). .cores Number cores use parallel processing via `future` framework. Defaults 1 (sequential). Set using `future::plan()` beforehand control. .verbose Logical. `TRUE`, prints progress messages iteration. Defaults `FALSE`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_searchlight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a Custom Analysis Function in a Searchlight — run_custom_searchlight","text":"`searchlight_result` object (see `rMVPA::wrap_out`). list   containing: `results`: named list element corresponds metric           returned `custom_func`. element           `searchlight_performance` object containing `NeuroVol`           `NeuroSurface` (`$data`) metric values mapped back           brain space, along summary statistics (`$summary_stats`). `metrics`: character vector metric names. `n_voxels`, `active_voxels`: Information dataset mask. `method = \"randomized\"`, values output maps represent   average metric value voxel across spheres participated .","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_searchlight.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run a Custom Analysis Function in a Searchlight — run_custom_searchlight","text":"function provides flexible way perform custom analyses across brain using searchlight approach, without defining full `mvpa_model`. handles iterating searchlight spheres, extracting data, running custom function (potentially parallel), handling errors, combining results back brain-space maps. `custom_func` performs core calculation sphere. framework manages iteration, data handling, parallelization, error catching, result aggregation. `method = \"standard\"`, function iterates every active voxel/vertex dataset mask potential sphere center. `method = \"randomized\"`, randomly selects sphere centers `niter` iterations. final map represents average results spheres covering voxel. requires custom function's results meaningfully averageable. **Important**: `custom_func` must consistently return set named scalar metrics every sphere successfully processes.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_custom_searchlight.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a Custom Analysis Function in a Searchlight — run_custom_searchlight","text":"","code":"# Generate sample dataset dset_info <- gen_sample_dataset(D = c(10, 10, 10), nobs = 30, nlevels = 2) dataset_obj <- dset_info$dataset  # Define a custom function: calculate mean and sd within the sphere my_sl_stats <- function(sl_data, sl_info) {   # sl_data is samples x features_in_sphere matrix   # sl_info contains center_index, indices, etc.   mean_signal <- mean(sl_data, na.rm = TRUE)   sd_signal <- sd(sl_data, na.rm = TRUE)   n_features <- ncol(sl_data)   list(     mean_signal = mean_signal,     sd_signal = sd_signal,     n_vox_in_sphere = n_features   ) }  # Run the custom searchlight (standard method) # \\donttest{  custom_sl_results <- run_custom_searchlight(dataset_obj, my_sl_stats,                                             radius = 7, method = \"standard\",                                             .cores = 2, .verbose = TRUE) #> Error in run_custom_searchlight(dataset_obj, my_sl_stats, radius = 7,     method = \"standard\", .cores = 2, .verbose = TRUE): Specified radius (7) is too large for dataset dimensions (10x10x10). Maximum supported radius is 5. print(custom_sl_results) #> Error: object 'custom_sl_results' not found  # Access the NeuroVol for a specific metric mean_signal_map <- custom_sl_results$results$mean_signal$data #> Error: object 'custom_sl_results' not found # plot(mean_signal_map) # Requires neuroim2 plotting capabilities  # Example with an error in some spheres (e.g., if too few voxels) my_error_sl_func <- function(sl_data, sl_info) {   if (ncol(sl_data) < 5) {     stop(\"Too few voxels in this sphere!\")   }   list(mean_signal = mean(sl_data)) }  error_sl_results <- run_custom_searchlight(dataset_obj, my_error_sl_func,                                            radius = 4, method = \"standard\") #> INFO [2025-09-27 21:49:04] Starting custom searchlight analysis (method: standard, radius: 4 mm)... #> INFO [2025-09-27 21:49:04] Preparing 512 standard searchlight spheres... #> INFO [2025-09-27 21:49:22]  #> ✨ MVPA Iteration Complete #> ├─ Total ROIs: 512 #> ├─ Processed: 512 #> └─ Skipped: 0 #> INFO [2025-09-27 21:49:22] Combining results from standard searchlight... #> INFO [2025-09-27 21:49:22] Finished custom searchlight analysis. print(error_sl_results) # Errors will be caught, corresponding voxels may be NA #>  #>  █▀▀ Searchlight Analysis Results ▀▀█  #>  #> ├─ Coverage  #> │  ├─ Voxels/Vertices in Mask:  1,000  #> │  └─ Voxels/Vertices with Results:  512  #> └─ Output Maps (Metrics)  #>    ├─  mean_signal  (Type:  searchlight_performance )  #>   # Run randomized searchlight (faster for large datasets/radii) custom_sl_rand_results <- run_custom_searchlight(dataset_obj, my_sl_stats,                                                  radius = 7, method = \"randomized\",                                                  niter = 50, # Fewer iterations for example                                                  .cores = 2, .verbose = TRUE) #> Error in run_custom_searchlight(dataset_obj, my_sl_stats, radius = 7,     method = \"randomized\", niter = 50, .cores = 2, .verbose = TRUE): Specified radius (7) is too large for dataset dimensions (10x10x10). Maximum supported radius is 5. print(custom_sl_rand_results) #> Error: object 'custom_sl_rand_results' not found  # Clean up parallel plan future::plan(future::sequential) # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_future-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Future — run_future","title":"Run Future — run_future","text":"Run future-based computation defined object frame.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_future-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Future — run_future","text":"","code":"run_future(obj, frame, processor, ...)  # Default S3 method run_future(obj, frame, processor = NULL, verbose = FALSE, analysis_type, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_future-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Future — run_future","text":"obj object specifying computation. frame data frame environment containing data computation. processor function object specifying process frame. ... Additional arguments passed method-specific function. verbose Logical; print progress messages TRUE. analysis_type type analysis (e.g., \"searchlight\").","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_future-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Future — run_future","text":"tibble containing processed results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_future-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Future — run_future","text":"","code":"frame <- tibble::tibble(   .id = 1:2,   rnum = c(\"roi1\", \"roi2\"),   roi = list(1:3, 4:5),   size = c(3, 2) ) mod_spec <- list(process_roi = function(mod_spec, roi, rnum, ...) {   tibble::tibble(     result = list(mean(roi)),     indices = list(seq_along(roi)),     performance = list(NULL),     id = rnum   ) }) run_future(mod_spec, frame, NULL) #> Error in run_future(mod_spec, frame, NULL): could not find function \"run_future\""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_regional-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Region of Interest Based MVPA Analysis — run_regional","title":"Region of Interest Based MVPA Analysis — run_regional","text":"Run separate MVPA analysis multiple disjoint regions interest.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_regional-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Region of Interest Based MVPA Analysis — run_regional","text":"","code":"run_regional(model_spec, region_mask, ...)  run_regional_base(   model_spec,   region_mask,   coalesce_design_vars = FALSE,   processor = NULL,   verbose = FALSE,   compute_performance = model_spec$compute_performance,   return_predictions = model_spec$return_predictions,   return_fits = model_spec$return_fits,   ... )  # Default S3 method run_regional(model_spec, region_mask, ...)  # S3 method for class 'mvpa_model' run_regional(   model_spec,   region_mask,   coalesce_design_vars = FALSE,   processor = NULL,   verbose = FALSE,   ... )  # S3 method for class 'rsa_model' run_regional(   model_spec,   region_mask,   return_fits = FALSE,   compute_performance = TRUE,   coalesce_design_vars = FALSE,   ... )  # S3 method for class 'vector_rsa_model' run_regional(   model_spec,   region_mask,   return_fits = FALSE,   compute_performance = TRUE,   coalesce_design_vars = FALSE,   processor = NULL,   verbose = FALSE,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_regional-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Region of Interest Based MVPA Analysis — run_regional","text":"model_spec mvpa_model instance containing model specifications region_mask NeuroVol NeuroSurface object region identified unique integer ... Extra arguments passed specific regional analysis methods (e.g., `return_fits`, `compute_performance`). coalesce_design_vars TRUE, merges design variables prediction table (present generated). Default FALSE. processor optional custom processor function region (ROI). NULL (default), behavior depends model_spec class. verbose TRUE, print progress messages iteration (default FALSE). compute_performance Logical indicating whether compute performance metrics (default TRUE). return_predictions Logical indicating whether combine full prediction table (defaults model_spec$return_predictions). return_fits Logical indicating whether return fitted models (default FALSE).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_regional-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Region of Interest Based MVPA Analysis — run_regional","text":"regional_mvpa_result object (list) containing: performance_table tibble performance metrics region (computed). prediction_table tibble detailed predictions observation/region (generated). vol_results list volumetric maps representing performance metrics across space (computed). fits list fitted model objects region (requested via `return_fits=TRUE`). model_spec original model specification object provided. # Note: Original documentation said 'performance', clarified .","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_regional-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Region of Interest Based MVPA Analysis — run_regional","text":"function serves base implementation regional analyses, orchestrating data preparation, iteration regions, performance computation, result aggregation. Specific `run_regional` methods different model classes may call function provide specialized behavior. fallback method called specialized `run_regional` method found class `model_spec`. typically calls `run_regional_base`. method provides standard regional analysis pipeline objects class `mvpa_model` calling `run_regional_base`. `rsa_model` objects, `return_predictions` defaults `FALSE` standard RSA typically produce prediction table way classification/regression models. `vector_rsa_model` objects, `return_predictions` defaults `FALSE` `run_regional_base`. `model_spec$return_predictions` TRUE, method assemble `observation_scores_table`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_regional-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Region of Interest Based MVPA Analysis — run_regional","text":"","code":"# \\donttest{   # Generate sample dataset (3D volume with categorical response)   dataset <- gen_sample_dataset(     D = c(10,10,10),       # Small 10x10x10 volume     nobs = 100,            # 100 observations     nlevels = 3,           # 3 classes     response_type = \"categorical\",     data_mode = \"image\",     blocks = 3             # 3 blocks for cross-validation   )      # Create region mask with 5 ROIs   region_mask <- NeuroVol(     sample(1:5, size=length(dataset$dataset$mask), replace=TRUE),     space(dataset$dataset$mask)   ) #> Error in NeuroVol(sample(1:5, size = length(dataset$dataset$mask), replace = TRUE),     space(dataset$dataset$mask)): could not find function \"NeuroVol\"      # Create cross-validation specification   cval <- blocked_cross_validation(dataset$design$block_var)      # Load SDA classifier (Shrinkage Discriminant Analysis)   model <- load_model(\"sda_notune\")      # Create MVPA model   mspec <- mvpa_model(     model = model,     dataset = dataset$dataset,     design = dataset$design,     model_type = \"classification\",     crossval = cval,     return_fits = TRUE    # Return fitted models   )      # Run regional analysis   results <- run_regional(mspec, region_mask) #> Error: object 'region_mask' not found      # Access results   head(results$performance)           # Performance metrics #> Error: object 'results' not found   head(results$prediction_table)      # Predictions #> Error: object 'results' not found   first_roi_fit <- results$fits[[1]]  # First ROI's fitted model #> Error: object 'results' not found # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.contrast_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Searchlight Analysis for Contrast RSA Model — run_searchlight.contrast_rsa_model","title":"Run Searchlight Analysis for Contrast RSA Model — run_searchlight.contrast_rsa_model","text":"S3 method running searchlight analysis specifically contrast_rsa_model object. performs Multi-Dimensional Signed Representational Voxel Encoding (MS-ReVE) style analysis across brain volume surface.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.contrast_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Searchlight Analysis for Contrast RSA Model — run_searchlight.contrast_rsa_model","text":"","code":"# S3 method for class 'contrast_rsa_model' run_searchlight(   model_spec,   radius = NULL,   method = c(\"standard\", \"randomized\"),   niter = NULL,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.contrast_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Searchlight Analysis for Contrast RSA Model — run_searchlight.contrast_rsa_model","text":"model_spec contrast_rsa_model object created \\link{contrast_rsa_model}. radius radius searchlight sphere (mm volume data, geodesic distance/vertex count surface data - interpretation depends distance_metric used neuroim2::searchlight neurosurf::SurfaceSearchlight). method type searchlight procedure. Currently, \"standard\" fully supported recommended contrast RSA. \"standard\" method iterates voxels/vertices mask, treating center calculating specific contribution metric (e.g., beta_delta). results combined directly Q output maps using combine_msreve_standard.  Using \"randomized\" **recommended** model. code run, default combiner (combine_msreve_standard) produce sparse maps values random center locations. proper interpretation randomized searchlight (averaging results based voxel coverage) require different, model-specific combiner (e.g., combine_msreve_randomized), currently implemented due conceptual challenges averaging center-voxel specific MS-ReVE metric. niter number iterations method = \"randomized\" used (see note ). ... Additional arguments passed underlying searchlight machinery (e.g., mvpa_iterate).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.contrast_rsa_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Searchlight Analysis for Contrast RSA Model — run_searchlight.contrast_rsa_model","text":"searchlight_result object (specifically class   c(\"msreve_searchlight_result\", \"searchlight_result\", \"list\")), containing: results named list element SparseNeuroVec     NeuroSurfaceVector representing map one contrast. metrics character vector contrast names. n_voxels Total number voxels/vertices original mask space. active_voxels Number voxels/vertices results computed.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.contrast_rsa_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Searchlight Analysis for Contrast RSA Model — run_searchlight.contrast_rsa_model","text":"","code":"# Assuming 'spec' is a valid contrast_rsa_model object # Standard (recommended) method: # results <- run_searchlight(spec, radius = 8, method = \"standard\") # plot(results$results[[1]]) # Plot the map for the first contrast  # Assuming contrast_rsa_model examples have run and objects like # 'mvpa_dat', 'msreve_des', 'model_basic', 'model_recon' are available. # This requires the setup from contrast_rsa_model examples.  if (requireNamespace(\"neuroim2\", quietly = TRUE) &&      requireNamespace(\"rMVPA\", quietly = TRUE) &&     exists(\"model_basic\") && inherits(model_basic, \"contrast_rsa_model\") &&     exists(\"model_recon\") && inherits(model_recon, \"contrast_rsa_model\")) {    # --- Example 1: Run searchlight with basic model ---   # Use a very small radius for quick example run.   # Actual searchlight analyses would use a more appropriate radius (e.g., 3-4 voxels).   # With dummy data, results won't be meaningful; focus is on execution.    message(\"Running searchlight example 1 (basic model, radius=1)... May take a moment.\")   sl_results_basic <- tryCatch({     run_searchlight(model_basic, radius = 1, method = \"standard\")   }, error = function(e) {     message(\"Searchlight (basic model) example failed: \", e$message)     NULL   })   if (!is.null(sl_results_basic)) {     print(sl_results_basic)   }    # --- Example 2: Run searchlight with recon_score output ---   message(\"Running searchlight example 2 (recon_score model, radius=1)... May take a moment.\")   sl_results_recon <- tryCatch({     run_searchlight(model_recon, radius = 1, method = \"standard\")   }, error = function(e) {     message(\"Searchlight (recon_score model) example failed: \", e$message)     NULL   })   if (!is.null(sl_results_recon)) {     print(sl_results_recon)   }    # Note on Crossnobis with searchlight:   # To run a searchlight with 'estimation_method = \"crossnobis\"' from 'model_crossnobis',   # the 'whitening_matrix_W' needs to be passed through the searchlight machinery   # to 'compute_crossvalidated_means_sl'. This typically involves passing it via   # the `...` argument of `run_searchlight` and ensuring `mvpa_iterate` and   # `train_model` propagate it. This advanced usage is not shown here as it   # requires modification to the general `mvpa_iterate` or a custom processor.  } else {  message(\"Skipping run_searchlight.contrast_rsa_model example execution here.\")  message(\"It can be time-consuming and depends on prior setup.\") } #> Skipping run_searchlight.contrast_rsa_model example execution here. #> It can be time-consuming and depends on prior setup."},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Default method for run_searchlight — run_searchlight.default","title":"Default method for run_searchlight — run_searchlight.default","text":"default, object's class implement specific run_searchlight.<class> method, fallback call run_searchlight_base.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default method for run_searchlight — run_searchlight.default","text":"","code":"# Default S3 method run_searchlight(   model_spec,   radius = 8,   method = c(\"randomized\", \"standard\"),   niter = 4,   combiner = \"average\",   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default method for run_searchlight — run_searchlight.default","text":"model_spec generic model specification object. radius Numeric searchlight radius (1 100). method Character: \"standard\" \"randomized\". niter Number iterations method=\"randomized\". combiner Either function combines partial results string (\"pool\", \"average\") selects built-combiner. ... Additional arguments passed do_standard do_randomized.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Searchlight Analysis — run_searchlight","title":"Run Searchlight Analysis — run_searchlight","text":"Execute searchlight analysis using multivariate pattern analysis.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Searchlight Analysis — run_searchlight","text":"","code":"run_searchlight(   model_spec,   radius,   method = c(\"standard\", \"randomized\"),   niter = NULL,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Searchlight Analysis — run_searchlight","text":"model_spec mvpa_model instance containing model specifications radius searchlight radius millimeters method type searchlight, either 'randomized' 'standard' niter number searchlight iterations (used 'randomized' method) ... Extra arguments passed specific searchlight methods. Currently supported: batch_size: Integer specifying number searchlights process per batch.         Default 10% total searchlights. Lower values reduce memory usage may impact         performance. controls searchlights grouped processing - batch         processed sequentially, searchlights within batch processed parallel.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Searchlight Analysis — run_searchlight","text":"named list NeuroVol objects containing performance metrics (e.g., AUC) voxel location","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Searchlight Analysis — run_searchlight","text":"","code":"# \\donttest{   # Generate sample dataset with categorical response   dataset <- gen_sample_dataset(     D = c(8,8,8),           # 8x8x8 volume     nobs = 100,             # 100 observations     response_type = \"categorical\",     data_mode = \"image\",     blocks = 3,             # 3 blocks for cross-validation     nlevels = 2             # binary classification   )      # Create cross-validation specification using blocks   cval <- blocked_cross_validation(dataset$design$block_var)      # Load the SDA classifier (Shrinkage Discriminant Analysis)   model <- load_model(\"sda_notune\")      # Create MVPA model   mspec <- mvpa_model(     model = model,     dataset = dataset$dataset,     design = dataset$design,     model_type = \"classification\",     crossval = cval   )      # Run searchlight analysis   results <- run_searchlight(     mspec,     radius = 8,            # 8mm radius     method = \"standard\"    # Use standard searchlight   ) #> INFO [2025-09-27 21:49:23] Running standard searchlight with radius = 8 #> INFO [2025-09-27 21:49:23] creating standard searchlight #> INFO [2025-09-27 21:49:23] running standard searchlight iterator #> INFO [2025-09-27 21:49:23] ⚡ Processing batch 1/11 (24 ROIs in this batch) #> INFO [2025-09-27 21:49:31] ⚡ Processing batch 2/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:49:38] ⚡ Processing batch 3/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:49:46] ⚡ Processing batch 4/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:49:54] ⚡ Processing batch 5/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:50:02] ⚡ Processing batch 6/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:50:10] ⚡ Processing batch 7/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:50:17] ⚡ Processing batch 8/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:50:24] ⚡ Processing batch 9/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:50:31] ⚡ Processing batch 10/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:50:39] ⚡ Processing batch 11/11 (23 ROIs in this batch) #> INFO [2025-09-27 21:50:45]  #> ✨ MVPA Iteration Complete #> ├─ Total ROIs: 254 #> ├─ Processed: 254 #> └─ Skipped: 0 #> New names: #> • `` -> `...1` #> • `` -> `...2` #> • `` -> `...3` #> • `` -> `...4` #> • `` -> `...5` #> • `` -> `...6` #> • `` -> `...7` #> • `` -> `...8` #> • `` -> `...9` #> • `` -> `...10` #> • `` -> `...11` #> • `` -> `...12` #> • `` -> `...13` #> • `` -> `...14` #> • `` -> `...15` #> • `` -> `...16` #> • `` -> `...17` #> • `` -> `...18` #> • `` -> `...19` #> • `` -> `...20` #> • `` -> `...21` #> • `` -> `...22` #> • `` -> `...23` #> • `` -> `...24` #> • `` -> `...25` #> • `` -> `...26` #> • `` -> `...27` #> • `` -> `...28` #> • `` -> `...29` #> • `` -> `...30` #> • `` -> `...31` #> • `` -> `...32` #> • `` -> `...33` #> • `` -> `...34` #> • `` -> `...35` #> • `` -> `...36` #> • `` -> `...37` #> • `` -> `...38` #> • `` -> `...39` #> • `` -> `...40` #> • `` -> `...41` #> • `` -> `...42` #> • `` -> `...43` #> • `` -> `...44` #> • `` -> `...45` #> • `` -> `...46` #> • `` -> `...47` #> • `` -> `...48` #> • `` -> `...49` #> • `` -> `...50` #> • `` -> `...51` #> • `` -> `...52` #> • `` -> `...53` #> • `` -> `...54` #> • `` -> `...55` #> • `` -> `...56` #> • `` -> `...57` #> • `` -> `...58` #> • `` -> `...59` #> • `` -> `...60` #> • `` -> `...61` #> • `` -> `...62` #> • `` -> `...63` #> • `` -> `...64` #> • `` -> `...65` #> • `` -> `...66` #> • `` -> `...67` #> • `` -> `...68` #> • `` -> `...69` #> • `` -> `...70` #> • `` -> `...71` #> • `` -> `...72` #> • `` -> `...73` #> • `` -> `...74` #> • `` -> `...75` #> • `` -> `...76` #> • `` -> `...77` #> • `` -> `...78` #> • `` -> `...79` #> • `` -> `...80` #> • `` -> `...81` #> • `` -> `...82` #> • `` -> `...83` #> • `` -> `...84` #> • `` -> `...85` #> • `` -> `...86` #> • `` -> `...87` #> • `` -> `...88` #> • `` -> `...89` #> • `` -> `...90` #> • `` -> `...91` #> • `` -> `...92` #> • `` -> `...93` #> • `` -> `...94` #> • `` -> `...95` #> • `` -> `...96` #> • `` -> `...97` #> • `` -> `...98` #> • `` -> `...99` #> • `` -> `...100` #> • `` -> `...101` #> • `` -> `...102` #> • `` -> `...103` #> • `` -> `...104` #> • `` -> `...105` #> • `` -> `...106` #> • `` -> `...107` #> • `` -> `...108` #> • `` -> `...109` #> • `` -> `...110` #> • `` -> `...111` #> • `` -> `...112` #> • `` -> `...113` #> • `` -> `...114` #> • `` -> `...115` #> • `` -> `...116` #> • `` -> `...117` #> • `` -> `...118` #> • `` -> `...119` #> • `` -> `...120` #> • `` -> `...121` #> • `` -> `...122` #> • `` -> `...123` #> • `` -> `...124` #> • `` -> `...125` #> • `` -> `...126` #> • `` -> `...127` #> • `` -> `...128` #> • `` -> `...129` #> • `` -> `...130` #> • `` -> `...131` #> • `` -> `...132` #> • `` -> `...133` #> • `` -> `...134` #> • `` -> `...135` #> • `` -> `...136` #> • `` -> `...137` #> • `` -> `...138` #> • `` -> `...139` #> • `` -> `...140` #> • `` -> `...141` #> • `` -> `...142` #> • `` -> `...143` #> • `` -> `...144` #> • `` -> `...145` #> • `` -> `...146` #> • `` -> `...147` #> • `` -> `...148` #> • `` -> `...149` #> • `` -> `...150` #> • `` -> `...151` #> • `` -> `...152` #> • `` -> `...153` #> • `` -> `...154` #> • `` -> `...155` #> • `` -> `...156` #> • `` -> `...157` #> • `` -> `...158` #> • `` -> `...159` #> • `` -> `...160` #> • `` -> `...161` #> • `` -> `...162` #> • `` -> `...163` #> • `` -> `...164` #> • `` -> `...165` #> • `` -> `...166` #> • `` -> `...167` #> • `` -> `...168` #> • `` -> `...169` #> • `` -> `...170` #> • `` -> `...171` #> • `` -> `...172` #> • `` -> `...173` #> • `` -> `...174` #> • `` -> `...175` #> • `` -> `...176` #> • `` -> `...177` #> • `` -> `...178` #> • `` -> `...179` #> • `` -> `...180` #> • `` -> `...181` #> • `` -> `...182` #> • `` -> `...183` #> • `` -> `...184` #> • `` -> `...185` #> • `` -> `...186` #> • `` -> `...187` #> • `` -> `...188` #> • `` -> `...189` #> • `` -> `...190` #> • `` -> `...191` #> • `` -> `...192` #> • `` -> `...193` #> • `` -> `...194` #> • `` -> `...195` #> • `` -> `...196` #> • `` -> `...197` #> • `` -> `...198` #> • `` -> `...199` #> • `` -> `...200` #> • `` -> `...201` #> • `` -> `...202` #> • `` -> `...203` #> • `` -> `...204` #> • `` -> `...205` #> • `` -> `...206` #> • `` -> `...207` #> • `` -> `...208` #> • `` -> `...209` #> • `` -> `...210` #> • `` -> `...211` #> • `` -> `...212` #> • `` -> `...213` #> • `` -> `...214` #> • `` -> `...215` #> • `` -> `...216` #> • `` -> `...217` #> • `` -> `...218` #> • `` -> `...219` #> • `` -> `...220` #> • `` -> `...221` #> • `` -> `...222` #> • `` -> `...223` #> • `` -> `...224` #> • `` -> `...225` #> • `` -> `...226` #> • `` -> `...227` #> • `` -> `...228` #> • `` -> `...229` #> • `` -> `...230` #> • `` -> `...231` #> • `` -> `...232` #> • `` -> `...233` #> • `` -> `...234` #> • `` -> `...235` #> • `` -> `...236` #> • `` -> `...237` #> • `` -> `...238` #> • `` -> `...239` #> • `` -> `...240` #> • `` -> `...241` #> • `` -> `...242` #> • `` -> `...243` #> • `` -> `...244` #> • `` -> `...245` #> • `` -> `...246` #> • `` -> `...247` #> • `` -> `...248` #> • `` -> `...249` #> • `` -> `...250` #> • `` -> `...251` #> • `` -> `...252` #> • `` -> `...253` #> • `` -> `...254` #> WARN [2025-09-27 21:50:47] Observed probabilities map skipped: expected 512 rows but found 100.      # Run with custom batch size for memory management   # results <- run_searchlight(   #   mspec,   #   radius = 8,   #   method = \"standard\",   #   batch_size = 500      # Process 500 searchlights per batch   # )      # Results contain performance metrics   # Access them with results$performance # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.vector_rsa.html","id":null,"dir":"Reference","previous_headings":"","what":"run_searchlight method for vector_rsa_model — run_searchlight.vector_rsa","title":"run_searchlight method for vector_rsa_model — run_searchlight.vector_rsa","text":"sets custom mvpa_fun (e.g., vector_rsa_iterate) different combiners standard vs. randomized, etc.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.vector_rsa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"run_searchlight method for vector_rsa_model — run_searchlight.vector_rsa","text":"","code":"# S3 method for class 'vector_rsa' run_searchlight(   model_spec,   radius = 8,   method = c(\"randomized\", \"standard\"),   niter = 4,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight.vector_rsa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"run_searchlight method for vector_rsa_model — run_searchlight.vector_rsa","text":"model_spec vector_rsa_model object. radius Numeric searchlight radius (1 100). method Character: \"standard\" \"randomized\". niter Number iterations method=\"randomized\". ... Additional arguments passed do_standard do_randomized.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight_base.html","id":null,"dir":"Reference","previous_headings":"","what":"A ","title":"A ","text":"function implements generic logic running searchlight: Checks radius method. \"standard\" searchlight, calls do_standard(...). \"randomized\", calls do_randomized(...) niter times. Handles combiner function string (\"pool\", \"average\").","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight_base.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A ","text":"","code":"run_searchlight_base(   model_spec,   radius = 8,   method = c(\"randomized\", \"standard\"),   niter = 4,   combiner = \"average\",   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight_base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A ","text":"model_spec model specification object (e.g., mvpa_model, vector_rsa_model, etc.). radius Numeric searchlight radius (1 100). method Character: \"standard\" \"randomized\". niter Number iterations method=\"randomized\". combiner Either function combines partial results string (\"pool\", \"average\") selects built-combiner. ... Additional arguments passed do_standard do_randomized.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight_base.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A ","text":"result object do_standard do_randomized (often searchlight_result similar).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/run_searchlight_base.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A ","text":"assume specific model type, expects model_spec compatible do_standard(...) do_randomized(...) code.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/save_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Save searchlight results to disk (S3 generic) — save_results","title":"Save searchlight results to disk (S3 generic) — save_results","text":"Save searchlight results disk (S3 generic)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/save_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save searchlight results to disk (S3 generic) — save_results","text":"","code":"save_results(   x,   dir,   level = c(\"standard\", \"minimal\", \"complete\"),   stack = c(\"none\", \"auto\", \"vec\"),   fname = \"searchlight.nii.gz\",   include = NULL,   dtype = NULL,   overwrite = FALSE,   quiet = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/save_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save searchlight results to disk (S3 generic) — save_results","text":"x result object (e.g., `searchlight_result`, list NeuroVols, etc.) dir Directory write (created needed) level One \"minimal\", \"standard\", \"complete\" - minimal: maps - standard: maps + manifest (default) - complete: maps + manifest + tables + aux (present) stack One c(\"none\",\"auto\",\"vec\"). - \"none\": Write individual NIfTI files metric (default) - \"auto\": Stack 4D maps compatible, otherwise individual files - \"vec\": Force stacking one 4D NIfTI file fname Base filename writing 4D file (default \"searchlight.nii.gz\") used stack=\"vec\" stack=\"auto\" compatible volumes include Character vector extras include; subset c(\"manifest\",\"tables\",\"aux\"). `level` sets sensible defaults. dtype Optional data_type neuroim2 write_* (e.g., \"FLOAT\",\"DOUBLE\") overwrite Logical; FALSE target exists, stop. quiet Logical; suppress messages.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/save_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save searchlight results to disk (S3 generic) — save_results","text":"(invisible) list describing written.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/second_order_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Second-Order Similarity Scores — second_order_similarity","title":"Compute Second-Order Similarity Scores — second_order_similarity","text":"Calculates correlation-based second order similarity : full NxN distance matrix computed X via distfun, Dref matrix (\"reference\" dissimilarities). row , excludes -block comparisons selecting (block_var != block_var[]).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/second_order_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Second-Order Similarity Scores — second_order_similarity","text":"","code":"second_order_similarity(   distfun,   X,   Dref,   block_var,   method = c(\"pearson\", \"spearman\") )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/second_order_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Second-Order Similarity Scores — second_order_similarity","text":"distfun S3 distance object (see create_dist) specifying compute pairwise distance matrix X. X numeric matrix (rows = observations, columns = features). Dref numeric NxN reference matrix dissimilarities (e.g., ROI mask prior). block_var vector indicating block/group memberships row X. method Correlation method: \"pearson\" \"spearman\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/second_order_similarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Second-Order Similarity Scores — second_order_similarity","text":"numeric vector length nrow(X), entry correlation (using method) distance_matrix[, valid] Dref[, valid], valid = (block_var != block_var[]).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/second_order_similarity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Second-Order Similarity Scores — second_order_similarity","text":"function first calls pairwise_dist(distfun, X), obtaining NxN matrix pairwise distances. block-based exclusion internally. Instead, row , excludes -block rows correlation subsetting distances valid_indices.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/second_order_similarity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Second-Order Similarity Scores — second_order_similarity","text":"","code":"# Suppose we have X (10x5), a reference D (10x10), block var, and a correlation distfun: X <- matrix(rnorm(50), 10, 5) D <- matrix(runif(100), 10, 10) block <- rep(1:2, each=5) dist_obj <- cordist(method=\"pearson\") scores <- second_order_similarity(dist_obj, X, D, block, method=\"spearman\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/select_features-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Features — select_features","title":"Select Features — select_features","text":"Given feature_selection specification object dataset, returns set selected features binary vector.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/select_features-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Features — select_features","text":"","code":"select_features(obj, X, Y, ...)  # S3 method for class 'catscore' select_features(obj, X, Y, ranking.score = c(\"entropy\", \"avg\", \"max\"), ...)  # S3 method for class 'FTest' select_features(obj, X, Y, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/select_features-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Features — select_features","text":"obj feature_selection object specifying feature selection method parameters. X dataset containing training features. can matrix ROIVolume ROISurface object. Y dependent variable factor numeric variable. ... Additional arguments passed method-specific function. ranking.score feature score use. Supported scores \"entropy\", \"avg\", \"max\". Default \"entropy\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/select_features-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Features — select_features","text":"logical vector indicating columns X matrix selected.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/select_features-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Features — select_features","text":"","code":"fsel <- feature_selector(\"FTest\", \"top_k\", 2) coords <- rbind(c(1,1,1), c(2,2,2), c(3,3,3)) space <- neuroim2::NeuroSpace(c(10,10,10)) roi_data <- matrix(rnorm(100*3), 100, 3) ROI <- neuroim2::ROIVec(space, coords=coords, roi_data) Y <- factor(rep(c(\"a\", \"b\"), each=50)) featureMask <- select_features(fsel, neuroim2::values(ROI), Y) #> selecting features via FTest #> cutoff type top_k #> cutoff value 2 #> retaining 2 features in matrix with 3 columns sum(featureMask) == 2 #> [1] TRUE  fsel2 <- feature_selector(\"FTest\", \"top_p\", .1) featureMask <- select_features(fsel2, neuroim2::values(ROI), Y) #> selecting features via FTest #> cutoff type top_p #> cutoff value 0.1 #> retaining 1 features in matrix with 3 columns"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/strip_dataset-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Strip Dataset from Model Specification — strip_dataset","title":"Strip Dataset from Model Specification — strip_dataset","text":"Removes potentially large dataset component model specification object avoid copying parallel processing.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/strip_dataset-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Strip Dataset from Model Specification — strip_dataset","text":"","code":"strip_dataset(obj, ...)  # Default S3 method strip_dataset(obj, ...)  # S3 method for class 'mvpa_model' strip_dataset(obj, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/strip_dataset-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Strip Dataset from Model Specification — strip_dataset","text":"obj model specification object. ... Additional arguments.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/strip_dataset-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Strip Dataset from Model Specification — strip_dataset","text":"model specification object `dataset` element removed set NULL.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/strip_dataset-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Strip Dataset from Model Specification — strip_dataset","text":"","code":"# \\donttest{   ds <- gen_sample_dataset(D = c(4, 4, 4), nobs = 20)   mdl <- load_model(\"sda_notune\")   mspec <- mvpa_model(mdl, ds$dataset, ds$design, \"classification\")   stripped <- strip_dataset(mspec)   is.null(stripped$dataset) #> [1] TRUE # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset Multiway Classification Result — sub_result.multiway_classification_result","title":"Subset Multiway Classification Result — sub_result.multiway_classification_result","text":"function subsets multiway classification result based provided indices. function subsets binary classification result based provided indices.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset Multiway Classification Result — sub_result.multiway_classification_result","text":"","code":"# S3 method for class 'multiway_classification_result' sub_result(x, indices)  # S3 method for class 'binary_classification_result' sub_result(x, indices)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset Multiway Classification Result — sub_result.multiway_classification_result","text":"x object class binary_classification_result containing binary classification results. indices set indices used subset results.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset Multiway Classification Result — sub_result.multiway_classification_result","text":"multiway_classification_result object containing subset results specified indices. binary_classification_result object containing subset results specified indices.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Row-wise Subset of a Result — sub_result","title":"Extract Row-wise Subset of a Result — sub_result","text":"Extract subset rows classification/regression result object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Row-wise Subset of a Result — sub_result","text":"","code":"sub_result(x, indices)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Row-wise Subset of a Result — sub_result","text":"x input result object. indices Row indices extract.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/sub_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Row-wise Subset of a Result — sub_result","text":"new result object specified rows.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/summary.feature_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Feature RSA Model — summary.feature_rsa_model","title":"Summary Method for Feature RSA Model — summary.feature_rsa_model","text":"Summary Method Feature RSA Model","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/summary.feature_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Feature RSA Model — summary.feature_rsa_model","text":"","code":"# S3 method for class 'feature_rsa_model' summary(object, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/summary.feature_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Feature RSA Model — summary.feature_rsa_model","text":"object feature RSA model ... Additional args","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/table_to_rdm.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Similarity Table to RDM — table_to_rdm","title":"Convert Similarity Table to RDM — table_to_rdm","text":"Converts similarity lookup table Representational Dissimilarity Matrix (RDM) use RSA analyses. function maps label pairs similarity table creates complete RDM, using default values missing pairs.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/table_to_rdm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Similarity Table to RDM — table_to_rdm","text":"","code":"table_to_rdm(   similarity_table,   labels,   label1_col = \"label1\",   label2_col = \"label2\",   similarity_col = \"similarity\",   default_similarity = 0,   symmetric = TRUE,   self_similarity = 1,   as_dist = TRUE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/table_to_rdm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Similarity Table to RDM — table_to_rdm","text":"similarity_table data frame containing pairwise similarity values columns label1, label2, similarity values labels character vector labels create RDM. output RDM labels order label1_col Character string specifying column name first label (default: \"label1\") label2_col Character string specifying column name second label (default: \"label2\") similarity_col Character string specifying column name similarity values (default: \"similarity\"). Values 0 1, 1 = identical default_similarity Numeric value use label pairs found table (default: 0, meaning maximum dissimilarity) symmetric Logical indicating whether similarity table treated symmetric (default: TRUE). TRUE, (,B) = (B,) self_similarity Numeric value diagonal elements (self-similarity). Default 1 (perfect similarity). Set NA look table as_dist Logical; TRUE return dist object, otherwise return matrix (default: TRUE)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/table_to_rdm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Similarity Table to RDM — table_to_rdm","text":"dist object symmetric matrix representing dissimilarities (RDM).   Values computed 1 - similarity, 0 = identical 1 = maximally different","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/table_to_rdm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Similarity Table to RDM — table_to_rdm","text":"function useful hypothesis-driven RSA theoretical predictions similarity structure conditions. similarity table can sparse (pairs need specified), missing pairs use default similarity value. function converts similarities dissimilarities using formula: dissimilarity = 1 - similarity","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/table_to_rdm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Similarity Table to RDM — table_to_rdm","text":"","code":"# Create a similarity table based on theoretical predictions sim_table <- data.frame(   label1 = c(\"cat\", \"cat\", \"dog\", \"car\"),   label2 = c(\"dog\", \"bird\", \"bird\", \"plane\"),   similarity = c(0.7, 0.5, 0.6, 0.8) )  # Create RDM for specific conditions conditions <- c(\"cat\", \"dog\", \"bird\", \"car\", \"plane\", \"boat\") rdm <- table_to_rdm(sim_table, conditions)  # Get as matrix instead of dist rdm_matrix <- table_to_rdm(sim_table, conditions, as_dist = FALSE)  # Use in RSA design if (FALSE) { # \\dontrun{ rsa_des <- rsa_design(~ theoretical_rdm,                      data = list(theoretical_rdm = rdm)) } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal RDM wrapper for formula usage — temporal","title":"Temporal RDM wrapper for formula usage — temporal","text":"Convenience wrapper temporal_rdm simplifies usage RSA formulas.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal RDM wrapper for formula usage — temporal","text":"","code":"temporal(index, block = NULL, ..., as_dist = TRUE)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal RDM wrapper for formula usage — temporal","text":"index numeric integer vector representing trial order time block optional vector run/block identifiers ... additional parameters passed temporal_rdm as_dist logical; TRUE return dist object (default TRUE)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal RDM wrapper for formula usage — temporal","text":"dist object matrix representing temporal relationships","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Temporal RDM wrapper for formula usage — temporal","text":"function provides shorter name use RSA design formulas. calls temporal_rdm parameters.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal RDM wrapper for formula usage — temporal","text":"","code":"if (FALSE) { # \\dontrun{ # Use directly in RSA formula rdes <- rsa_design(   ~ task_rdm + temporal(trial_index, block=run, kernel=\"adjacent\", width=2),   data = list(task_rdm = task_rdm, trial_index = 1:100, run = run_ids),   block_var = ~ run ) } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_nuisance_for_msreve.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal nuisance RDM at condition level (for MS-ReVE) — temporal_nuisance_for_msreve","title":"Temporal nuisance RDM at condition level (for MS-ReVE) — temporal_nuisance_for_msreve","text":"Creates condition-level temporal nuisance RDM use MS-ReVE/contrast_rsa_model. function reduces trial-level temporal relationships condition-level relationships.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_nuisance_for_msreve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal nuisance RDM at condition level (for MS-ReVE) — temporal_nuisance_for_msreve","text":"","code":"temporal_nuisance_for_msreve(   mvpa_design,   time_idx,   reduce = c(\"min\", \"mean\", \"median\", \"nn_min\"),   kernel = c(\"adjacent\", \"boxcar\", \"linear\", \"poly\", \"exp\", \"gauss\"),   within_blocks_only = TRUE,   ... )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_nuisance_for_msreve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal nuisance RDM at condition level (for MS-ReVE) — temporal_nuisance_for_msreve","text":"mvpa_design mvpa_design object containing Y (condition labels) block_var time_idx numeric/integer vector temporal indices, length = nrow(mvpa_design$train_design) reduce character string specifying reduction method: \"min\"Minimum lag pair trials two conditions \"mean\"Average lag pairs trials \"median\"Median lag pairs trials \"nn_min\"Minimum nearest-neighbor distance kernel character string specifying kernel type (see temporal_rdm) within_blocks_only logical; TRUE, ignore pairs spanning different blocks (default TRUE) ... additional kernel parameters passed kernel functions (width, power, lambda, sigma)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_nuisance_for_msreve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal nuisance RDM at condition level (for MS-ReVE) — temporal_nuisance_for_msreve","text":"K x K symmetric matrix (0 diagonal) aligned levels(mvpa_design$Y)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_nuisance_for_msreve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Temporal nuisance RDM at condition level (for MS-ReVE) — temporal_nuisance_for_msreve","text":"function designed MS-ReVE analyses temporal confounds need modeled condition level rather trial level. computes aggregate temporal relationships conditions based temporal structure individual trials.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_nuisance_for_msreve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal nuisance RDM at condition level (for MS-ReVE) — temporal_nuisance_for_msreve","text":"","code":"if (FALSE) { # \\dontrun{ # Create temporal nuisance for MS-ReVE temp_K <- temporal_nuisance_for_msreve(   mvpa_design = mvpa_des,   time_idx = seq_len(nrow(mvpa_des$train_design)),   reduce = \"min\",   kernel = \"exp\",    lambda = 3,   within_blocks_only = TRUE )  # Use in msreve_design msreve_des <- msreve_design(   mvpa_design = mvpa_des,   contrast_matrix = C_mat,   nuisance_rdms = list(temp_decay = temp_K) ) } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_rdm.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal/ordinal nuisance RDM (trial-level) — temporal_rdm","title":"Temporal/ordinal nuisance RDM (trial-level) — temporal_rdm","text":"Creates temporal ordinal nuisance representational dissimilarity matrix (RDM) use RSA analyses. function generates various kernels model temporal proximity effects neuroimaging data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_rdm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal/ordinal nuisance RDM (trial-level) — temporal_rdm","text":"","code":"temporal_rdm(   index,   block = NULL,   kernel = c(\"adjacent\", \"boxcar\", \"linear\", \"poly\", \"exp\", \"gauss\"),   width = 1L,   power = 1,   lambda = 1,   sigma = 1,   within_blocks_only = TRUE,   wrap = FALSE,   normalize = c(\"rank\", \"z\", \"none\"),   as_dist = TRUE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_rdm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal/ordinal nuisance RDM (trial-level) — temporal_rdm","text":"index numeric integer vector representing trial order time (length N observations) block optional vector (length N) run/block identifiers kernel character string specifying kernel type, one : \"adjacent\"Binary kernel immediate neighbors within specified width \"boxcar\"Binary kernel including diagonal specified width \"linear\"Linear decay based lag \"poly\"Polynomial decay specified power \"exp\"Exponential decay specified lambda \"gauss\"Gaussian decay specified sigma width integer window \"adjacent\"/\"boxcar\" kernels (default 1) power exponent \"poly\" kernel (default 1) lambda decay constant \"exp\" kernel (default 1) sigma standard deviation \"gauss\" kernel (default 1) within_blocks_only logical; TRUE, zero nuisance across blocks (default TRUE) wrap logical; TRUE, treat index circular (default FALSE) normalize character string specifying normalization method: \"rank\"Rank transform (ties averaged) \"z\"Z-score normalization \"none\"normalization as_dist logical; TRUE return dist object, otherwise return matrix (default TRUE)","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_rdm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal/ordinal nuisance RDM (trial-level) — temporal_rdm","text":"dist object symmetric matrix (N x N) 0 diagonal,   representing temporal/ordinal relationships observations","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_rdm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Temporal/ordinal nuisance RDM (trial-level) — temporal_rdm","text":"function creates temporal nuisance RDMs modeling carry-effects, scanner drift, temporal confounds fMRI data. resulting RDM can included nuisance regressor RSA models account temporal proximity effects preserving statistical power.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/temporal_rdm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal/ordinal nuisance RDM (trial-level) — temporal_rdm","text":"","code":"# Create temporal RDM for 20 trials across 4 runs trial_index <- 1:20 run_labels <- rep(1:4, each = 5)  # Exponential decay kernel within runs only temp_rdm <- temporal_rdm(trial_index, block = run_labels,                           kernel = \"exp\", lambda = 2,                          within_blocks_only = TRUE)  # Use in RSA design if (FALSE) { # \\dontrun{ rdes <- rsa_design(~ task_rdm + temporal_rdm(trial_idx, block=run, kernel=\"adjacent\"),                    data = list(task_rdm = my_task_rdm,                               trial_idx = seq_len(n_trials),                               run = run_ids),                    block_var = ~ run,                    keep_intra_run = TRUE) } # }"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/test_design-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Test Design Extraction — test_design","title":"Test Design Extraction — test_design","text":"Return design table associated test set object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/test_design-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test Design Extraction — test_design","text":"","code":"test_design(obj)  # S3 method for class 'mvpa_design' test_design(obj)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/test_design-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test Design Extraction — test_design","text":"obj object extract test design table.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/test_design-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test Design Extraction — test_design","text":"","code":"ds <- gen_sample_dataset(D = c(4, 4, 4), nobs = 10, external_test = TRUE) #> external test test_design(ds$design) #> # A tibble: 10 × 2 #>    Ytest .rownum #>    <fct>   <int> #>  1 d           1 #>  2 c           2 #>  3 a           3 #>  4 a           4 #>  5 e           5 #>  6 e           6 #>  7 b           7 #>  8 d           8 #>  9 c           9 #> 10 b          10"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_indices.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Training Indices for a Fold — train_indices","title":"Get Training Indices for a Fold — train_indices","text":"S3 generic method retrieve training sample indices specific fold cross-validation specification object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_indices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Training Indices for a Fold — train_indices","text":"","code":"train_indices(obj, fold_num, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_indices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Training Indices for a Fold — train_indices","text":"obj cross-validation specification object (e.g., inheriting `cross_validation`). fold_num integer specifying fold number retrieve training indices. ... Additional arguments passed methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_indices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Training Indices for a Fold — train_indices","text":"integer vector training indices.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_indices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Training Indices for a Fold — train_indices","text":"","code":"cval <- kfold_cross_validation(len = 20, nfolds = 4) train_indices(cval, 1) #>  [1]  1  2  4  5  6  7  9 10 11 12 13 14 15 18 19"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Train a classification, regression, or representational model. — train_model","title":"Train a classification, regression, or representational model. — train_model","text":"generic function trains model based provided model specification object. Different model types different methods implemented specific parameters. function trains multivariate analysis variance (MANOVA) model using specified design. function implements core logic MS-ReVE analysis within single searchlight region.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train a classification, regression, or representational model. — train_model","text":"","code":"train_model(obj, ...)  # S3 method for class 'manova_model' train_model(obj, train_dat, y, indices, ...)  # S3 method for class 'mvpa_model' train_model(obj, train_dat, y, indices, wts = NULL, ...)  # S3 method for class 'rsa_model' train_model(obj, train_dat, y, indices, ...)  # S3 method for class 'vector_rsa_model' train_model(obj, train_dat, y, indices, ...)  # S3 method for class 'feature_rsa_model' train_model(obj, X, y, indices, ...)  # S3 method for class 'contrast_rsa_model' train_model(obj, sl_data, sl_info, cv_spec, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train a classification, regression, or representational model. — train_model","text":"obj object class contrast_rsa_model. ... Additional arguments (currently ignored). train_dat data frame matrix representing training subset (e.g., voxel intensities). y Feature matrix used RSA (samples x features). indices Spatial indices associated training data. wts Optional class weights (underlying model supports ). X Brain data (samples x voxels). sl_data data matrix current searchlight (samples x voxels). sl_info list containing information current searchlight, including center_local_id. cv_spec cross-validation specification.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train a classification, regression, or representational model. — train_model","text":"trained model object. exact return value depends specific   method implementation. named numeric vector -log(p-values) predictor MANOVA model. model fit object containing trained model, fit, model type (classification regression), best tuning parameters, voxel indices, feature mask. Depending obj$regtype: \"lm\" + constraints + obj$semipartial=TRUE: semi-partial correlations \"lm\" + constraints + obj$semipartial=FALSE: T-values predictor \"lm\" + nneg constraints: raw coefficients constrained glmnet \"rfit\": robust regression coefficients \"pearson\" \"spearman\": correlation coefficients structure containing \"scores\" similar second-order similarity results. list containing RSA metrics , requested, permutation results. named list element corresponds requested `output_metric` `obj$output_metric` vector.   element : metrics like \"beta_delta\", \"beta_only\", \"delta_only\": Q-length named vector           values indexed contrast names match contrast_matrix column names (Q = number contrasts) metrics like \"recon_score\", \"composite\": single numeric value list attribute \"na_reason\" metric calculation failed, can used diagnostics. example, `obj$output_metric = c(\"beta_delta\", \"recon_score\")`, returned list   two elements: `$beta_delta` (Q-length vector) `$recon_score` (single value). named list element corresponds requested metric obj$output_metric.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/train_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Train a classification, regression, or representational model. — train_model","text":"","code":"# \\donttest{   # Generate a small sample dataset for classification   dset_info <- gen_sample_dataset(     D = c(8, 8, 8),     nobs = 20,     response_type = \"categorical\",     data_mode = \"image\",     nlevels = 2   )    # Create a cross-validation specification   cval <- blocked_cross_validation(dset_info$design$block_var)    # Load a simple classifier   sda_model <- load_model(\"sda_notune\")    # Create an MVPA model specification   mspec <- mvpa_model(     model = sda_model,     dataset = dset_info$dataset,     design = dset_info$design,     model_type = \"classification\",     crossval = cval   )    # Train the model   fit <- train_model(     mspec,     dset_info$dataset$train_data,     dset_info$design$y_train,     indices = seq_len(ncol(dset_info$dataset$train_data))   ) #> Error in UseMethod(\"train_model\"): no applicable method for 'train_model' applied to an object of class \"c('mvpa_model', 'model_spec', 'list')\" # } # This example shows the structure of the returned list but doesn't actually run the function # For a multi-metric model: output_metric = c(\"beta_delta\", \"recon_score\", \"beta_only\")"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"Applies centering, scaling, /orthogonalization pre-existing numeric contrast matrix.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"","code":"transform_contrasts(   C,   centre = TRUE,   scale = c(\"none\", \"sd\", \"l2\"),   orth = FALSE,   keep_attr = TRUE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"C numeric matrix representing contrasts (conditions x contrasts). Row names, present, correspond condition labels preserved. Column names, present, used `\"source\"` attribute `orth = TRUE` `keep_attr = TRUE`. centre Logical. TRUE (default), columns matrix mean-centered. scale Character string specifying scaling method centering (`orth=FALSE`). Options: `\"none\"` (default), `\"sd\"` (divide sample standard deviation), `\"l2\"` (divide L2 norm / vector length get unit vectors). argument *ignored* `orth = TRUE`. orth Logical. FALSE (default), matrix columns represent specified contrasts directly (centering/scaling). TRUE, orthonormal basis column space computed via QR decomposition. Resulting columns orthogonal unit length (L2 norm = 1). keep_attr Logical. TRUE (default) `orth = TRUE`, original column names (orthogonalization) stored `attr(C_transformed, \"source\")`, names linearly dependent columns removed orthogonalization stored `attr(C_transformed, \"dropped\")`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"transformed numeric matrix. `orth = TRUE` `keep_attr = TRUE`,   includes `\"source\"` potentially `\"dropped\"` attributes.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"function useful post-processing contrast matrix, especially one might created combining outputs different sources (e.g., theory-driven contrasts data-driven contrasts) direct manual construction.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"scaling","dir":"Reference","previous_headings":"","what":"Scaling","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"Applied ** centering `orth=FALSE`. `\"none\"`: scaling. `\"sd\"`: `scale(..., center=FALSE, scale=TRUE)`. Uses sample standard deviation (N-1 denominator).         Note columns unique values (e.g., centered +/-1 contrast), SD         can slightly different depending whether number items even odd,         due N-1 denominator. might lead minor differences scaled norms. `\"l2\"`: Divides column L2 norm (`sqrt(sum(x^2))`).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"orthogonalization","dir":"Reference","previous_headings":"","what":"Orthogonalization","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"`orth = TRUE`, uses `qr.Q(qr(C))` find orthonormal basis. number columns output rank input matrix. Columns renamed `Orth1`, `Orth2`, etc. Scaling ignored columns already unit L2 norm. `keep_attr = TRUE`:   `attr(C_orth, \"source\")` stores names original columns   formed basis orthogonalized matrix.   `attr(C_orth, \"dropped\")` stores names original columns   linearly dependent thus part basis, .","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"specific-behaviors","dir":"Reference","previous_headings":"","what":"Specific Behaviors","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"`orth = TRUE` input matrix one column potential centering,         column scaled unit L2 norm. Centering still depends `centre` argument. `centre = FALSE` `orth = TRUE`, QR decomposition performed         *uncentered* columns. mini-DSL `. ` notation used `levelsB` `levelsA` already contains         `labels`, `levelsB` becomes empty, potentially resulting constant (zero)         column centering. warning issued case.","code":""},{"path":[]},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/transform_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Transformations to an Existing Contrast Matrix — transform_contrasts","text":"","code":"C_manual <- matrix(c( 1,  1,  0,  0,                      -1,  1,  0,  0,                       0,  0,  1,  1,                       0,  0, -1,  1), nrow = 4, byrow = TRUE,                    dimnames = list(paste0(\"Cond\", 1:4), c(\"MainA\", \"MainB\"))) #> Error in matrix(c(1, 1, 0, 0, -1, 1, 0, 0, 0, 0, 1, 1, 0, 0, -1, 1), nrow = 4,     byrow = TRUE, dimnames = list(paste0(\"Cond\", 1:4), c(\"MainA\",         \"MainB\"))): length of 'dimnames' [2] not equal to array extent  # Center and make orthonormal C_transformed <- transform_contrasts(C_manual, orth = TRUE) #> Error: object 'C_manual' not found print(C_transformed) #> Error: object 'C_transformed' not found print(attr(C_transformed, \"source\")) #> Error: object 'C_transformed' not found  # Center and scale to unit L2 norm C_l2 <- transform_contrasts(C_manual, scale = \"l2\") #> Error: object 'C_manual' not found print(round(colSums(C_l2^2), 5)) #> Error: object 'C_l2' not found"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/tune_grid-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Tuning Grid — tune_grid","title":"Extract Tuning Grid — tune_grid","text":"Returns parameter grid used tune model.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/tune_grid-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Tuning Grid — tune_grid","text":"","code":"tune_grid(obj, x, y, len)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/tune_grid-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Tuning Grid — tune_grid","text":"obj model model specification. x Training data. y Response variable. len Number parameter sets generate.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/tune_grid-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Tuning Grid — tune_grid","text":"data frame tuning parameter combinations.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/tune_grid-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Tuning Grid — tune_grid","text":"","code":"ds  <- gen_sample_dataset(D = c(5, 5, 5), nobs = 10) mdl <- load_model(\"sda_notune\") tune_grid(mdl, ds$dataset$train_data, ds$design$y_train, len = 1) #> Error in UseMethod(\"tune_grid\"): no applicable method for 'tune_grid' applied to an object of class \"list\""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/twofold_blocked_cross_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"twofold_blocked_cross_validation — twofold_blocked_cross_validation","title":"twofold_blocked_cross_validation — twofold_blocked_cross_validation","text":"Construct cross-validation specification randomly partitions input set two sets blocks.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/twofold_blocked_cross_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"twofold_blocked_cross_validation — twofold_blocked_cross_validation","text":"","code":"twofold_blocked_cross_validation(block_var, nreps = 10)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/twofold_blocked_cross_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"twofold_blocked_cross_validation — twofold_blocked_cross_validation","text":"block_var integer vector representing cross-validation blocks. block indicated unique integer. nreps integer specifying number repetitions twofold split.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/twofold_blocked_cross_validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"twofold_blocked_cross_validation — twofold_blocked_cross_validation","text":"object class \"twofold_blocked_cross_validation\", \"cross_validation\", \"list\" containing block_var,   nfolds (fixed 2 function), nreps, block_ind.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/twofold_blocked_cross_validation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"twofold_blocked_cross_validation — twofold_blocked_cross_validation","text":"function creates cross-validation scheme cases data organized blocks, blocks divided two groups evaluation. approach can useful inherent structure dependency within blocks, separating can help avoid biased estimates model performance. returns object class \"twofold_blocked_cross_validation\", \"cross_validation\", \"list\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/twofold_blocked_cross_validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"twofold_blocked_cross_validation — twofold_blocked_cross_validation","text":"","code":"blockvar <- rep(1:5, each=10) nreps <- 5 cval <- twofold_blocked_cross_validation(blockvar, nreps=nreps) samples <- crossval_samples(cval, as.data.frame(matrix(rnorm(50*50),50,50)), y=rep(letters[1:5],10)) stopifnot(nrow(samples) == nreps)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a design for a vectorized RSA model — vector_rsa_design","title":"Construct a design for a vectorized RSA model — vector_rsa_design","text":"function constructs design RSA model using single distance matrix, labels, blocks.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a design for a vectorized RSA model — vector_rsa_design","text":"","code":"vector_rsa_design(D, labels, block_var)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a design for a vectorized RSA model — vector_rsa_design","text":"D representational dissimilarity matrix row.names indicating labels. labels character vector labels corresponding rows another dataset X. block_var vector indicating block (strata) label belongs . Must length `labels`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a design for a vectorized RSA model — vector_rsa_design","text":"list containing elements RSA design, class attributes \"vector_rsa_design\" \"list\".","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Construct a design for a vectorized RSA model — vector_rsa_design","text":"function verifies `labels` appear `rownames(D)` creates expanded dissimilarity matrix (`Dexpanded`) matching order `labels`.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a vectorized RSA model — vector_rsa_model","title":"Create a vectorized RSA model — vector_rsa_model","text":"function integrates vector_rsa_design mvpa_dataset create vectorized RSA model.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a vectorized RSA model — vector_rsa_model","text":"","code":"vector_rsa_model(   dataset,   design,   distfun = cordist(),   rsa_simfun = c(\"pearson\", \"spearman\"),   nperm = 0,   save_distributions = FALSE,   return_predictions = FALSE )"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a vectorized RSA model — vector_rsa_model","text":"dataset mvpa_dataset object. design vector_rsa_design object. distfun distfun (distance function) computing pairwise dissimilarities among image rows. rsa_simfun character string specifying similarity function use RSA, one \"pearson\" \"spearman\". nperm Integer, number permutations statistical testing (default: 0). save_distributions Logical, whether save full permutation distributions (default: FALSE). return_predictions Logical, whether return per-observation similarity scores (default: FALSE).","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a vectorized RSA model — vector_rsa_model","text":"vector_rsa_model object (S3 class) containing references dataset, design, function parameters.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/vector_rsa_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a vectorized RSA model — vector_rsa_model","text":"`return_predictions` TRUE, output `run_regional` `run_searchlight` include `prediction_table` tibble containing observation-level RSA scores.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrap output results — wrap_out","title":"Wrap output results — wrap_out","text":"function wraps output results performance matrix list spatial objects (NeuroVol NeuroSurface) column performance matrix, structures searchlight_result.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrap output results — wrap_out","text":"","code":"wrap_out(perf_mat, dataset, ids = NULL)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrap output results — wrap_out","text":"perf_mat performance matrix (voxels/vertices x metrics) containing classifier results. dataset dataset object containing dataset information (including mask type). ids integer vector voxel/vertex indices corresponding rows `perf_mat`. typically global indices mask space volumetric data, vertex numbers surface data.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrap output results — wrap_out","text":"`searchlight_result` object containing `results`: Named spatial maps metric. `n_voxels`: Total number voxels/vertices defined mask. `active_voxels`: Number voxels/vertices results. `metrics`: Character vector metric names.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrap Output — wrap_output","title":"Wrap Output — wrap_output","text":"Wrap output values desired format.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrap Output — wrap_output","text":"","code":"wrap_output(obj, vals, ...)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrap Output — wrap_output","text":"obj object used determine wrapping method. vals values wrapped. ... Additional arguments passed methods.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/wrap_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrap Output — wrap_output","text":"wrapped output object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_test-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Test Labels/Response Extraction — y_test","title":"Test Labels/Response Extraction — y_test","text":"Extract test labels response variable object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_test-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test Labels/Response Extraction — y_test","text":"","code":"y_test(obj)  # S3 method for class 'mvpa_design' y_test(obj)  # S3 method for class 'mvpa_model' y_test(obj)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_test-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test Labels/Response Extraction — y_test","text":"obj object extract test response variable.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_test-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test Labels/Response Extraction — y_test","text":"","code":"ds <- gen_sample_dataset(D = c(4, 4, 4), nobs = 10, external_test = TRUE) #> external test y_test(ds$design) #>  [1] b e d c e b a d c a #> Levels: a b c d e"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_train-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Training Labels/Response Extraction — y_train","title":"Training Labels/Response Extraction — y_train","text":"Extract training labels response variable object.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_train-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training Labels/Response Extraction — y_train","text":"","code":"y_train(obj)  # S3 method for class 'mvpa_design' y_train(obj)  # S3 method for class 'mvpa_model' y_train(obj)  # S3 method for class 'feature_rsa_model' y_train(obj)  # S3 method for class 'feature_rsa_design' y_train(obj)"},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_train-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Training Labels/Response Extraction — y_train","text":"obj object extract training response variable.","code":""},{"path":"http://bbuchsbaum.github.io/rMVPA/reference/y_train-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training Labels/Response Extraction — y_train","text":"","code":"ds <- gen_sample_dataset(D = c(4, 4, 4), nobs = 10) y_train(ds$design) #>  [1] e b a d c c b d a e #> Levels: a b c d e"},{"path":"http://bbuchsbaum.github.io/rMVPA/signed_rsa_proposal.html","id":"full-rsa-proposal-multi-dimensional-signed-representational-voxel-encoding-ms-reve-with-flow-mapping","dir":"","previous_headings":"","what":"Full RSA Proposal: “Multi-Dimensional Signed Representational Voxel Encoding (MS-ReVE) with Flow Mapping”","title":"NA","text":"Abstract: proposal outlines comprehensive Representational Similarity Analysis (RSA) framework, “Multi-Dimensional Signed Representational Voxel Encoding (MS-ReVE),” designed compute interpretable, signed voxel-wise contributions multi-class neural representations. MS-ReVE extends standard RSA : 1) defining model-relevant contrasts; 2) using multiple-regression RSA cross-validated, noise-normalized condition means determine strength contrasts within local searchlights; 3) projecting condition means onto contrast axes derive signed voxel contributions; 4) combining elements produce robust voxel-weight maps. framework incorporates advanced features including voxel reliability weighting, voxel-specific RDM reconstruction scores, mapping interaction effects, rigorous basis robustness checks. Crucially, MS-ReVE culminates “Representational Flow Mapping” (RFM), novel technique visualize quantify multi-contrast representations transform across cortical surface (volumetric extensions possible), revealing large-scale organizational principles information processing dynamics. complementary “Representational Cross-Talk” analysis probes spatial co-localization different representational dimensions. 1. Introduction & Rationale: Representational Similarity Analysis (RSA) proven invaluable linking brain activity computational models psychological theories. However, traditional RSA often yields searchlight-level summary statistics (e.g., RDM correlations) classifier-based voxel weights can hard interpret directly terms underlying neural coding, especially designs two conditions. pressing need methods : * Provide signed voxel weights indicating individual voxels contribute specific, theoretically meaningful representational dimensions (contrasts). * Scale robustly beyond two experimental conditions. * firmly anchored RSA theory (distance-based, second-moment statistics) rather relying solely classification. * Offer insights spatial organization transformation representations across brain. MS-ReVE addresses needs integrating regression-RSA voxel-level projections, enhanced reliability measures, interaction analyses, novel flow-mapping visualization approach. 2. Research Questions & Hypotheses (Example-driven): framework can address wide range questions, : 1. specific representational dimensions (e.g., animacy, object size, task rule) encoded given brain region? 2. individual voxels contribute (positively negatively) encoding distinct dimensions? 3. voxels reliably contribute specific dimensions, reliability vary spatially? 4. well voxel’s multi-contrast contribution profile explain local empirical representational geometry? 5. conjunctive codes, voxels respond interactions representational dimensions? 6. sensitive voxel-level interpretations precise definition theoretical contrasts? 7. large-scale spatial organization multi-dimensional representations across cortex (e.g., gradients, boundaries)? 8. representations transform (e.g., rotate, scale, differentiate, integrate) along cortical pathways? 3. Methodology & Implementation Plan: . Preprocessing & Experimental Design: 1. Data Acquisition: Standard fMRI data acquisition. 2. Preprocessing: Standard fMRI preprocessing (motion correction, slice-time correction, spatial normalization/surface projection, temporal filtering). Crucially, include noise normalization/whitening voxel time-series, typically using residuals first-level GLM, ensure pattern analyses dominated voxels high noise variance. 3. Experimental Design: Assumes K-condition experimental design K ≥ 2 (multi-way case emphasized), though framework naturally includes binary case. B. Contrast Matrix Definition (C): 1. Priori Contrasts: Define K x Q contrast matrix C, Q columns c_q represents theoretically meaningful comparison feature dimension (e.g., faces - houses, tools - animals, abstract - concrete). * Contrasts centered (sum elements c_q zero). * Ideally, contrasts made orthonormal (CᵀC = ) independent β weights. 2. Data-Driven Contrasts (Alternative/Complementary): * Construct model RDM based theoretical predictions. * Apply classical Multidimensional Scaling (MDS) model RDM. * Use first Q MDS embedding dimensions columns C. * provides data-driven way define orthogonal axes capturing model’s primary representational structure. C. Searchlight RSA Core Engine (Iterate across searchlights): 1. Cross-Validated Condition Means (Û): * Within searchlight (sphere voxels V): * Estimate condition-specific activation patterns (μ_k) K conditions using cross-validation scheme (e.g., leave-one-run-, split-half). Employ methods like crossnobis obtain unbiased estimates pattern distinctness. * results K x V matrix Û cross-validated, noise-normalized condition means. 2. Empirical Second-Moment Matrix (Ĝ): * Calculate unbiased empirical second-moment matrix: Ĝ = ÛÛᵀ. K x K matrix fully determines Mahalanobis distances conditions within searchlight. 3. Multiple-Regression RSA: * Vectorize lower (upper) triangle Ĝ form dependent variable y. * contrast c_q C, form predictor RDM R_q = c_q c_qᵀ. Vectorize lower triangle R_q form columns design matrix X. * Fit multiple linear regression: y = Xβ + ε. * resulting β_q coefficients indicate strongly geometry implied contrast c_q present local empirical geometry Ĝ. * Regularization (Optional): Q large contrasts correlated, use ridge regression (β_ridge = (XᵀX + λI)⁻¹Xᵀy) elastic-net. Hyperparameters (λ, α elastic-net) chosen via nested cross-validation within searchlight training data avoid bias. 4. Signed Voxel Contributions (Δ_q): * contrast c_q, project cross-validated condition means Û onto : Δ_q = Ûᵀc_q. yields V-dimensional vector element Δ_{q,v} represents voxel v’s signed contribution contrast q. * Store : * Raw Δ_q: Preserves magnitude, reflecting effect size contrast voxel activity. * Normalized ~Δ_q = Δ_q / ||Δ_q||: Captures direction . D. Voxel-Level Refinements & Metrics (within searchlight): 1. Voxel Reliability Weighting (ρ_q,v): * Δ_{q,v} estimate, compute stability across cross-validation folds. * Define ρ_{q,v} = 1 - Var_folds(Δ_{q,v}^{(fold)}) / (Var_folds(Δ_{q,v}^{(fold)}) + σ²_noise,q,v). * σ²_noise,q,v (expected variance Δ_{q,v} null) estimated within-condition residual variances contrast weights: σ²_noise,q,v = (1/S) Σ_s Σ_k (w_qk² / n_k^(s)) * σ_k,v²^(s). * Alternatively, use ρ_{q,v} = 1 / (1 + SE(Δ_{q,v})^2) similar based Walther et al. (2016). 2. Voxel-Specific RDM Reconstruction Score (r_v): * voxel v, construct predicted RDM based signed contrast profile: Ĝ^(v) = C * diag(β_1Δ_{1,v}, ..., β_QΔ_{Q,v}) * Cᵀ (using raw Δ). * Calculate r_v = corr(vec_lower(Ĝ^(v)), vec_lower(Ĝ_empirical)) measure crucial voxel v’s multi-contrast profile reconstructing local empirical RDM. E. Generating Voxel-Weight Maps: 1. Contrast-Specific Maps (Set Q maps): * M_{q,v} = β_q * Δ_{q,v} (magnitude-preserved signed contribution). * ~M_{q,v} = β_q * ~Δ_{q,v} (direction-, scaled RSA fit). * M_{q,v}_reliab = ρ_{q,v} * β_q * Δ_{q,v} (reliability-weighted). 2. Single Composite Map (optional): * w_v = Σ_q (β_q * ~Δ_{q,v}) (use reliability-weighted terms). Represents net pull voxel v overall representational space. Note: C orthogonal, interpretation w_v less straightforward contributions summed across potentially non-independent axes. F. Extending Interaction Effects: 1. Define Interaction Contrasts: Create new columns C taking element-wise products main effect contrast columns (c_{pq} = c_p ⊙ c_q). 2. Orthogonalize Expanded Matrix: Orthogonalize expanded contrast matrix C_exp = [C_main | C_interaction] (e.g., using QR decomposition Gram-Schmidt) ensure interpretability interaction βs unique contributions. Note: Orthogonalization procedures may arbitrarily flip sign contrast vectors; orthogonalization, consider aligning sign derived column (e.g., interaction terms) primary parent component based correlation raw Δ projection consistent interpretation. 3. Re-run C.3 C.4: Fit multiple-regression RSA C_exp get β_{pq} compute interaction voxel contributions Δ_{pq,v} = Ûᵀc̃_{pq} (c̃_{pq} orthogonalized interaction contrast). G. Aggregation & Statistical Inference: 1. Searchlight Aggregation: Average voxel weights (M_{q,v}, w_v, r_v, etc.) voxel receives searchlights containing . RSA-weighted average (weighting β_q searchlight R²) can also used. 2. Permutation Testing: voxel-wise significance testing, shuffle condition labels consistently across cross-validation folds, recompute entire pipeline (Û onwards) many times build null distributions β_q, M_{q,v}, w_v, r_v, etc. Apply appropriate cluster-correction methods. Note memory: Storing intermediate Δ values across permutations can memory-intensive. Consider strategies like streaming permutations (recomputing Δ fly within permutation loop) writing intermediate searchlight results disk RAM limited. H. Representational Flow Mapping (RFM): 1. Surface Projection: Project voxel-wise multi-contrast loading vectors m_v = [β_1Δ_{1,v}, ..., β_QΔ_{Q,v}] (reliability-weighted versions) nearest vertices cortical surface model (e.g., subject’s midthickness surface). creates Q scalar maps f_q() surface. 2. Tangential Gradient Estimation: surface map f_q(), compute 2D tangential gradient ∇_T f_q() vertex , typically using filters approximating Gaussian derivatives ensure robustness high-frequency noise. 3. Local PCA Principal Flow: * moving geodesic window surface: * Stack Q gradient vectors ∇_T f_q() vertices within window large matrix (effectively (|WindowVertices|*Q) rows x 2 columns). * Perform PCA matrix’s 2x2 covariance find principal flow direction e₁ (2D unit vector) associated eigenvalue λ₁. 4. Streamline Visualization: * Draw streamlines (e.g., using Line Integral Convolution) along e₁. * Color streamlines contrast q whose gradient ∇_T f_q() aligns best e₁ (.e., argmax_q |<∇_T f_q(), e₁>|), sign indicating increase/decrease. * Modulate streamline opacity/thickness λ₁ (flow strength) /underlying ρ_q,v. 5. Analysis Transformation Along Flow Lines: * Sample m(s) (Q-dimensional vector βΔ values) along streamlines. * Calculate directional derivatives (dm/ds) assess rate dimensionality change (via SVD). * Compare m(s) m(s+Δs) quantify representational rotation (angle change) scaling (norm change). * Visualize transformations (e.g., map rotation rate streamline hue). * Use permutation testing significance flow properties. 6. Volumetric Extension (Optional): surface-based RFM often preferred visualizing cortical organization, core logic can extended 3D volume space computing 3D gradients performing PCA resulting 3x3 covariance matrix within volumetric searchlights. Visualization challenging may relevant subcortical structures. . Robustness & Validation: 1. Basis Robustness Checks: * Re-run key analyses (e.g., generating M_{q,v} maps) alternative, plausible contrast matrix C' (e.g., MDS-derived initially theory-driven, vice-versa). * Correlate resulting voxel maps. Low correlations suggest basis-dependent interpretations. * Use diagnostics: Compare searchlight R² different bases; Canonical Correlation Analysis (CCA) C C'; assess R² gain using [C | C']; compare non-linear/kernel RSA probe model mismatch. 4. Data Analysis & Interpretation Strategy: β_q maps (searchlight regression): Indicate regions geometry predicted contrast q prevalent. M_{q,v} maps: Reveal individual voxels contribute (sign magnitude) specific contrast q. M_{q,v}_reliab maps: Highlight robust voxel contributions. w_v composite map: Shows net directional “pull” voxels combined representational space. r_v maps: Identify voxels whose multi-contrast tuning critical local empirical geometry. Interaction maps (β_{pq}Δ_{pq,v}): Uncover voxels involved conjunctive coding. RFM visualizations: Provide insights large-scale topological organization, functional boundaries, representational transformations across cortex. Analysis λ₁, rotation, scaling along flow lines characterize nature transformations. Compute voxel-wise correlation pairs reliability-weighted contrast maps (M_{q,v}_reliab M_{p,v}_reliab) across voxels within relevant brain regions whole brain/surface. High positive correlations suggest shared neural populations contribute similarly contrasts. High negative correlations suggest competitive coding opponent populations. Visualizing correlation patterns (e.g., matrix projecting strong correlations onto brain) complements RFM showing different representational dimensions spatially co-localize segregate. Group-Level Inference: analyzing results across participants, individual participant maps (M_q,v, r_v, RFM-derived metrics, etc.) aligned common space (e.g., MNI volume space surface template like fsaverage). Standard group-level statistical approaches (e.g., mixed-effects models, t-tests aggregated maps appropriate permutation-based correction) can applied. 5. Expected Outcomes & Significance: MS-ReVE provide unprecedentedly rich interpretable view distributed neural representations. Expected outcomes include: * Detailed, signed voxel-level maps multi-dimensional neural codes. * Identification robust reliable voxel contributions. * Discovery conjunctive coding patterns. * quantitative understanding representations organized transform across cortical areas, linking local computations large-scale network dynamics. * framework significantly advance ability test nuanced theories neural representation bridge gap computational models brain activity. 6. Potential Challenges & Mitigations: Computational Cost: Searchlight analyses, permutation testing, RFM can computationally intensive. Mitigation: Efficient coding, parallel processing, optimized algorithms. Interpretation Complexity: wealth generated maps requires careful interpretation. Mitigation: Clear guidelines, targeted research questions, development standardized reporting. Choice Contrasts: Results can sensitive C. Mitigation: Explicit reporting C, basis robustness checks, use theory-driven data-driven contrasts. Multiple Comparisons: Extensive voxel-wise testing. Mitigation: Rigorous permutation-based cluster correction methods. Memory Usage: Especially permutation testing. Mitigation: Streaming computations, disk caching, efficient data structures (noted 3.G.2). 7. Implementation Plan (Conceptual - Language/Platform Agnostic): implementation modular: 1. Module 1: Core RSA Engine: * Input: Preprocessed fMRI data, condition labels, contrast matrix C, searchlight definitions. * Functions : Cross-validated mean estimation, Ĝ computation, multiple-regression RSA (optional regularization), Δ_q calculation. * Output: β_q values per searchlight, raw Δ_q ~Δ_q vectors per searchlight. 2. Module 2: Voxel-Level Metrics & Map Generation: * Input: Outputs Module 1. * Functions : Reliability (ρ_q,v) calculation, RDM reconstruction (r_v), map generation (M_q,v, w_v), searchlight aggregation. 3. Module 3: Interaction Analysis: * Functions : Generating interaction contrasts, orthogonalizing C_exp, integrating Module 1 & 2 interaction maps. 4. Module 4: Statistical Inference & Aggregation: * Functions : Permutation testing framework (including memory management considerations), cluster correction, group-level analysis preparation execution. 5. Module 5: Representational Flow Mapping (RFM): * Input: Aggregated β_qΔ_{q,v} maps, cortical surface model (/volumetric data). * Functions : Surface projection (applicable), gradient calculation (smoothing options), local PCA (surface volume), streamline generation, transformation analysis along streamlines. * Visualization tools (interfacing existing surface/volume visualization libraries). 6. Module 6: Cross-Talk & Diagnostics: * Functions : Basis robustness checks (CCA, R² comparisons), Representational Cross-Talk computation visualization. modular design facilitate development, testing, future extensions. module encapsulate specific mathematical operations data transformations. Okay, comprehensive summary rMVPA codebase. clearly lays object-oriented structure, key functionalities, dependencies. excellent foundation thinking integrate G-ReCa Phase 0 (subsequently Phase 1) plan. Based summary G-ReCa Phase 0 proposal, ’s can conceptualize integration identify next steps. Conceptual Integration G-ReCa Phase 0 rMVPA: core idea leverage rMVPA’s existing capabilities data handling, design specification, potentially pre-processing, build new modules extend existing ones perform G-ReCa specific steps: MS-ReVE output generation, PCA pre-reduction, PPCA/lightweight manifold learning, ID estimation, validation. Proposed Workflow & rMVPA Integration Points: Dataset Creation (mvpa_dataset, mvpa_surface_dataset): Use rMVPA load structure fMRI data (volume surface). handles train/test splits needed initial pattern estimation. Design Specification (mvpa_design): Define experimental conditions, blocking variables cross-validation, etc., using rMVPA’s design objects. significant new piece. need way generate m_v vectors ([β₁Δ₁,v, ..., β_QΔ₁,v]). rMVPA’s mvpa_model simple “model” (e.g., just averaging betas first-level GLM within condition cross-validation fold) adapted. Alternatively, new function might needed takes mvpa_dataset mvpa_design (cv_spec) returns K x V matrix Û (cross-validated condition means voxel/vertex V). Step 2b: Contrast Definition (C): user-defined outside rMVPA K x Q matrix. potentially leverage rsa_model adapted, custom function. rsa_model currently seems focused RDM--RDM regression. need regress vec_lower(ÛÛᵀ) onto vec_lower(c_q c_qᵀ) Q contrasts. might require new mvpa_mod_spec custom process_roi function searchlight approach β_q searchlight-specific. whole-brain m_v, β_q might derived globally. Decision Point: β_q global searchlight-specific constructing m_v? G-ReCa proposal implied searchlight aggregation, β_q local. Step 2d: Voxel Contributions (Δ_q = Ûᵀc_q): matrix multiplication. Step 2e: Construct m_v: Combine local β_q Δ_q voxel. Output: NeuroVec NeuroSurfaceVector object containing m_v vectors. Input: m_v NeuroVec/NeuroSurfaceVector. rMVPA doesn’t seem dedicated top-level PCA function purpose, though pcadist implies PCA capability. utility function using stats::prcomp scalable randomized PCA (e.g., irlba rsvd packages) needed. Output: PCA-reduced m_v matrix (N_voxels x ~256 components). Input: PCA-reduced m_v matrix. Implement PPCA (e.g., using EM algorithm, leveraging existing R packages like pcaMethods::ppca suitable uncertainty outputs accessible). Output: Latent coordinates z, posterior covariance Cov(z|m_v). Input: PCA-reduced m_v (PPCA-whitened data). Implement/wrap TwoNN Levina-Bickel MLE (e.g., using R packages like intrinsicDimension custom code). Use scree plot PPCA likelihoods. Output: ID estimates, plot. Reconstruction MSE: Calculated PPCA. Trustworthiness/Continuity: Use scikit-learn via reticulate, find/implement R equivalents. rMVPA doesn’t seem directly. External Gradient Correlations: Standard R functions (cor). Leave-One-Subject-: requires iterating PPCA fitting prediction steps. Store z uncertainty maps NeuroVec/NeuroSurfaceVector easy visualization neuroim2/neurosurf tools. Report generation (Markdown/Jupyter via R Markdown/knitr). Key rMVPA Objects Might Extended Reused: mvpa_model_spec: define g_reca_phase0_model_spec encapsulates PPCA step parameters? run_custom_regional / run_custom_searchlight: promising. core MS-ReVE output generation (steps 2a-2e) potentially wrapped custom_func either ROI searchlight application. run_searchlight machinery handle iteration provide sl_data (voxel patterns within sphere) custom function. NeuroVec / NeuroSurfaceVector (nvec, nsvec): primary data containers m_v, z, uncertainty maps. Concrete Proposal Initial Integration Steps (Focusing MS-ReVE Output Generation): Project: grecamvpa - G-ReCa Integration rMVPA (Phase 0 Focus) Module 1: MS-ReVE Output Generation mvpa_design: underlying mvpa_des object condition/block info. contrast_matrix: user-defined K x Q matrix C. beta_estimation_method: char (e.g., “global_rsa”, “searchlight_rsa”). Purpose: Encapsulates necessary inputs MS-ReVE. Input: mvpa_dataset (ds), mvpa_design (des), cv_spec (cv). Identifies training data fold. Estimates condition means (μ_k) K conditions using training data (e.g., simple averaging voxel activities per condition, betas simple GLM fit training data). Stores means, associated test fold conditions. Output: list structure array containing Û (K x V matrix cross-validated condition means, row k mean condition k estimated data including trials condition k current test fold/run). Input: mvpa_dataset (ds), msreve_design (msreve_des), radius (num), cv_spec (cv). Receives sl_data (data current searchlight sphere) sl_info. Calls compute_crossvalidated_means sl_data using provided msreve_des$mvpa_design cv_spec get local Û_sl. Computes local Ĝ_sl = Û_sl Û_slᵀ. Performs multiple regression RSA using msreve_des$contrast_matrix (C) get local β_q_sl vector (length Q). Computes local Δ_q_sl = Û_slᵀ c_q contrast q. Constructs local m_v_sl vector center voxel sphere: m_v_center = [β_1_sl * Δ_1_center_sl, ..., β_Q_sl * Δ_Q_center_sl]. (Need decide Δ_q whole sphere just center voxel m_v). proposal implies Δ_q V-dim vector, β_q * Δ_q . m_v Q-dim per voxel, ’d use m_v[q] = β_q_sl * Δ_{q,center_voxel_sl}. Returns Q-dimensional m_v_sl vector center voxel. Output: NeuroVec NeuroSurfaceVector voxel/vertex value Q-dimensional m_v vector (implies output actually Q-channel NeuroVec/NeuroSurfaceVector). Module 2: PPCA & ID Estimation (Can standalone R functions initially) Functions PCA pre-reduction. Function PPCA (EM algorithm wrapper). Functions TwoNN, Levina-Bickel MLE. Module 3: Validation (Standalone R functions) Functions Trustworthiness/Continuity (possibly via reticulate). Functions correlation external maps. Phased Implementation Plan grecamvpa (Phase 0): Develop compute_crossvalidated_means: foundational. Test thoroughly. Develop msreve_design object. First, implement regression RSA Δ_q calculation. , integrate compute_crossvalidated_means. Carefully define m_v constructed local β_q Δ_q. Wrap process_msreve_sphere run_msreve_searchlight using run_custom_searchlight: generates primary m_v maps. Implement PCA pre-reduction m_v maps. Implement PPCA module. Implement ID estimation module. Implement validation metrics. End--end pipeline test report generation. approach leverages rMVPA’s strengths data handling searchlight iteration, building new MS-ReVE manifold learning components modular way. run_custom_searchlight function seems like key enabler.","code":""}]
